I wonder if there is a direct way to import the contents of a csv file into a record array, much in the way that R\'s read.table(), read.delim(), and read.csv() family imports data to R\'s data frame? Or is the best way to use csv.reader() and then apply something like numpy.core.records.fromrecords()?You can use Numpy\'s genfromtxt() method to do so, by setting the delimiter kwarg to a comma.More information on the function can be found at its respective documentation.I would recommend the read_csv function from the pandas library:This gives a pandas DataFrame - allowing many useful data manipulation functions which are not directly available with numpy record arrays.DataFrame is a 2-dimensional labeled data structure with columns of\n  potentially different types. You can think of it like a spreadsheet or\n  SQL table...I would also recommend genfromtxt. However, since the question asks for a record array, as opposed to a normal array, the dtype=None parameter needs to be added to the genfromtxt call:Given an input file, myfile.csv:gives an array:and gives a record array:This has the advantage that file with multiple data types (including strings) can be easily imported.You can also try recfromcsv() which can guess data types and return a properly formatted record array.I timed the versus on 4.6 million rows with about 70 columns and found that the numpy path took 2 min 16s and the csv-list comprehension method took 13s.I would recommend the csv-list comprehension method as it is most likely relies on pre-compiled libraries and not the interpreter as much as numpy. i suspect the pandas method would have similar interpreter overhead.You can use this code to send csv file data in to a arrayI tried this: