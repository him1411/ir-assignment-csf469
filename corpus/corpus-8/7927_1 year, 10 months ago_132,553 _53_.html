After you train a model in Tensorflow: I am improving my answer to add more details for saving and restoring models. In(and after) Tensorflow version 0.11: Save the model:Restore the model: This and some more advanced use-cases have been explained very well here.http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/In( and After) TensorFlow version 0.11.0RC1, you can save and restore your model directly by calling tf.train.export_meta_graph and tf.train.import_meta_graph according to https://www.tensorflow.org/programmers_guide/meta_graphsave model:restore model:For TensorFlow version < 0.11.0RC1:The checkpoints that are saved contain values for the Variables in your model, not the model/graph itself, which means that the graph should be the same when you restore the checkpoint.Here\'s an example for a linear regression where there\'s a training loop that saves variable checkpoints and an evaluation section that will restore variables saved in a prior run and compute predictions. Of course, you can also restore variables and continue training if you\'d like.Here are the docs for Variables, which cover saving and restoring. And here are the docs for the Saver.There are two parts to the model, the model definition, saved by Supervisor as graph.pbtxt in the model directory and the numerical values of tensors, saved into checkpoint files like model.ckpt-1003418.The model definition can be restored using tf.import_graph_def, and the weights are restored using Saver.However, Saver uses special collection holding list of variables that\'s attached to the model Graph, and this collection is not initialized using import_graph_def, so you can\'t use the two together at the moment (it\'s on our roadmap to fix). For now, you have to use approach of Ryan Sepassi -- manually construct a graph with identical node names, and use Saver to load the weights into it.(Alternatively you could hack it by using by using import_graph_def, creating variables manually, and using tf.add_to_collection(tf.GraphKeys.VARIABLES, variable) for each variable, then using Saver)You can also take this easier way.Step.1 - Initialize all your variablesStep.2 - Save the list inside Model Saver and Save itStep. 3 - Restore the modelStep. 4 - Check VariableWhile running in different python instance, useAs Yaroslav said, you can hack restoring from a graph_def and checkpoint by importing the graph, manually creating variables, and then using a Saver.I implemented this for my personal use, so I though I\'d share the code here.Link: https://gist.github.com/nikitakit/6ef3b72be67b86cb7868(This is, of course, a hack, and there is no guarantee that models saved this way will remain readable in future versions of TensorFlow.)If it is an internally saved model, you just specify a restorer for all variables asand use it to restore variables in a current session:For the external model you need to specify the mapping from the its variable names to your variable names. You can view the model variable names using the command The inspect_checkpoint.py script can be found in \'./tensorflow/python/tools\' folder of the Tensorflow source.To specify the mapping, you can use my Tensorflow-Worklab, which contains a set of classes and scripts to train and retrain different models. It includes an example of retraining ResNet models, located here Here\'s my simple solution for the two basic cases differing on whether you want to load the graph from file or build it during runtime.This answer holds for Tensorflow 0.12+ (including 1.0).When using this technique, make sure all your layers/variables have explicitly set unique names. Otherwise Tensorflow will make the names unique itself and they\'ll be thus different from the names stored in the file. It\'s not a problem in the previous technique, because the names are "mangled" the same way in both loading and saving.In most cases, saving and restoring from disk using a tf.train.Saver is your best option:You can also save/restore the graph structure itself (see the MetaGraph documentation for details). By default, the Saver saves the graph structure into a .meta file. You can call import_meta_graph() to restore it. It restores the graph structure and returns a Saver that you can use to restore the model\'s state:However, there are cases where you need something much faster. For example, if you implement early stopping, you want to save checkpoints every time the model improves during training (as measured on the validation set), then if there is no progress for some time, you want to roll back to the best model.  If you save the model to disk every time it improves, it will tremendously slow down training. The trick is to save the variable states to memory, then just restore them later:A quick explanation: when you create a variable X, TensorFlow automatically creates an assignment operation X/Assign to set the variable\'s initial value. Instead of creating placeholders and extra assignment ops (which would just make the graph messy), we just use these existing assignment ops. The first input of each assignment op is a reference to the variable it is supposed to initialize, and the second input (assign_op.inputs[1]) is the initial value. So in order to set any value we want (instead of the initial value), we need to use a feed_dict and replace the initial value. Yes, TensorFlow lets you feed a value for any op, not just for placeholders, so this works fine.EditAdded the import_meta_graph() code example.You can also check out examples in TensorFlow/skflow, which offers save and restore methods that can help you easily manage your models. It has parameters that you can also control how frequently you want to back up your model. As described in issue 6255:instead of If you use tf.train.MonitoredTrainingSession as the default session, you don\'t need to add extra code to do save/restore things. Just pass a checkpoint dir name to MonitoredTrainingSession\'s constructor, it will use session hooks to handle these. All the answers here are great, but I want to add two things.First, to elaborate on @user7505159\'s answer, the "./" can be important to add to the beginning of the file name that you are restoring.For example, you can save a graph with no "./" in the file name like so:But in order to restore the graph, you may need to prepend a "./" to the file_name:You will not always need the "./", but it can cause problems depending on your environment and version of TensorFlow.It also want to mention that the sess.run(tf.global_variables_initializer()) can be important before restoring the session.If you are receiving an error regarding uninitialized variables when trying to restore a saved session, make sure you include sess.run(tf.global_variables_initializer()) before the saver.restore(sess, save_file) line. It can save you a headache.