Is there any benefit in using compile for regular expressions in Python?vsI\'ve had a lot of experience running a compiled regex 1000s of times versus compiling on-the-fly, and have not noticed any perceivable difference.  Obviously, this is anecdotal, and certainly not a great argument against compiling, but I\'ve found the difference to be negligible.EDIT:\nAfter a quick glance at the actual Python 2.5 library code, I see that Python internally compiles AND CACHES regexes whenever you use them anyway (including calls to re.match()), so you\'re really only changing WHEN the regex gets compiled, and shouldn\'t be saving much time at all - only the time it takes to check the cache (a key lookup on an internal dict type).From module re.py (comments are mine):I still often pre-compile regular expressions, but only to bind them to a nice, reusable name, not for any expected performance gain.For me, the biggest benefit to re.compile isn\'t any kind of premature optimization (which is the root of all evil, anyway). It\'s being able to separate definition of the regex from its use.Even a simple expression such as 0|[1-9][0-9]* (integer in base 10 without leading zeros) can be complex enough that you\'d rather not have to retype it, check if you made any typos, and later have to recheck if there are typos when you start debugging. Plus, it\'s nicer to use a variable name such as num or num_b10 than 0|[1-9][0-9]*.It\'s certainly possible to store strings and pass them to re.match; however, that\'s less readable:Versus compiling:Though it is fairly close, the last line of the second feels more natural and simpler when used repeatedly.FWIW:so, if you\'re going to be using  the same regex a lot, it may be worth it to do re.compile (especially for more complex regexes).The standard arguments against premature optimization apply, but I don\'t think you really lose much clarity/straightforwardness by using re.compile if you suspect that your regexps may become a performance bottleneck.Here\'s a simple test case:with re.compile:    So, it would seem to compiling is faster with this simple case, even if you only match once.I just tried this myself. For the simple case of parsing a number out of a string and summing it, using a compiled regular expression object is about twice as fast as using the re methods.As others have pointed out, the re methods (including re.compile) look up the regular expression string in a cache of previously compiled expressions. Therefore, in the normal case, the extra cost of using the re methods is simply the cost of the cache lookup.However, examination of the code, shows the cache is limited to 100 expressions. This begs the question, how painful is it to overflow the cache? The code contains an internal interface to the regular expression compiler, re.sre_compile.compile. If we call it, we bypass the cache. It turns out to be about two orders of magnitude slower for a basic regular expression, such as r\'\\w+\\s+([0-9_]+)\\s+\\w*\'.Here\'s my test:The \'reallyCompiled\' methods use the internal interface, which bypasses the cache. Note the one that compiles on each loop iteration is only iterated 10,000 times, not one million.I agree with Honest Abe that the match(...) in the given examples are different.  They are not a one-to-one comparisons and thus, outcomes are vary.  To simplify my reply, I use A, B, C, D for those functions in question.  Oh yes, we are dealing with 4 functions in re.py instead of 3.Running this piece of code:is same as running this code:Because, when looked into the source re.py, (A + B) means:and (C) is actually:So, (C) is not the same as (B).  In fact, (C) calls (B) after calling (D) which is also called by (A).  In other words, (C) = (A) + (B).  Therefore, comparing (A + B) inside a loop has same result as (C) inside a loop.  George\'s regexTest.py proved this for us.Everyone\'s interest is, how to get the result of 2.323 seconds.  In order to make sure compile(...) only get called once, we need to store the compiled regex object in memory.  If we are using a class, we could store the object and reuse when every time our function get called.If we are not using class (which is my request today), then I have no comment.  I\'m still learning to use global variable in Python, and I know global variable is a bad thing.One more point, I believe that using (A) + (B) approach has an upper hand.  Here are some facts as I observed (please correct me if I\'m wrong):Calls A once, it will do one search in the _cache followed by one sre_compile.compile() to create a regex object.  Calls A twice, it will do two searches and one compile (because the regex object is cached).If the _cache get flushed in between, then the regex object is released from memory and Python need to compile again. (someone suggest that Python won\'t recompile.)If we keep the regex object by using (A), the regex object will still get into _cache and get flushed somehow.  But our code keep a reference on it and the regex object will not be released from memory.  Those, Python need not to compile again.The 2 seconds differences in George\'s test compiledInLoop vs compiled is mainly the time required to build the key and search the _cache.  It doesn\'t mean the compile time of regex.George\'s reallycompile test show what happen if it really re-do the compile every time: it will be 100x slower (he reduced the loop from 1,000,000 to 10,000).Here are the only cases that (A + B) is better than (C):Case that (C) is good enough:Just a recap, here are the A B C:Thanks for reading.In general, I find it is easier to use flags (at least easier to remember how), like re.I when compiling patterns than to use flags inline.vs Interestingly, compiling does prove more efficient for me (Python 2.5.2 on Win XP):Running the above code once as is, and once with the two if lines commented the other way around, the compiled regex is twice as fastI ran this test before stumbling upon the discussion here.  However, having run it I thought I\'d at least post my results.I stole and bastardized the example in Jeff Friedl\'s "Mastering Regular Expressions".  This is on a macbook running OSX 10.6 (2Ghz intel core 2 duo, 4GB ram).  Python version is 2.6.1.Run 1 - using re.compileRun 2 - Not using re.compileUsing the given examples:The match method in the example above is not the same as the one used below:re.compile() returns a regular expression object, which means h is a regex object.The regex object has its own match method with the optional pos and endpos parameters:regex.match(string[, pos[, endpos]]) posThe optional second parameter pos gives an index in the string where\n  the search is to start; it defaults to 0. This is not completely\n  equivalent to slicing the string; the \'^\' pattern character matches at\n  the real beginning of the string and at positions just after a\n  newline, but not necessarily at the index where the search is to\n  start.endposThe optional parameter endpos limits how far the string will be\n  searched; it will be as if the string is endpos characters long, so\n  only the characters from pos to endpos - 1 will be searched for a\n  match. If endpos is less than pos, no match will be found; otherwise,\n  if rx is a compiled regular expression object, rx.search(string, 0,\n  50) is equivalent to rx.search(string[:50], 0).The regex object\'s search, findall, and finditer methods also support these parameters.re.match(pattern, string, flags=0) does not support them as you can see,\nnor does its search, findall, and finditer counterparts.A match object has attributes that complement these parameters:match.posThe value of pos which was passed to the search() or match() method of\n  a regex object. This is the index into the string at which the RE\n  engine started looking for a match.match.endposThe value of endpos which was passed to the search() or match() method\n  of a regex object. This is the index into the string beyond which the\n  RE engine will not go.A regex object has two unique, possibly useful, attributes:regex.groupsThe number of capturing groups in the pattern.regex.groupindexA dictionary mapping any symbolic group names defined by (?P) to\n  group numbers. The dictionary is empty if no symbolic groups were used\n  in the pattern.And finally, a match object has this attribute:match.reThe regular expression object whose match() or search() method\n  produced this match instance.There is one addition perk of using re.compile(), in the form of adding comments to my regex patterns using re.VERBOSEAlthough this does not affect the speed of running your code, I like to do it this way as it is part of my commenting habit. I throughly dislike spending time trying to remember the logic that went behind my code 2 months down the line when I want to make modifications.This is a good question. You often see people use re.compile without reason. It lessens readability. But sure there are lots of times when pre-compiling the expression is called for. Like when you use it repeated times in a loop or some such.It\'s like everything about programming (everything in life actually). Apply common sense.Performance difference aside, using re.compile and using the compiled regular expression object to do match (whatever regular expression related operations) makes the semantics clearer to Python run-time.I had some painful experience of debugging some simple code:and later I\'d use compare in where patternPhrases is supposed to be a variable containing regular expression string, x[columnIndex] is a variable containing string.I had trouble that patternPhrases did not match some expected string!But if I used the re.compile form:then in Python would have complained that "string does not have attribute of match", as by positional argument mapping in compare, x[columnIndex] is used as regular expression!, when I actually meantIn my case, using re.compile is more explicit of the purpose of regular expression, when it\'s value is hidden to naked eyes, thus I could get more help from Python run-time checking. So the moral of my lesson is that when the regular expression is not just literal string, then I should use re.compile to let Python to help me to assert my assumption.This answer might be arriving late but is an interesting find. Using compile can really save you time if you are planning on using the regex multiple times (this is also mentioned in the docs). Below you can see that using a compiled regex is the fastest when the match method is directly called on it. passing a compiled regex to re.match makes it even slower and passing re.match with the patter string is somewhere in the middle. Mostly, there is little difference whether you use re.compile or not.  Internally, all of the functions are implemented in terms of a compile step:If you use re.compile() you by-pass a little of overhead for the extra indirection and for the overhead of the caching logic:In addition to the small speed benefit from using re.compile, people also like the readability that comes from naming potentially complex pattern specifications and separating them from the business logic where there are applied:Note, one other respondent incorrectly believed that pyc files stored compiled patterns directly; however, in reality they are rebuilt each time when the PYC is loaded:The above disassembly comes from the PYC file for a tmp.py containing:Regular Expressions are compiled before being used when using the second version.  If you are going to executing it many times it is definatly better to compile it first.  If not compiling every time you match for one off\'s is fine.(months later) it\'s easy to add your own cache around re.match,\nor anything else for that matter --A wibni, wouldn\'t it be nice if: cachehint( size= ), cacheinfo() -> size, hits, nclear ...i\'d like to motivate that pre-compiling is both conceptually and \'literately\' (as in \'literate programming\') advantageous. have a look at this code snippet:in your application, you\'d write:this is about as simple in terms of functionality as it can get. because this is example is so short, i conflated the way to get _text_has_foobar_re_search all in one line. the disadvantage of this code is that it occupies a little memory for whatever the lifetime of the TYPO library object is; the advantage is that when doing a foobar search, you\'ll get away with two function calls and two class dictionary lookups. how many regexes are cached by re and the overhead of that cache are irrelevant here. compare this with the more usual style, below:In the application:I readily admit that my style is highly unusual for python, maybe even debatable. however, in the example that more closely matches how python is mostly used, in order to do a single match, we must instantiate an object, do three instance dictionary lookups, and perform three function calls; additionally, we might get into re caching troubles when using more than 100 regexes. also, the regular expression gets hidden inside the method body, which most of the time is not such a good idea. be it said that every subset of measures---targeted, aliased import statements; aliased methods where applicable; reduction of function calls and object dictionary lookups---can help reduce computational and conceptual complexity. I\'ve had a lot of experience running a compiled regex 1000s\n  of times versus compiling on-the-fly, and have not noticed\n  any perceivable differenceThe votes on the accepted answer leads to the assumption that what @Triptych says is true for all cases. This is not necessarily true. One big difference is when you have to decide whether to accept a regex string or a compiled regex object as a parameter to a function:It is always better to compile your regexs in case you need to reuse them. Note the example in the timeit above simulates creation of a compiled regex object once at import time versus "on-the-fly" when required for a match.I really respect all the above answers. From my opinion\nYes! For sure it is worth to use re.compile instead of compiling the regex, again and again, every time. Using re.compile makes your code more dynamic, as you can call the already compiled regex, instead of compiling again and aagain. This thing benefits you in cases:Example :Similarly you can use it for: Match and SubstituteMy understanding is that those two examples are effectively equivalent. The only difference is that in the first, you can reuse the compiled regular expression elsewhere without causing it to be compiled again.Here\'s a reference for you: http://diveintopython3.ep.io/refactoring.htmlCalling the compiled pattern object\'s search function with the string \'M\' accomplishes the same thing as calling re.search with both the regular expression and the string \'M\'. Only much, much faster. (In fact, the re.search function simply compiles the regular expression and calls the resulting pattern object\'s search method for you.) 