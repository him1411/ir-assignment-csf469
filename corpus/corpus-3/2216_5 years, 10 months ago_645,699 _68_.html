Pretty much I need to write a program to check if a list has any duplicates and if it does it removes them and returns a new list with the items that werent duplicated/removed. This is what I have but to be honest I do not know what to do.The common approach to get a unique collection of items is to use a set. Sets are unordered collections of distinct objects. To create a set from any iterable, you can simply pass it to the built-in set() function. If you later need a real list again, you can similarly pass the set to the list() function.The following example should cover whatever you are trying to do:As you can see from the example result, the original order is not maintained. As mentioned above, sets themselves are unordered collections, so the order is lost. When converting a set back to a list, an arbitrary order is created.If order is important to you, then you will have to use a different mechanism. This question covers that topic in more detail.FWIW, the new (v2.7) Python way for removing duplicates from an iterable while keeping it in the original order is:In Python 3.5, the OrderedDict has a C implementation. My timings show that this is now both the fastest and shortest of the various approaches.In CPython 3.6, the regular dict in now both ordered and compact.  For the moment, this is considered an implementation detail but will likely become a guaranteed feature in the future.  That gives us a new fastest way of deduping while retaining order:It\'s a one-liner: list(set(source_list)) will do the trick.A set is something that can\'t possibly have duplicates.Update: an order-preserving approach is two lines:Here we use the fact that OrderedDict remembers the insertion order of keys, and does not change it when a value at a particular key is updated. We insert True as values, but we could insert anything, values are just not used. (set works a lot like a dict with ignored values, too.)If you don\'t care about the order, just do this:A set is guaranteed to not have duplicates.To make a new list  retaining the order of first elements of duplicates in Lnewlist=[ii for n,ii in enumerate(L) if ii not in L[:n]]for example if L=[1, 2, 2, 3, 4, 2, 4, 3, 5] then newlist will be [1,2,3,4,5]This checks each new element has not appeared previously in the list before adding it. \nAlso it does not need imports. Another way of doing:A colleague have sent the accepted answer as part of his code to me for a codereview today.\nWhile I certainly admire the elegance of the answer in question, I am not happy with the performance.\nI have tried this solution (I use set to reduce lookup time)To compare efficiency, I used a random sample of 100 integers - 62 were uniqueHere are the results of the measurementsWell, what happens if set is removed from the solution?The result is not as bad as with the OrderedDict, but still more than 3 times of the original solutionI had a dict in my list, so I could not use the above approach. I got the error:So if you care about order and/or some items are unhashable. Then you might find this useful:Some may consider list comprehension with a side effect to not be a good solution. Here\'s an alternative:Simple and easy:Output:Try using sets:You can use numpy function unique() (eventually using the function .tolist() if you don\'t want a numpy array)below code is simple for removing duplicate in listit returns [1,2,3,4]You could also do this:The reason that above works is that index method returns only the first index of an element. Duplicate elements have higher indices. Refer to here:list.index(x[, start[, end]])\n  Return zero-based index in the list of\n  the first item whose value is x.    Raises a ValueError if there is no\n  such item.This one cares about the order without too much hassle (OrderdDict & others). Probably not the most Pythonic way, nor shortest way, but does the trick:All the order-preserving approaches I\'ve seen here so far either use naive  comparison (with O(n^2) time-complexity at best) or heavy-weight OrderedDicts/set+list combinations that are limited to hashable inputs. Here is a hash-independent O(nlogn) solution:Nowadays you might use Counter class:Here is an example, returning list without repetiotions preserving order. Does not need any external imports.Reduce variant with ordering preserve:Assume that we have list:Reduce variant (unefficient):5 x faster but more sophisticatedExplanation:There are many other answers suggesting different ways to do this, but they\'re all batch operations, and some of them throw away the original order. That might be okay depending on what you need, but if you want to iterate over the values in the order of the first instance of each value, and you want to remove the duplicates on-the-fly versus all at once, you could use this generator:This returns a generator/iterator, so you can use it anywhere that you can use an iterator.Output:If you do want a list, you can do this:Output:Here\'s the fastest pythonic solution comaring to others listed in replies.Using implementation details of short-circuit evaluation allows to use list comprehension, which is fast enough. visited.add(item) always returns None as a result, which is evaluated as False, so the right-side of or would always be the result of such an expression.Time it yourselfCheck this if you want to remove duplicates (in-place edit rather than returning new list) without using inbuilt set, dict.keys, uniqify, counterUsing set :Using unique :Best approach of removing duplicates from a list is using set() function, available in python, again converting that set into listTo remove the duplicates, make it a SET and then again make it a LIST and print/use it.\nA set is guaranteed to have unique elements. For example : The output will be as follows (checked in python 2.7)For completeness, and since this is a very popular question, the toolz library offers a unique function:I think converting to set is the easiest way to remove duplicate:You can do this simply by using sets.Step1: Get Different elements of lists \nStep2 Get Common elements of lists \nStep3 Combine themA list comprehesion to remove duplicatesIf you don\'t care about order and want something different than the pythonic ways suggested above (that is, it can be used in interviews) then : Time Complexity : O(n)Auxiliary Space : O(n)Reference: http://www.geeksforgeeks.org/remove-duplicates-sorted-array/