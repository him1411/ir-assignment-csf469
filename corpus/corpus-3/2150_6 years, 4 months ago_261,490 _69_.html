I\'m looking for the fastest way of inserting into Entity Framework.I\'m asking this because of the scenario where you have an active TransactionScope and the insertion is huge (4000+). It can potentially last more than 10 minutes (default timeout of transactions), and this will lead to an incomplete transaction.To your remark in the comments to your question:"...SavingChanges (for each\n  record)..."That\'s the worst thing you can do! Calling SaveChanges() for each record slows bulk inserts extremely down. I would do a few simple tests which will very likely improve the performance:For bulk inserts I am working and experimenting with a pattern like this:I have a test program which inserts 560.000 entities (9 scalar properties, no navigation properties) into the DB. With this code it works in less than 3 minutes.For the performance it is important to call SaveChanges() after "many" records ("many" around 100 or 1000). It also improves the performance to dispose the context after SaveChanges and create a new one. This clears the context from all entites, SaveChanges doesn\'t do that, the entities are still attached to the context in state Unchanged. It is the growing size of attached entities in the context what slows down the insertion step by step. So, it is helpful to clear it after some time.Here are a few measurements for my 560.000 entities:The behaviour in the first test above is that the performance is very non-linear and decreases extremely over time. ("Many hours" is an estimation, I never finished this test, I stopped at 50.000 entities after 20 minutes.) This non-linear behaviour is not so significant in all other tests.This combination increase speed well enough.The fastest way would be using bulk insert extension, which I developed.It uses SqlBulkCopy and custom datareader to get max performance. As a result it is over 20 times faster than using regular insert or AddRange\nusage is extremely simpleYou should look at using the System.Data.SqlClient.SqlBulkCopy for this.  Here\'s the documentation, and of course there are plenty of tutorials online.Sorry, I know you were looking for a simple answer to get EF to do what you want, but bulk operations are not really what ORMs are meant for.I agree with Adam Rackis. SqlBulkCopy is the fastest way of transferring bulk records from one data source to another. I used this to copy 20K records and it took less than 3 seconds. Have a look at the example below.I\'ve investigated Slauma\'s answer (which is awesome, thanks for the idea man), and I\'ve reduced batch size until I\'ve hit optimal speed. Looking at the Slauma\'s results:It is visible that there is speed increase when moving from 1 to 10, and from 10 to 100, but from 100 to 1000 inserting speed is falling down again.So I\'ve focused on what\'s happening when you reduce batch size to value somewhere in between 10 and 100, and here are my results (I\'m using different row contents, so my times are of different value):Based on my results, actual optimum is around value of 30 for batch size. It\'s less than both 10 and 100. Problem is, I have no idea why is 30 optimal, nor could have I found any logical explanation for it.Dispose() context create problems if the entities you Add() rely on other preloaded entities (e.g. navigation properties) in the contextI use similar concept to keep my context small to achieve the same performanceBut instead of Dispose() the context and recreate, I simply detach the entities that already SaveChanges()wrap it with try catch and TrasactionScope() if you need,\nnot showing them here for keeping the code cleanAs other people have said SqlBulkCopy is the way to do it if you want really good insert performance.It\'s a bit cumbersome to implement but there are libraries that can help you with it. There are a few out there but I will shamelesslyplug my own library this time: https://github.com/MikaelEliasson/EntityFramework.Utilities#batch-insert-entitiesThe only code you would need is:So how much faster is it? Very hard to say because it depends on so many factors, computer performance, network, object size etc etc. The performance tests I\'ve made suggests 25k entities can be inserted at around 10s the standard way on localhost IF you optimize your EF configuration like mentioned in the other answers. With EFUtilities that takes about 300ms. Even more interesting is that I have saved around 3 millions entities in under 15 seconds using this method, averaging around 200k entities per second.The one problem is ofcourse if you need to insert releated data. This can be done efficently into sql server using the method above but it requires you to have an Id generation strategy that let you generate id\'s in the app-code for the parent so you can set the foreign keys. This can be done using GUIDs or something like HiLo id generation.  I would recommend this article on how to do bulk inserts using EF.Entity Framework and slow bulk INSERTsHe explores these areas and compares perfomance:Try to use a Stored Procedure that will get an XML of the data that you want to insert.I\'m looking for the fastest way of inserting into Entity FrameworkThere is some third party library supporting Bulk Insert available:See: Entity Framework Bulk Insert libraryBe careful, when choosing a bulk insert library. Only Entity Framework Extensions support all kind of associations and inheritance and it\'s the only one still supported.Disclaimer: I\'m the owner of Entity Framework ExtensionsThis library allows you to perform all bulk operations you need for your scenarios:ExampleAs per my knowledge there is no BulkInsert in EntityFramework to increase the performance of the huge inserts.In this scenario you can go with SqlBulkCopy in ADO.net to solve your problemHere is a performance comparison between using Entity Framework and using SqlBulkCopy class on a realistic example: How to Bulk Insert Complex Objects into SQL Server DatabaseAs others already emphasized, ORMs are not meant to be used in bulk operations. They offer flexibility, separation of concerns and other benefits, but bulk operations (except bulk reading) are not one of them.I have made an generic extension of @Slauma s example above;Usage:Another option is to use SqlBulkTools available from Nuget. It\'s very easy to use and has some powerful features. Example:See the documentation for more examples and advanced usage. Disclaimer: I am the author of this library and any views are of my own opinion.  Use SqlBulkCopy:The secret is to insert into an identical blank staging table. Inserts are lightening quick. Then run a single insert from that into your main large table. Then truncate the staging table ready for the next batch.ie.Have you ever tried to insert through a background worker or task?In my case, im inserting 7760 registers, distributed in 182 different tables with foreign key relationships ( by NavigationProperties).Without the task, it took 2 minutes and a half.\nWithin a Task ( Task.Factory.StartNew(...) ), it took 15 seconds.Im only doing the SaveChanges() after adding all the entities to the context. (to ensure data integrity)All the solutions written here don\'t help because when you do SaveChanges(), insert statements are sent to database one by one, that\'s how Entity works. And if your trip to database and back is 50 ms for instance then time needed for insert is number of records x 50 ms.You have to use BulkInsert, here is the link: https://efbulkinsert.codeplex.com/I got insert time reduced from 5-6 minutes to 10-12 seconds by using it.You may use Bulk package library. \nBulk Insert 1.0.0 version is used in projects having Entity framework >=6.0.0 .More description can be found here-\nBulkoperation source code [NEW SOLUTION FOR POSTGRESQL]\nHey, I know it\'s quite an old post, but I have recently run into similar problem, but we were using Postgresql. I wanted to use effective bulkinsert, what turned out to be pretty difficult. I haven\'t found any proper free library to do so on this DB. I have only found this helper:\nhttps://bytefish.de/blog/postgresql_bulk_insert/\nwhich is also on Nuget. I have written a small mapper, which auto mapped properties the way Entity Framework:I use it the following way (I had entity named Undertaking):I showed an example with transaction, but it can also be done with normal connection retrieved from context. undertakingsToAdd is enumerable of normal entity records, which I want to bulkInsert into DB.This solution, to which I\'ve got after few hours of research and trying, is as you could expect much faster and finally easy to use and free! I really advice you to use this solution, not only for the reasons mentioned above, but also because it\'s the only one with which I had no problems with Postgresql itself, many other solutions work flawlessly for example with SqlServer.First - it works much faster (about 10x) when project is compile in Release not in DebugSecond - If there is a serious performance issue - isolate this place in code and rewrite it to ADO using Table-Valued-Parameters. It will works MUCH faster. 