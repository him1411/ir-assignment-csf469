If I have some R list mylist, you can append an item obj to it like so:But surely there is some more compact way.  When I was new at R, I  tried writing lappend() like so:but of course that doesn\'t work due to R\'s call-by-name semantics (lst is effectively copied upon call, so changes to lst are not visible outside the scope of lappend().  I know you can do environment hacking in an R function to reach outside the scope of your function and mutate the calling environment, but that seems like a large hammer to write a simple append function.Can anyone suggest a more beautiful way of doing this? Bonus points if it works for both vectors and lists.If it\'s a list of string, just use the c() function :That works on vectors too, so do I get the bonus points?Edit (2015-Feb-01): This post is coming up on its fifth birthday.  Some kind readers keep repeating any shortcomings with it, so by all means also see some of the comments below. One suggestion for list types:In general, R types can make it hard to have one and just one idiom for all types and uses.The OP (in the April 2012 updated revision of the question) is interested in knowing if there\'s a way to add to a list in amortized constant time, such as can be done, for example, with a C++ vector<> container. The best answer(s?) here so far only show the relative execution times for various solutions given a fixed-size problem, but do not address any of the various solutions\' algorithmic efficiency directly. Comments below many of the answers discuss the algorithmic efficiency of some of the solutions, but in every case to date (as of April 2015) they come to the wrong conclusion.Algorithmic efficiency captures the growth characteristics, either in time (execution time) or space (amount of memory consumed) as a problem size grows. Running a performance test for various solutions given a fixed-size problem does not address the various solutions\' growth rate. The OP is interested in knowing if there is a way to append objects to an R list in "amortized constant time". What does that mean? To explain, first let me describe "constant time":Constant or O(1) growth:If the time required to perform a given task remains the same as the size of the problem doubles, then we say the algorithm exhibits constant time growth, or stated in "Big O" notation, exhibits O(1) time growth. When the OP says "amortized" constant time, he simply means "in the long run"... i.e., if performing a single operation occasionally takes much longer than normal (e.g. if a preallocated buffer is exhausted and occasionally requires resizing to a larger buffer size), as long as the long-term average performance is constant time, we\'ll still call it O(1).For comparison, I will also describe "linear time" and "quadratic time":Linear or O(n) growth:If the time required to perform a given task doubles as the size of the problem doubles, then we say the algorithm exhibits linear time, or O(n) growth.Quadratic or O(n2) growth:If the time required to perform a given task increases by the square of the problem size, them we say the algorithm exhibits quadratic time, or O(n2) growth.There are many other efficiency classes of algorithms; I defer to the Wikipedia article for further discussion.I thank @CronAcronis for his answer, as I am new to R and it was nice to have a fully-constructed block of code for doing a performance analysis of the various solutions presented on this page. I am borrowing his code for my analysis, which I duplicate (wrapped in a function) below:The results posted by @CronAcronis definitely seem to suggest that the a <- list(a, list(i)) method is fastest, at least for a problem size of 10000, but the results for a single problem size do not address the growth of the solution. For that, we need to run a minimum of two profiling tests, with differing problem sizes:First of all, a word about the min/lq/mean/median/uq/max values: Since we are performing the exact same task for each of 5 runs, in an ideal world, we could expect that it would take exactly the same amount of time for each run. But the first run is normally biased toward longer times due to the fact that the code we are testing is not yet loaded into the CPU\'s cache. Following the first run, we would expect the times to be fairly consistent, but occasionally our code may be evicted from the cache due to timer tick interrupts or other hardware interrupts that are unrelated to the code we are testing. By testing the code snippets 5 times, we are allowing the code to be loaded into the cache during the first run and then giving each snippet 4 chances to run to completion without interference from outside events. For this reason, and because we are really running the exact same code under the exact same input conditions each time, we will consider only the \'min\' times to be sufficient for the best comparison between the various code options.Note that I chose to first run with a problem size of 2000 and then 20000, so my problem size increased by a factor of 10 from the first run to the second.Performance of the list solution: O(1) (constant time)Let\'s first look at the growth of the list solution, since we can tell right away that it\'s the fastest solution in both profiling runs: In the first run, it took 854 microseconds (0.854 milliseconds) to perform 2000 "append" tasks. In the second run, it took 8.746 milliseconds to perform 20000 "append" tasks. A na\xc3\xafve observer would say, "Ah, the list solution exhibits O(n) growth, since as the problem size grew by a factor of ten, so did the time required to execute the test." The problem with that analysis is that what the OP wants is the growth rate of a single object insertion, not the growth rate of the overall problem. Knowing that, it\'s clear then that the list solution provides exactly what the OP wants: a method of appending objects to a list in O(1) time.Performance of the other solutionsNone of the other solutions come even close to the speed of the list solution, but it is informative to examine them anyway:Most of the other solutions appear to be O(n) in performance. For example, the by_index solution, a very popular solution based on the frequency with which I find it in other SO posts, took 11.6 milliseconds to append 2000 objects, and 953 milliseconds to append ten times that many objects. The overall problem\'s time grew by a factor of 100, so a na\xc3\xafve observer might say "Ah, the by_index solution exhibits O(n2) growth, since as the problem size grew by a factor of ten, the time required to execute the test grew by a factor of 100." As before, this analysis is flawed, since the OP is interested in the growth of a single object insertion. If we divide the overall time growth by the problem\'s size growth, we find that the time growth of appending objects increased by a factor of only 10, not a factor of 100, which matches the growth of the problem size, so the by_index solution is O(n). There are no solutions listed which exhibit O(n2) growth for appending a single object.In the other answers, only the list approach results in O(1) appends, but it results in a deeply nested list structure, and not a plain single list. I have used the below datastructures, they supports O(1) (amortized) appends, and allow the result to be converted back to a plain list. andUse them as follows:These solutions could be expanded into full objects that support al list-related operations by themselves, but that will remain as an exercise for the reader. Another variant for a named list:BenchmarksPerformance comparison using @phonetagger\'s code (which is based on @Cron Arconis\' code). I have also added a better_env_as_container and changed the env_as_container_ a bit. The original env_as_container_ was broken and doesn\'t actually store all the numbers.result:I have added linkedList and expandingList and an inlined version of both. The inlinedLinkedList is basically a copy of list_, but it also converts the nested structure back into a plain list. Beyond that the difference between the inlined and non-inlined versions is due to the overhead of the function calls.All variants of expandingList and linkedList show O(1) append performance, with the benchmark time scaling linearly with the number of items appended. linkedList is slower than expandingList, and the function call overhead is also visible. So if you really need all the speed you can get (and want to stick to R code), use an inlined version of expandingList.I\'ve also had a look at the C implementation of R, and both approaches should be O(1) append for any size up until you run out of memory.I have also changed env_as_container_, the original version would store every item under index "i", overwriting the previously appended item. The better_env_as_container I have added is very similar to env_as_container_ but without the deparse stuff. Both exhibit O(1) performance, but they have an overhead that is quite a bit larger than the linked/expanding lists.Memory overheadIn the C R implementation there is an overhead of 4 words and 2 ints per allocated object. The linkedList approach allocates one list of length two per append, for a total of (4*8+4+4+2*8=) 56 bytes per appended item on 64-bit computers (excluding memory allocation overhead, so probably closer to 64 bytes). The expandingList approach uses one word per appended item, plus a copy when doubling the vector length, so a total memory usage of up to 16 bytes per item. Since the memory is all in one or two objects the per-object overhead is insignificant. I haven\'t looked deeply into the env memory usage, but I think it will be closer to linkedList. In the Lisp we did it this way:though it was \'cons\', not just \'c\'. If you need to start with an empy list, use l <- NULL.If you pass in the list variable as a quoted string, you can reach it from within the function like:so:or for extra credit:You want something like this maybe?It\'s not a very polite function (assigning to parent.frame() is kind of rude) but IIUYC it\'s what you\'re asking for.Not sure why you don\'t think your first method won\'t work.  You have a bug in the lappend function: length(list) should be length(lst).  This works fine and returns a list with the appended obj.I have made a small comparison of methods mentioned here.Results:I think what you want to do is actually pass by reference (pointer) to the function-- create a new environment (which are passed by reference to functions) with the list added to it:Now you are only modifying the existing list (not creating a new one)try this function lappendand other suggestions from this page Add named vector to a listBye.in fact there is a subtelty with the c() function. If you do:you will obtain as expected:but if you add a matrix with x <- c(x, matrix(5,2,2), your list will have another 4 elements of value 5 !\nYou would better do:It works for any other object and you will obtain as expected:Finally, your function becomes:and it works for any type of object. You can be smarter and do:This is a straightforward way to add items to an R List:Or programmatically:This is a very interesting question and I hope my thought below could contribute an way of solution to it. This method do give a flat list without indexing, but it does have list and unlist to avoid the nesting structures. I\'m not sure about the speed since I don\'t know how to benchmark it.