I\'m having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup. The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.One of the sections of code that is causing problems is shown below:Here is a stack trace produced on SOME strings when the snippet above is run:I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?You need to read the Python Unicode HOWTO. This error is the very first example.Basically, stop using str to convert from unicode to encoded text / bytes.Instead, properly use .encode() to encode the string:or work entirely in unicode.This is a classic python unicode pain point! Consider the following:All good so far, but if we call str(a), let\'s see what happens:Oh dip, that\'s not gonna do anyone any good! To fix the error, encode the bytes explicitly with .encode and tell python what codec to use:Voil\\u00E0!The issue is that when you call str(), python uses the default character encoding to try and encode the bytes you gave it, which in your case are sometimes representations of unicode characters. To fix the problem, you have to tell python how to deal with the string you give it by using .encode(\'whatever_unicode\'). Most of the time, you should be fine using utf-8.For an excellent exposition on this topic, see Ned Batchelder\'s PyCon talk here: http://nedbatchelder.com/text/unipain.htmlI found elegant work around for me to remove symbols and continue to keep string as string in follows:It\'s important to notice that using the ignore option is dangerous because it silently drops any unicode(and internationalization) support from the code that uses it, as seen here:A subtle problem causing even print to fail is having your environment variables set wrong, eg. here LC_ALL set to "C".  In Debian they discourage setting it: Debian wiki on Localewell i tried everything but it did not help, after googling around i figured the following and it helped.\npython 2.7 is in use.I\'ve actually found that in most of my cases, just stripping out those characters is much simpler:For me, what worked was:Hope this helps someone.Add line below at the beginning of your script ( or as second line):That\'s definition of python source code encoding. More info in PEP 263.The problem is that you\'re trying to print a unicode character, but your terminal doesn\'t support it.You can try installing language-pack-en package to fix that:which provides English translation data updates for all supported packages (including Python). Install different language package if necessary (depending which characters you\'re trying to print).On some Linux distributions it\'s required in order to make sure that the default English locales are set-up properly (so unicode characters can be handled by shell/terminal). Sometimes it\'s easier to install it, than configuring it manually.Then when writing the code, make sure you use the right encoding in your code.For example:If you\'ve still a problem, double check your system configuration, such as:your locale file (/etc/default/locale), which should have e.g.value of LANG/LC_CTYPE in shellDemonstrating the problem and solution in fresh VM.Initialize and provision the VM (e.g. using vagrant):See: available Ubuntu boxes..Printing unicode characters (such as trade mark sign like \xe2\x84\xa2): Now installing language-pack-en:Now problem is solved:Simple helper functions found here.I just used the following:Check what documentation says about it:unicodedata.normalize(form, unistr) Return the normal form form for\n  the Unicode string unistr. Valid values for form are \xe2\x80\x98NFC\xe2\x80\x99, \xe2\x80\x98NFKC\xe2\x80\x99,\n  \xe2\x80\x98NFD\xe2\x80\x99, and \xe2\x80\x98NFKD\xe2\x80\x99.The Unicode standard defines various normalization forms of a Unicode\n  string, based on the definition of canonical equivalence and\n  compatibility equivalence. In Unicode, several characters can be\n  expressed in various way. For example, the character U+00C7 (LATIN\n  CAPITAL LETTER C WITH CEDILLA) can also be expressed as the sequence\n  U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING CEDILLA).For each character, there are two normal forms: normal form C and\n  normal form D. Normal form D (NFD) is also known as canonical\n  decomposition, and translates each character into its decomposed form.\n  Normal form C (NFC) first applies a canonical decomposition, then\n  composes pre-combined characters again.In addition to these two forms, there are two additional normal forms\n  based on compatibility equivalence. In Unicode, certain characters are\n  supported which normally would be unified with other characters. For\n  example, U+2160 (ROMAN NUMERAL ONE) is really the same thing as U+0049\n  (LATIN CAPITAL LETTER I). However, it is supported in Unicode for\n  compatibility with existing character sets (e.g. gb2312).The normal form KD (NFKD) will apply the compatibility decomposition,\n  i.e. replace all compatibility characters with their equivalents. The\n  normal form KC (NFKC) first applies the compatibility decomposition,\n  followed by the canonical composition.Even if two unicode strings are normalized and look the same to a\n  human reader, if one has combining characters and the other doesn\xe2\x80\x99t,\n  they may not compare equal.Solves it for me. Simple and easy.I just had this problem, and Google led me here, so just to add to the general solutions here, this is what worked for me:I had this idea after reading Ned\'s presentation.I don\'t claim to fully understand why this works, though. So if anyone can edit this answer or put in a comment to explain, I\'ll appreciate it.