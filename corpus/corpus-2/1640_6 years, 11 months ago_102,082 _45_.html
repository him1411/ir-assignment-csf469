Who first said the following?A monad is just a monoid in the\n  category of endofunctors, what\'s the\n  problem?And on a less important note, is this true and if so could you give an explanation (hopefully one that can be understood by someone who doesn\'t have much Haskell experience)?That particularly phrasing is by James Iry, from his highly entertaining Brief, Incomplete and Mostly Wrong History of Programming Languages, in which he fictionally attributes it to Philip Wadler. The original quote is from Saunders Mac Lane in Categories for the Working Mathematician, one of the foundational texts of Category Theory. Here it is in context, which is probably the best place to learn exactly what it means.But, I\'ll take a stab. The original sentence is this:All told, a monad in X is just a monoid in the category of endofunctors of X, with product \xc3\x97 replaced by composition of endofunctors and unit set by the identity endofunctor.X here is a category. Endofunctors are functors from a category to itself (which is usually all Functors as far as functional programmers are concerned, since they\'re mostly dealing with just one category; the category of types--but I digress). But you could imagine another category which is the category of "endofunctors on X". This is a category in which the objects are endofunctors and the morphisms are natural transformations. And of those endofunctors, some of them might be monads. Which ones are monads? Just exactly the ones which are monoidal in a particular sense. Instead of spelling out the exact mapping from monads to monoids (since Mac Lane does that far better than I could hope to), I\'ll just put their respective definitions side by side and let you compare:With a bit of squinting you might be able to see that both of these definitions are instances of the same abstract concept.Intuitively, I think that what the fancy math vocabulary is saying is that:A monoid is a set of objects, and a method of combining them. Well known monoids are:There are more complex examples also.Further, every monoid has an identity, which is that "no-op" element that has no effect when you combine it with something else:Finally, a monoid must be associative. (you can reduce a long string of combinations anyway you want, as long as you don\'t change the left-to-right-order of objects) Addition is OK ((5+3)+1 == 5+(3+1)), but subtraction isn\'t ((5-3)-1 != 5-(3-1)).Now, let\'s consider a special kind of set and a special way of combining objects.Suppose your set contains objects of a special kind: functions. And these functions have an interesting signature: They don\'t carry numbers to numbers or strings to strings. Instead, each function carries a number to a list of numbers in a two-step process.Examples:Also, our way of combining functions is special. A simple way to combine function is composition: Let\'s take our examples above, and compose each function with itself:Without getting too much into type theory, the point is that you can combine two integers to get an integer, but you can\'t always compose two functions and get a function of the same type. (Functions with type a -> a  will compose, but a-> [a] won\'t.)So, let\'s define a different way of combining functions. When we combine two of these functions, we don\'t want to "double-wrap" the results. Here is what we do. When we want to combine two functions F and G, we follow this process (called binding):Back to our examples, let\'s combine (bind) a function with itself using this new way of "binding" functions:This more sophisticated way of combining functions is associative (following from how function composition is associative when you aren\'t doing the fancy wrapping stuff).Tying it all together, There are lots of ways to "wrap" results. You can make a list, or a set, or discard all but the first result while noting if there are no results, attach a sidecar of state, print a log message, etc, etc.I\'ve played a bit loose with the definitions in hopes of getting the essential idea across intuitively.I\'ve simplified things a bit by insisting that our monad operates on functions of type a -> [a]. In fact, monads work on functions of type a -> m b, but the generalization is kind of a technical detail that isn\'t the main insight.First, the extensions and libraries that we\'re going to use:Of these, RankNTypes is the only one that\'s absolutely essential to the below. I once wrote an explanation of RankNTypes that some people seem to have found useful, so I\'ll refer to that.Quoting Tom Crockett\'s excellent answer, we have:How do we translate this to Haskell code? Well, let\'s start with the notion of a natural transformation:A type of the form f :-> g is analogous to a function type, but instead of thinking of it as a function between two types (of kind *), think of it as a morphism between two functors (each of kind * -> *). Examples:Basically, in Haskell, natural transformations are functions from some type f x to another type g x such that the x type variable is "inaccessible" to the caller. So for example, sort :: Ord a => [a] -> [a] cannot be made into a natural transformation, because it\'s "picky" about which types we may instantiate for a. One intuitive way I often use to think of this is the following:Now, with that out of the way, let\'s tackle the clauses of the definition.The first clause is "an endofunctor, T : X -> X." Well, every Functor in Haskell is an endofunctor in what people call "the Hask category," whose objects are Haskell types (of kind *) and whose morphisms are Haskell functions. This sounds like a complicated statement, but it\'s actually a very trivial one. All it means is that that a Functor f :: * -> * gives you the means of constructing a type f a :: * for any a :: * and a function fmap f :: f a -> f b out of any f :: a -> b, and that these obey the functor laws.Second clause: the Identity functor in Haskell (which comes with the Platform, so you can just import it) is defined this way:So the natural transformation \xce\xb7 : I -> T from Tom Crockett\'s definition can be written this way for any Monad instance t:Third clause: The composition of two functors in Haskell can be defined this way (which also comes with the Platform):So the natural transformation \xce\xbc : T \xc3\x97 T -> T from Tom Crockett\'s definition can be written like this:The statement that this is a monoid in the category of endofunctors then means that Compose (partially applied to just its first two parameters) is associative, and that Identity is its identity element. I.e., that the following isomorphisms hold:These are very easy to prove because Compose and Identity are both defined as newtype, and the Haskell Reports define the semantics of newtype as an isomorphism between the type being defined and the type of the argument to the newtype\'s data constructor. So for example, let\'s prove Compose f Identity ~= f:Note: No, this isn\'t true. At some point there was a comment on this answer from Dan Piponi himself saying that the cause and effect here was exactly the opposite, that he wrote his article in response to James Iry\'s quip. But it seems to have been removed, perhaps by some compulsive tidier.Below is my original answer.It\'s quite possible that Iry had read From Monoids to Monads, a post in which Dan Piponi (sigfpe) derives monads from monoids in Haskell, with much discussion of category theory and explicit mention of "the category of endofunctors on Hask" . In any case, anyone who wonders what it means for a monad to be a monoid in the category of endofunctors might benefit from reading this derivation.