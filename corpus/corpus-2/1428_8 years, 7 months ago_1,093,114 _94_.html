I\'m looking for detailed information regarding the size of basic C++ types.\nI know that it depends on the architecture (16 bits, 32 bits, 64 bits) and the compiler.But are there any standards for C++?I\'m using Visual Studio 2008 on a 32-bit architecture. Here is what I get:I tried to find, without much success, reliable information stating the sizes of char, short, int, long, double, float (and other types I didn\'t think of) under different architectures and compilers.The C++ standard does not specify the size of integral types in bytes, but it specifies minimum ranges they must be able to hold. You can infer minimum size in bits from the required range. You can infer minimum size in bytes from that and the value of the CHAR_BIT macro that defines the number of bits in a byte (in all but the most obscure platforms it\'s 8, and it can\'t be less than 8).One additional constraint for char is that its size is always 1 byte, or CHAR_BIT bits (hence the name).Minimum ranges required by the standard (page 22) are:and Data Type Ranges on MSDN:A C++ (or C) implementation can define the size of a type in bytes sizeof(type) to any value, as long asThe actual implementation-specific ranges can be found in <limits.h> header in C, or <climits> in C++ (or even better, templated std::numeric_limits in <limits> header).For example, this is how you will find maximum range for int:C:C++:For 32-bit systems, the \'de facto\' standard is ILP32 \xe2\x80\x94 that is, int, long and pointer are all 32-bit quantities.For 64-bit systems, the primary Unix \'de facto\' standard is LP64 \xe2\x80\x94 long and pointer are 64-bit (but int is 32-bit).  The Windows 64-bit standard is LLP64 \xe2\x80\x94 long long and pointer are 64-bit (but long and int are both 32-bit).At one time, some Unix systems used an ILP64 organization.None of these de facto standards is legislated by the C standard (ISO/IEC 9899:1999), but all are permitted by it.And, by definition, sizeof(char) is 1, notwithstanding the test in the Perl configure script.Note that there were machines (Crays) where CHAR_BIT was much larger than 8.  That meant, IIRC, that sizeof(int) was also 1, because both char and int were 32-bit.In practice there\'s no such thing. You can expect std::size_t to always represent the unsigned native integer size on current architecture. i.e. 16-bit, 32-bit or 64-bit.But as far as all the other built-in types go, it really depends on the compiler. Here\'s two excerpts taken from the current working draft of the latest C++ standard:There are five standard signed integer types : signed char, short int, int, long int, and long long int. In this list, each type provides at least as much storage as those preceding it in the list.For each of the standard signed integer types, there exists a corresponding (but different) standard unsigned integer type: unsigned char, unsigned short int, unsigned int, unsigned long int, and unsigned long long int, each of which occupies the same amount of storage and has the same alignment requirements.If you want to you can statically (compile-time) assert the sizeof these fundamental types. It will alert people to think about porting your code if the sizeof assumptions change. There is standard. C90 standard requires thatC99 standard requires thatHere is the C99 specifications. Page 22 details sizes of different integral types. Here is the int type sizes (bits) for Windows platforms:If you are concerned with portability, or you want the name of the type reflects the size, you can look at the header <inttypes.h>, where the following macros are available:int8_t is guaranteed to be 8 bits, and int16_t is guaranteed to be 16 bits, etc.If you need fixed size types, use types like uint32_t (unsigned integer 32 bits) defined in stdint.h. They are specified in C99.Updated: C++11 brought the types from TR1 officially into the standard:And the "sized" types from <cstdint>Plus you get:These types represent the smallest integer types with at least the specified number of bits. Likewise there are the "fastest" integer types with at least the specified number of bits:What "fast" means, if anything, is up to the implementation. It need not be the fastest for all purposes either.The C++ Standard says it like this:3.9.1, \xc2\xa72:There are five signed integer types :\n  "signed char", "short int", "int",\n  "long int", and "long long int". In\n  this list, each type provides at least\n  as much storage as those preceding it\n  in the list. Plain ints have the\n  natural size suggested by the\n  architecture of the execution\n  environment (44); the other signed\n  integer types are provided to meet\n  special needs.(44) that is, large enough to contain\n  any value in the range of INT_MIN and\n  INT_MAX, as defined in the header\n  <climits>.The conclusion: It depends on which architecture you\'re working on. Any other assumption is false.Nope, there is no standard for type sizes. Standard only requires that:The best thing you can do if you want variables of a fixed sizes is to use macros like this:Then you can use WORD to define your variables. It\'s not that I like this but it\'s the most portable way.We are allowed to define a synonym for the type so we can create our own "standard". On a machine in which sizeof(int) == 4, we can define:So when we transfer the code to a different machine where actually the size of long int is 4, we can just redefine the single occurrence of int.For floating point numbers there is a standard (IEEE754): floats are 32 bit and doubles are 64. This is a hardware standard, not a C++ standard, so compilers could theoretically define float and double to some other size, but in practice I\'ve never seen an architecture that used anything different.There is a standard and it is specified in the various standards documents (ISO, ANSI and whatnot).Wikipedia has a great page explaining the various types and the max they may store:\nInteger in Computer Science.However even with a standard C++ compiler you can find out relatively easily using the following code snippet:Documentation for std::numeric_limits can be found at Roguewave. It includes a plethora of other commands you can call to find out the various limits. This can be used with any arbitrary type that conveys size, for example std::streamsize.John\'s answer contains the best description, as those are guaranteed to hold. No matter what platform you are on, there is another good page that goes into more detail as to how many bits each type MUST contain: int types, which are defined in the standard.I hope this helps!1) Table N1 in article "The forgotten problems of 64-bit programs development"2) "Data model"You can use:datatype = int, long int etc.\nYou will be able to see the size for whichever datatype you type.When it comes to built in types for different architectures and different compilers just run the following code on your architecture with your compiler to see what it outputs. Below shows my UbuntuÂ 13.04 (Raring Ringtail) 64 bit g++4.7.3 output. Also please note what was answered below which is why the output is ordered as such:"There are five standard signed integer types: signed char, short int, int, long int, and long long int. In this list, each type provides at least as much storage as those preceding it in the list."As mentioned the size should reflect the current architecture. You could take a peak around in limits.h if you want to see how your current compiler is handling things.If you are interested in a pure C++ solution, I made use of templates and only C++ standard code to define types at compile time based on their bit size. \nThis make the solution portable across compilers.The idea behind is very simple: Create a list containing types char, int, short, long, long long (signed and unsigned versions) and the scan the list and by the use of numeric_limits template select the type with given size.Including this header you got 8 type stdtype::int8, stdtype::int16, stdtype::int32, stdtype::int64, stdtype::uint8, stdtype::uint16, stdtype::uint32, stdtype::uint64.If some type cannot be represented it will be evaluated to stdtype::null_type also declared in that header.THE CODE BELOW IS GIVEN WITHOUT WARRANTY, PLEASE DOUBLE CHECK IT.\nI\'M NEW AT METAPROGRAMMING TOO, FEEL FREE TO EDIT AND CORRECT THIS CODE.\nTested with DevC++ (so a gcc version around 3.5)As others have answered, the "standards" all leave most of the details as "implementation defined" and only state that type "char" is at leat "char_bis" wide, and that "char <= short <= int <= long <= long long" (float and double are pretty much consistent with the IEEE floating point standards, and long double is typically same as double--but may be larger on more current implementations).Part of the reasons for not having very specific and exact values is because languages like C/C++ were designed to be portable to a large number of hardware platforms--Including computer systems in which the "char" word-size may be 4-bits or 7-bits, or even some value other than the "8-/16-/32-/64-bit" computers the average home computer user is exposed to. (Word-size here meaning how many bits wide the system normally operates on--Again, it\'s not always 8-bits as home computer users may expect.)If you really need a object (in the sense of a series of bits representing an integral value) of a specific number of bits, most compilers have some method of specifying that; But it\'s generally not portable, even between compilers made by the ame company but for different platforms. Some standards and practices (especially limits.h and the like) are common enough that most compilers will have support for determining at the best-fit type for a specific range of values, but not the number of bits used. (That is, if you know you need to hold values between 0 and 127, you can determine that your compiler supports an "int8" type of 8-bits which will be large enought to hold the full range desired, but not something like an "int7" type which would be an exact match for 7-bits.)Note: Many Un*x source packages used "./configure" script which will probe the compiler/system\'s capabilities and output a suitable Makefile and config.h. You might examine some of these scripts to see how they work and how they probe the comiler/system capabilities, and follow their lead.I notice that all the other answers here have focused almost exclusively on integral types, while the questioner also asked about floating-points.I don\'t think the C++ standard requires it, but compilers for the most common platforms these days generally follow the IEEE754 standard for their floating-point numbers. This standard specifies four types of binary floating-point (as well as some BCD formats, which I\'ve never seen support for in C++ compilers):How does this map onto C++ types, then? Generally the float uses single precision; thus, sizeof(float) = 4. Then double uses double precision (I believe that\'s the source of the name double), and long double may be either double or quadruple precision (it\'s quadruple on my system, but on 32-bit systems it may be double). I don\'t know of any compilers that offer half precision floating-points.In summary, this is the usual:where X is a char,int,long etc.. will give you size of X in bits.From Alex B The C++ standard does not specify the size of integral types in bytes, but it specifies minimum ranges they must be able to hold. You can infer minimum size in bits from the required range. You can infer minimum size in bytes from that and the value of the CHAR_BIT macro that defines the number of bits in a byte (in all but the most obscure platforms it\'s 8, and it can\'t be less than 8).One additional constraint for char is that its size is always 1 byte, or CHAR_BIT bits (hence the name).Minimum ranges required by the standard (page 22) are:and Data Type Ranges on MSDN:signed char: -127 to 127 (note, not -128 to 127; this accommodates 1\'s-complement platforms)\nunsigned char: 0 to 255\n"plain" char: -127 to 127 or 0 to 255 (depends on default char signedness)\nsigned short: -32767 to 32767\nunsigned short: 0 to 65535\nsigned int: -32767 to 32767\nunsigned int: 0 to 65535\nsigned long: -2147483647 to 2147483647\nunsigned long: 0 to 4294967295\nsigned long long: -9223372036854775807 to 9223372036854775807\nunsigned long long: 0 to 18446744073709551615\nA C++ (or C) implementation can define the size of a type in bytes sizeof(type) to any value, as long asthe expression sizeof(type) * CHAR_BIT evaluates to the number of bits enough to contain required ranges, and\nthe ordering of type is still valid (e.g. sizeof(int) <= sizeof(long)).\nThe actual implementation-specific ranges can be found in  header in C, or  in C++ (or even better, templated std::numeric_limits in  header).For example, this is how you will find maximum range for int:C:C++:This is correct, however, you were also right in saying that:\nchar   : 1 byte\nshort  : 2 bytes\nint    : 4 bytes\nlong   : 4 bytes\nfloat  : 4 bytes\ndouble : 8 bytesBecause 32 bit architectures are still the default and most used, and they have kept these standard sizes since the pre-32 bit days when memory was less available, and for backwards compatibility and standardization it remained the same. Even 64 bit systems tend to use these and have extentions/modifications.\nPlease reference this for more information:http://en.cppreference.com/w/cpp/language/typesAs you mentioned - it largely depends upon the compiler and the platform. For this, check the ANSI standard, http://home.att.net/~jackklein/c/inttypes.htmlHere is the one for the Microsoft compiler: Data Type Ranges.You can use variables provided by libraries such as OpenGL, Qt, etc.For example, Qt provides qint8 (guaranteed to be 8-bit on all platforms supported by Qt), qint16, qint32, qint64, quint8, quint16, quint32, quint64, etc.On a 64-bit machine: There are four types of integers based on size: