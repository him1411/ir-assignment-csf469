If a picture\'s worth 1000 words, how much of a picture can you fit in 140 characters?Note: That\'s it folks! Bounty deadline is here, and after some tough deliberation, I have decided that Boojum\'s entry just barely edged out Sam Hocevar\'s. I will post more detailed notes once I\'ve had a chance to write them up. Of course, everyone should feel free to continue to submit solutions and improve solutions for people to vote on. Thank you to everyone who submitted and entry; I enjoyed all of them. This has been a lot of fun for me to run, and I hope it\'s been fun for both the entrants and the spectators.I came across this interesting post about trying to compress images into a Twitter comment, and lots of people in that thread (and a thread on Reddit) had suggestions about different ways you could do it. So, I figure it would make a good coding challenge; let people put their money where their mouth is, and show how their ideas about encoding can lead to more detail in the limited space that you have available.I challenge you to come up with a general purpose system for encoding images into 140 character Twitter messages, and decoding them into an image again. You can use Unicode characters, so you get more than 8 bits per character. Even allowing for Unicode characters, however, you will need to compress images into a very small amount of space; this will certainly be a lossy compression, and so there will have to be subjective judgements about how good each result looks.Here is the result that the original author, Quasimondo, got from his encoding (image is licensed under a Creative Commons Attribution-Noncommercial license):\nCan you do better?For the sake of consistency in user interface, your program must behave as follows:Your program must take input in one or more of the following ways (if you implement the one that takes file names, you may also read and write from stdin and stdout if file names are missing):Take input from standard in and produce output on standard out.Take input from a file named in the second argument, and produce output in the file named in the third.These are basically rules that may be broken, suggestions, or scoring criteria:As a general guide to how I will be ranking solutions when choosing my accepted solution, lets say that I\'ll probably be evaluating solutions on a 25 point scale (this is very rough, and I won\'t be scoring anything directly, just using this as a basic guideline):Some folks have asked for some reference images. Here are a few reference images that you can try; smaller versions are embedded here, they all link to larger versions of the image if you need those:\n\n\nI am offering a 500 rep bounty (plus the 50 that StackOverflow kicks in) for the solution that I like the best, based on the above criteria. Of course, I encourage everyone else to vote on their favorite solutions here as well.This contest will run until the bounty runs out, about 6 PM on Saturday, May 30. I can\'t say the precise time it will end; it may be anywhere from 5 to 7 PM. I will guarantee that I\'ll look at all entries submitted by 2 PM, and I will do my best to look at all entries submitted by 4 PM; if solutions are submitted after that, I may not have a chance to give them a fair look before I have to make my decision. Also, the earlier you submit, the more chance you will have for voting to be able to help me pick the best solution, so try and submit earlier rather than right at the deadline.There has also been some confusion on exactly what Unicode characters are allowed. The range of possible Unicode code points is U+0000 to U+10FFFF. There are some code points which are never valid to use as Unicode characters in any open interchange of data; these are the noncharacters and the surrogate code points. Noncharacters are defined in the Unidode Standard 5.1.0 section 16.7 as the values U+FFFE, U+FFFF, U+nFFFE, U+nFFFF where n is 1\xe2\x80\x9310 hexadecimal, and the range U+FDD0\xe2\x80\x93U+FDEF. These values are intended to be used for application-specific internal usage, and conforming applications may strip these characters out of text processed by them. Surrogate code points, defined in the Unicode Standard 5.1.0 section 3.8 as U+D800\xe2\x80\x93U+DFFF, are used for encoding characters beyond the Basic Multilingual Plane in UTF-16; thus, it is impossible to represent these code points directly in the UTF-16 encoding, and it is invalid to encode them in any other encoding. Thus, for the purpose of this contest, I will allow any program which encodes images into a sequence of no more than 140 Unicode code points from the range U+0000\xe2\x80\x93U+10FFFF, excluding all noncharacters and surrogate pairs as defined above.I will prefer solutions that use only assigned characters, and even better ones that use clever subsets of assigned characters or do something interesting with the character set they use. For a list of assigned characters, see the Unicode Character Database; note that some characters are listed directly, while some are listed only as the start and end of a range. Also note that surrogate code points are listed in the database, but forbidden as mentioned above. If you would like to take advantage of certain properties of characters for making the text you output more interesting, there are a variety of databases of character information available, such as a list of named code blocks and various character properties.Since Twitter does not specify the exact character set they support, I will be lenient about solutions which do not actually work with Twitter because certain characters count extra or certain characters are stripped. It is preferred but not required that all encoded outputs should be able to be transferred unharmed via Twitter or another microblogging service such as identi.ca. I have seen some documentation stating that Twitter entity-encodes <, >, and &, and thus counts those as 4, 4, and 5 characters respectively, but I have not tested that out myself, and their JavaScript character counter doesn\'t seem to count them that way.Alright, here\'s mine: nanocrunch.cpp and the CMakeLists.txt file to build it using CMake.  It relies on the Magick++ ImageMagick API for most of its image handling.  It also requires the GMP library for bignum arithmetic for its string encoding.I based my solution off of fractal image compression, with a few unique twists.  The basic idea is to take the image, scale down a copy to 50% and look for pieces in various orientations that look similar to non-overlapping blocks in the original image.  It takes a very brute force approach to this search, but that just makes it easier to introduce my modifications.The first modification is that instead of just looking at ninety degree rotations and flips, my program also considers 45 degree orientations.  It\'s one more bit per block, but it helps the image quality immensely.The other thing is that storing a contrast/brightness adjustment for each of color component of each block is way too expensive.  Instead, I store a heavily quantized color (the palette has only 4 * 4 * 4 = 64 colors) that simply gets blended in in some proportion.  Mathematically, this is equivalent to a variable brightness and constant contrast adjustment for each color.  Unfortunately, it also means there\'s no negative contrast to flip the colors.Once it\'s computed the position, orientation and color for each block, it encodes this into a UTF-8 string.  First, it generates a very large bignum to represent the data in the block table and the image size.  The approach to this is similar to Sam Hocevar\'s solution -- kind of a large number with a radix that varies by position.Then it converts that into a base of whatever the size of the character set available is.  By default, it makes full use of the assigned unicode character set, minus the less than, greater than, ampersand, control, combining, and surrogate and private characters.  It\'s not pretty but it works.  You can also comment out the default table and select printable 7-bit ASCII (again excluding <, >, and & characters) or CJK Unified Ideographs instead.  The table of which character codes are available is stored a run-length encoded with alternating runs of invalid and valid characters.Anyway, here are some images and times (as measured on my old 3.0GHz P4), and compressed to 140 characters in the full assigned unicode set described above.  Overall, I\'m fairly pleased with how they all turned out.  If I had more time to work on this, I\'d probably try to reduce the blockiness of the decompressed images.  Still, I think the results are pretty good for the extreme compression ratio.  The decompressed images are bit impressionistic, but I find it relatively easy to see how bits correspond to the original.  Stack Overflow Logo (8.6s to encode, 7.9s to decode, 485 bytes):\n http://i44.tinypic.com/2w7lok1.pngLena (32.8s to encode, 13.0s to decode, 477 bytes):\nhttp://i42.tinypic.com/2rr49wg.png http://i40.tinypic.com/2rhxxyu.pngMona Lisa (43.2s to encode, 14.5s to decode, 490 bytes):\nhttp://i41.tinypic.com/ekgwp3.png http://i43.tinypic.com/ngsxep.pngEdit: CJK Unified CharactersSam asked in the comments about using this with CJK.  Here\'s a version of the Mona Lisa compressed to 139 characters from the CJK Unified character set:http://i43.tinypic.com/2yxgdfk.png\n\xe5\x92\x8f\xe7\x92\x98\xe9\xa9\x9e\xe5\x87\x84\xe8\x84\x92\xe9\xb5\x9a\xe6\x8d\xae\xe8\x9b\xa5\xe9\xb8\x82\xe6\x8b\x97\xe6\x9c\x90\xe6\x9c\x96\xe8\xbe\xbf\xe9\x9f\xa9\xe7\x80\xa6\xe9\xad\xb7\xe6\xad\xaa\xe7\x97\xab\xe6\xa0\x98\xe7\x92\xaf\xe7\xb7\x8d\xe8\x84\xb2\xe8\x95\x9c\xe6\x8a\xb1\xe6\x8f\x8e\xe9\xa0\xbb\xe8\x93\xbc\xe5\x82\xb5\xe9\x91\xa1\xe5\x97\x9e\xe9\x9d\x8a\xe5\xaf\x9e\xe6\x9f\xae\xe5\x9a\x9b\xe5\x9a\xb5\xe7\xb1\xa5\xe8\x81\x9a\xe9\x9a\xa4\xe6\x85\x9b\xe7\xb5\x96\xe9\x8a\x93\xe9\xa6\xbf\xe6\xb8\xab\xe6\xab\xb0\xe7\x9f\x8d\xe6\x98\x80\xe9\xb0\x9b\xe6\x8e\xbe\xe6\x92\x84\xe7\xb2\x82\xe6\x95\xbd\xe7\x89\x99\xe7\xa8\x89\xe6\x93\x8e\xe8\x94\x8d\xe8\x9e\x8e\xe8\x91\x99\xe5\xb3\xac\xe8\xa6\xa7\xe7\xb5\x80\xe8\xb9\x94\xe6\x8a\x86\xe6\x83\xab\xe5\x86\xa7\xe7\xac\xbb\xe5\x93\x9c\xe6\x90\x80\xe6\xbe\x90\xe8\x8a\xaf\xe8\xad\xb6\xe8\xbe\x8d\xe6\xbe\xae\xe5\x9e\x9d\xe9\xbb\x9f\xe5\x81\x9e\xe5\xaa\x84\xe7\xab\xa5\xe7\xab\xbd\xe6\xa2\x80\xe9\x9f\xa0\xe9\x95\xb0\xe7\x8c\xb3\xe9\x96\xba\xe7\x8b\x8c\xe8\x80\x8c\xe7\xbe\xb6\xe5\x96\x99\xe4\xbc\x86\xe6\x9d\x87\xe5\xa9\xa3\xe5\x94\x86\xe9\x90\xa4\xe8\xab\xbd\xe9\xb7\x8d\xe9\xb4\x9e\xe9\xa7\xab\xe6\x90\xb6\xe6\xaf\xa4\xe5\x9f\x99\xe8\xaa\x96\xe8\x90\x9c\xe6\x84\xbf\xe6\x97\x96\xe9\x9e\xb0\xe8\x90\x97\xe5\x8b\xb9\xe9\x88\xb1\xe5\x93\xb3\xe5\x9e\xac\xe6\xbf\x85\xe9\xac\x92\xe7\xa7\x80\xe7\x9e\x9b\xe6\xb4\x86\xe8\xae\xa4\xe6\xb0\x97\xe7\x8b\x8b\xe7\x95\xb0\xe9\x97\xa5\xe7\xb1\xb4\xe7\x8f\xb5\xe4\xbb\xbe\xe6\xb0\x99\xe7\x86\x9c\xe8\xac\x8b\xe7\xb9\xb4\xe8\x8c\xb4\xe6\x99\x8b\xe9\xab\xad\xe6\x9d\x8d\xe5\x9a\x96\xe7\x86\xa5\xe5\x8b\xb3\xe7\xb8\xbf\xe9\xa4\x85\xe7\x8f\x9d\xe7\x88\xb8\xe6\x93\xb8\xe8\x90\xbfThe tuning parameters at the top of the program that I used for this were: 19, 19, 4, 4, 3, 10, 11, 1000, 1000.  I also commented out the first definition of number_assigned and codes, and uncommented out the last definitions of them to select the CJK Unified character set.image files and python source (version 1 and 2)Version 1\nHere is my first attempt. I will update as I go.I have got the SO logo down to 300 characters almost lossless. My technique uses conversion to SVG vector art so it works best on line art. It is actually an SVG compressor, it still requires the original art go through a vectorisation stage. For my first attempt I used an online service for the PNG trace however there are MANY free and non-free tools that can handle this part including potrace (open-source).Here are the resultsOriginal SO Logo http://www.warriorhut.org/graphics/svg_to_unicode/so-logo.png Original\nDecoded SO Logo http://www.warriorhut.org/graphics/svg_to_unicode/so-logo-decoded.png After encoding and decodingCharacters: 300Time: Not measured but practically instant (not including vectorisation/rasterisation steps)The next stage will be to embed 4 symbols (SVG path points and commands) per unicode character. At the moment my python build does not have wide character support UCS4 which limits my resolution per character. I\'ve also limited the maximum range to the lower end of the unicode reserved range 0xD800 however once I build a list of allowed characters and a filter to avoid them I can theoretically push the required number of characters as low as 70-100 for the logo above.A limitation of this method at present is the output size is not fixed. It depends on number of vector nodes/points after vectorisation. Automating this limit will require either pixelating the image (which removes the main benefit of vectors) or repeated running the paths through a simplification stage until the desired node count is reached (which I\'m currently doing manually in Inkscape).Version 2UPDATE: v2 is now qualified to compete. Changes:Characters: 133Time: A few secondsv2 decoded http://www.warriorhut.org/graphics/svg_to_unicode/so-logo-decoded-v2.png After encoding and decoding (version 2)As you can see there are some artifacts this time. It isn\'t a limitation of the method but a mistake somewhere in my conversions. The artifacts happen when the points go outside the range 0.0 - 127.0 and my attempts to constrain them have had mixed success. The solution is simply to scale the image down however I had trouble scaling the actual points rather than the artboard or group matrix and I\'m too tired now to care. In short, if your points are in the supported range it generally works.I believe the kink in the middle is due to a handle moving to the other side of a handle it\'s linked to. Basically the points are too close together in the first place. Running a simplify filter over the source image in advance of compressing it should fix this and shave of some unnecessary characters.UPDATE:\nThis method is fine for simple objects so I needed a way to simplify complex paths and reduce noise. I used Inkscape for this task. I\'ve had some luck with grooming out unnecessary paths using Inkscape but not had time to try automating it. I\'ve made some sample svgs using the Inkscape \'Simplify\' function to reduce the number of paths.Simplify works ok but it can be slow with this many paths.autotrace example http://www.warriorhut.org/graphics/svg_to_unicode/autotrace_16_color_manual_reduction.png cornell box http://www.warriorhut.com/graphics/svg_to_unicode/cornell_box_simplified.png lena http://www.warriorhut.com/graphics/svg_to_unicode/lena_std_washed_autotrace.pngthumbnails traced http://www.warriorhut.org/graphics/svg_to_unicode/competition_thumbnails_autotrace.pngHere\'s some ultra low-res shots. These would be closer to the 140 character limit though some clever path compression may be need as well.groomed http://www.warriorhut.org/graphics/svg_to_unicode/competition_thumbnails_groomed.png\nSimplified and despeckled.trianglulated http://www.warriorhut.org/graphics/svg_to_unicode/competition_thumbnails_triangulated.png\nSimplified, despeckled and triangulated.ABOVE: Simplified paths using autotrace. Unfortunately my parser doesn\'t handle the autotrace output so I don\'t know how may points are in use or how far to simplify, sadly there\'s little time for writing it before the deadline. It\'s much easier to parse than the inkscape output though.My full solution can be found at http://caca.zoy.org/wiki/img2twit. It has the following features:http://caca.zoy.org/raw-attachment/wiki/img2twit/so-logo.png\n  http://caca.zoy.org/raw-attachment/wiki/img2twit/twitter4.png\xe8\x9c\xa5\xe7\xa7\x93\xe9\x8b\x96\xe7\xad\xb7\xe8\x81\x9d\xe8\xaf\xbf\xe7\xbc\xb0\xe5\x81\xba\xe8\x85\xb6\xe6\xbc\xb7\xe5\xba\xaf\xe7\xa5\xa9\xe7\x9a\x99\xe9\x9d\x8a\xe8\xb0\xaa\xe7\x8d\x9c\xe5\xb2\xa8\xe5\xb9\xbb\xe5\xaf\xa4\xe5\x8e\x8e\xe8\xb6\x86\xe8\x84\x98\xe6\x90\x87\xe6\xa2\x84\xe8\xb8\xa5\xe6\xa1\xbb\xe7\x90\x86\xe6\x88\x82\xe6\xba\xa5\xe6\xac\x87\xe6\xb8\xb9\xe8\xa3\x8f\xe8\xbb\xb1\xe9\xaa\xbf\xe8\x8b\xb8\xe9\xab\x99\xe9\xaa\x9f\xe5\xb8\x82\xe7\xb0\xb6\xe7\x92\xa8\xe7\xb2\xad\xe6\xb5\xa7\xe9\xb1\x89\xe6\x8d\x95\xe5\xbc\xab\xe6\xbd\xae\xe8\xa1\x8d\xe8\x9a\x99\xe7\x80\xb9\xe5\xb2\x9a\xe7\x8e\xa7\xe9\x9c\xab\xe9\x8f\x93\xe8\x93\x95\xe6\x88\xb2\xe5\x82\xb5\xe9\xbc\xb6\xe8\xa5\x8b\xe8\xba\xbb\xe5\xbc\xaf\xe8\xa2\xae\xe8\xb6\xb3\xe5\xba\xad\xe4\xbe\x85\xe6\x97\x8d\xe5\x87\xbc\xe9\xa3\x99\xe9\xa9\x85\xe6\x93\x9a\xe5\x98\x9b\xe6\x8e\x94\xe5\x80\xbe\xe8\xaf\x97\xe7\xb1\x82\xe9\x98\x89\xe5\xb6\xb9\xe5\xa9\xbb\xe6\xa4\xbf\xe7\xb3\xa2\xe5\xa2\xa4\xe6\xb8\xbd\xe7\xb7\x9b\xe8\xb5\x90\xe6\x9b\xb4\xe5\x84\x85\xe6\xa3\xab\xe6\xad\xa6\xe5\xa9\xa9\xe7\xb8\x91\xe9\x80\xa1\xe8\x8d\xa8\xe7\x92\x99\xe6\x9d\xaf\xe7\xbf\x89\xe7\x8f\xb8\xe9\xbd\xb8\xe9\x99\x81\xe9\xa2\x97\xe9\xb3\xa3\xe6\x86\xab\xe6\x93\xb2\xe8\x88\xa5\xe6\x94\xa9\xe5\xaf\x89\xe9\x88\xb6\xe5\x85\x93\xe5\xba\xad\xe7\x92\xb1\xe7\xaf\x82\xe9\xb0\x80\xe4\xb9\xbe\xe4\xb8\x95\xe8\x80\x93\xe5\xba\x81\xe9\x8c\xb8\xe5\x8a\xaa\xe6\xa8\x80\xe8\x82\x9d\xe4\xba\x96\xe5\xbc\x9c\xe5\x96\x86\xe8\x9d\x9e\xe8\xba\x90\xe8\x91\x8c\xe7\x86\xb2\xe8\xb0\x8e\xe8\x9b\xaa\xe6\x9b\x9f\xe6\x9a\x99\xe5\x88\x8d\xe9\x95\xb6\xe5\xaa\x8f\xe5\x98\x9d\xe9\xa9\x8c\xe6\x85\xb8\xe7\x9b\x82\xe6\xb0\xa4\xe7\xbc\xb0\xe6\xae\xbe\xe8\xad\x91 Here is a rough overview of the encoding process:And this is the decoding process:What I believe is the most original part of the program is the bitstream. Instead of packing bit-aligned values (stream <<= shift; stream |= value), I pack arbitrary values that are not in power-of-two ranges (stream *= range; stream += value). This requires bignum computations and is of course a lot slower, but it gives me 2009.18 bits instead of 1960 when using the 20902 main CJK characters (that\'s three more points I can put in the data). And when using ASCII, it gives me 917.64 bits instead of 840.I decided against a method for the initial image computation that would have required heavy weaponry (corner detection, feature extraction, colour quantisation...) because I wasn\'t sure at first it would really help. Now I realise convergence is slow (1 minute is acceptable but it\'s slow nonetheless) and I may try to improve on that.The main fitting loop is loosely inspired from the Direct Binary Seach dithering algorithm (where pixels are randomly swapped or flipped until a better halftone is obtained). The energy computation is a simple root-mean-square distance, but I perform a 5x5 median filter on the original image first. A Gaussian blur would probably better represent the human eye behaviour, but I didn\'t want to lose sharp edges. I also decided against simulated annealing or other difficult to tune methods because I don\'t have months to calibrate the process. Thus the "quality" flag just represents the number of iterations that are performed on each point before the encoder ends.http://caca.zoy.org/raw-attachment/wiki/img2twit/Mona_Lisa_scaled.jpg\n  http://caca.zoy.org/raw-attachment/wiki/img2twit/twitter2.png\xe8\x8b\x89\xe6\x86\x97\xe6\x8f\xa3\xe5\xb6\x95\xe7\xb9\xa0\xe5\x89\xb3\xe8\x85\x8f\xe7\xaf\xae\xe6\xbf\x95\xe8\x8c\x9d\xe9\x9c\xae\xe5\xa2\xa7\xe8\x92\x86\xe6\xa3\x8c\xe6\x9d\x9a\xe8\x93\xb3\xe7\xb8\xb3\xe6\xa8\x9f\xe8\xb5\x92\xe8\x82\xb4\xe9\xa3\x97\xe5\x99\xb9\xe7\xa0\x83\xe7\x87\x8b\xe4\xbb\xbb\xe6\x9c\x93\xe5\xb3\x82\xe9\x87\xb0\xe9\x9d\x82\xe9\x99\xb4\xe8\xb2\x9c\xe7\x8a\x9f\xe6\x8e\x9d\xe5\x96\x97\xe8\xae\x84\xe8\x8d\x9b\xe7\xa0\x99\xe7\x9f\xba\xe6\x95\xa8\xe9\xb7\xbe\xe7\x93\x94\xe4\xba\xa8\xe9\xab\x8e\xe8\x8a\x9f\xe6\xb0\xb2\xe7\xb0\xb5\xe9\xb8\xac\xe5\xab\xa4\xe9\x89\xb8\xe4\xbf\x87\xe6\xbf\x80\xe8\xba\x99\xe6\x86\xae\xe9\x84\xb4\xe7\x94\xae\xe6\xa7\xba\xe9\xaa\xb3\xe4\xbd\x9b\xe6\x84\x9a\xe7\x8c\xaa\xe9\xa7\xaa\xe6\x83\xbe\xe5\xab\xa5\xe7\xb6\x96\xe7\x8f\x8f\xe7\x9f\xaf\xe5\x9d\xbc\xe5\xa0\xad\xe9\xa2\xbd\xe7\xae\xbd\xe8\xb5\xad\xe9\xa3\x89\xe8\xa8\xa5\xe5\x81\x81\xe7\xae\x9d\xe7\xaa\x82\xe8\xb9\xbb\xe7\x86\x9b\xe6\xbc\xa7\xe8\xa1\x86\xe6\xa9\xbc\xe6\x84\x80\xe8\x88\xaa\xe7\x8e\xb4\xe6\xaf\xa1\xe8\xa3\x8b\xe9\xa0\xa2\xe7\xbe\x94\xe6\x81\xba\xe5\xa2\x8e\xe5\xac\x94\xe9\x91\xb9\xe6\xa5\x84\xe7\x91\xa5\xe9\xb6\xbc\xe5\x91\x8d\xe8\x95\x96\xe6\x8a\xb2\xe9\xb8\x9d\xe7\xa7\x93\xe8\x8b\xbe\xe7\xbb\x92\xe9\x85\xaf\xe5\xb5\x9e\xe8\x84\x94\xe5\xa9\xba\xe6\xb1\xa1\xe5\x9b\x89\xe9\x85\xbc\xe4\xbf\xb5\xe8\x8f\x9b\xe7\x90\xaa\xe6\xa3\xba\xe5\x88\x99\xe8\xbe\xa9\xe6\x9b\x9a\xe9\xb8\xb8\xe8\x81\xb7\xe9\x8a\x9b\xe8\x92\x9d\xe7\xa4\xad\xe9\xb1\x9a\xe8\x9f\xba\xe7\xa8\xbf\xe7\xba\xa1\xe9\x86\xbe\xe9\x99\xb4\xe9\xb3\xa3\xe5\xb0\xa5\xe8\x9f\x80\xe6\x83\x98\xe9\x8b\x81\xe9\xab\x9a\xe5\xbf\xa9\xe7\xa5\xa4\xe8\x84\xa4\xe5\x85\xbb\xe8\xb6\xaf\xe6\xb2\x85\xe5\x86\xb5Even though not all images compress well, I\'m surprised by the results and I really wonder what other methods exist that can compress an image to 250 bytes.I also have small movies of the encoder state\'s evolution from a random initial state and from a "good" initial state.Edit: here is how the compression method compares with JPEG. On the left, jamoes\'s above 536-byte picture. On the right, Mona Lisa compressed down to 534 bytes using the method described here (the bytes mentioned here refer to data bytes, therefore ignoring bits wasted by using Unicode characters):http://caca.zoy.org/raw-attachment/wiki/img2twit/minimona.jpg\n  http://caca.zoy.org/raw-attachment/wiki/img2twit/minimona2.pngEdit: just replaced CJK text with the newest versions of the images.The following isn\'t a formal submission, since my software hasn\'t been tailored in any way for the indicated task.  DLI can be described as an optimizing general purpose lossy image codec.  It\'s the PSNR and MS-SSIM record holder for image compression, and I thought it would be interesting to see how it performs for this particular task.  I used the reference Mona Lisa image provided and scaled it down to 100x150 then used DLI to compress it to 344 bytes.Mona Lisa DLI http://i40.tinypic.com/2md5q4m.pngFor comparison with the JPEG and IMG2TWIT compressed samples, I used DLI to compress the image to 534 bytes as well.  The JPEG is 536 bytes and IMG2TWIT is 534 bytes.  Images have been scaled up to approximately the same size for easy comparison.  JPEG is the left image, IMG2TWIT is center, and DLI is the right image.Comparison http://i42.tinypic.com/302yjdg.pngThe DLI image manages to preserve some of the facial features, most notably the famous smile :).The general overview of my solution would be:I know that you were asking for code, but I don\'t really want to spend the time to actually code this up. I figured that an efficient design might at least inspire someone else to code this up.I think the major benefit of my proposed solution is that it is reusing as much existing technology as possible. It may be fun to try to write a good compression algorithm, but there is guaranteed to be a better algorithm out there, most likely written by people who have a degree in higher math.One other important note though is that if it is decided that utf16 is the preferred encoding, then this solution falls apart. jpegs don\'t really work when compressed down to 280 bytes. Although, maybe there is a better compression algorithm than jpg for this specific problem statement.Okay, I\'m late to the game, but nevertheless I made my project.It\'s a toy genetic algorithm that uses translucent colorful circles to recreate the initial image.Features:Mis-feautres:Here\'s an example twit that represents Lena:\n\xe7\x8a\xad\xe6\xa5\x8a\xe8\xb0\xb7\xe6\x9d\x8c\xe8\x92\x9d\xe8\x9e\xa6\xe7\x95\x8c\xe5\x8c\x98\xe7\x8e\x8f\xe6\x89\x9d\xe5\x8c\xae\xe4\xbf\x84\xe5\xbd\x92\xe6\x99\x83\xe5\xae\xa2\xe7\x8c\x98\xe6\x91\x88\xe7\xa1\xb0\xe5\x88\x92\xe5\x88\x80\xe8\x90\x95\xe7\xa0\x81\xe6\x91\x83\xe6\x96\xa2\xe5\x98\x81\xe8\x9c\x81\xe5\x9a\x8e\xe8\x80\x82\xe6\xbe\xb9\xe7\xb0\x9c\xe5\x83\xa8\xe7\xa0\xa0\xe5\x81\x91\xe5\xa9\x8a\xe5\x85\xa7\xe5\x9c\x98\xe6\x8f\x95\xe5\xbf\x88\xe7\xbe\xa9\xe5\x80\xa8\xe8\xa5\xa0\xe5\x87\x81\xe6\xa2\xa1\xe5\xb2\x82\xe6\x8e\x82\xe6\x88\x87\xe8\x80\x94\xe6\x94\x8b\xe6\x96\x98\xe7\x9c\x90\xe5\xa5\xa1\xe8\x90\x9b\xe7\x8b\x82\xe6\x98\xb8\xe7\xae\x86\xe4\xba\xb2\xe5\xac\x8e\xe5\xbb\x99\xe6\xa0\x83\xe5\x85\xa1\xe5\xa1\x85\xe5\x8f\x97\xe6\xa9\xaf\xe6\x81\xb0\xe5\xba\x94\xe6\x88\x9e\xe4\xbc\x98\xe7\x8c\xab\xe5\x83\x98\xe7\x91\xa9\xe5\x90\xb1\xe8\xb3\xbe\xe5\x8d\xa3\xe6\x9c\xb8\xe6\x9d\x88\xe8\x85\xa0\xe7\xb6\x8d\xe8\x9d\x98\xe7\x8c\x95\xe5\xb1\x90\xe7\xa8\xb1\xe6\x82\xa1\xe8\xa9\xac\xe4\xbe\x86\xe5\x99\xa9\xe5\x8e\x8b\xe7\xbd\x8d\xe5\xb0\x95\xe7\x86\x9a\xe5\xb8\xa4\xe5\x8e\xa5\xe8\x99\xa4\xe5\xab\x90\xe8\x99\xb2\xe5\x85\x99\xe7\xbd\xa8\xe7\xb8\xa8\xe7\x82\x98\xe6\x8e\x92\xe5\x8f\x81\xe6\x8a\xa0\xe5\xa0\x83\xe5\xbe\x9e\xe5\xbc\x85\xe6\x85\x8c\xe8\x9e\x8e\xe7\x86\xb0\xe6\xa8\x99\xe5\xae\x91\xe7\xb0\xab\xe6\x9f\xa2\xe6\xa9\x99\xe6\x8b\x83\xe4\xb8\xa8\xe8\x9c\x8a\xe7\xbc\xa9\xe6\x98\x94\xe5\x84\xbb\xe8\x88\xad\xe5\x8b\xb5\xe7\x99\xb3\xe5\x86\x82\xe5\x9b\xa4\xe7\x92\x9f\xe5\xbd\x94\xe6\xa6\x95\xe5\x85\xa0\xe6\x91\x88\xe4\xbe\x91\xe8\x92\x96\xe5\xad\x82\xe5\x9f\xae\xe6\xa7\x83\xe5\xa7\xa0\xe7\x92\x90\xe5\x93\xa0\xe7\x9c\x9b\xe5\xab\xa1\xe7\x90\xa0\xe6\x9e\x80\xe8\xa8\x9c\xe8\x8b\x84\xe6\x9a\xac\xe5\x8e\x87\xe5\xbb\xa9\xe7\x84\x9b\xe7\x80\xbb\xe4\xb8\xa5\xe5\x95\x98\xe5\x88\xb1\xe5\x9e\xab\xe4\xbb\x94 The code is in a Mercurial repository at bitbucket.org. Check out http://bitbucket.org/tkadlubo/circles.luaThe following is my approach to the problem and I must admit that this was quite an interesting project to work on, it is definitely outside of my normal realm of work and has given me a something new to learn about. The basic idea behind mine is as follows:It turns out that this does work, but only to a limited extent as you can see from the sample images below. In terms of output, what follows is a sample tweet, specifically for the Lena image shown in the samples.\xe4\xb9\xa4\xe4\xb9\xa4\xe4\xb8\x87\xe4\xb9\x90\xe5\x94\x82\xe4\xbc\x82\xe5\x80\x82\xe5\x80\x81\xe4\xbc\x81\xe5\x84\x822\xe4\xbc\x81\xe5\x80\x813\xe4\xbc\x81\xe5\x80\x812\xe4\xbc\x81\xe4\xbc\x828\xe4\xbc\x81\xe4\xbc\x823\xe4\xbc\x81\xe4\xbc\x825\xe4\xbc\x81\xe5\x80\x82\xe5\x80\x83\xe4\xbc\x82\xe5\x80\x813\xe4\xbc\x81\xe5\x84\x81\xe4\xbc\x812\xe4\xbc\x82\xe5\x80\x835\xe4\xbc\x81\xe5\x80\x813\xe4\xbc\x81\xe5\x80\x834\xe4\xbc\x81\xe5\x80\x82\xe4\xbc\x81\xe5\x80\x81\xe4\xbc\x81\xe4\xbc\x822\xe4\xbc\x81\xe4\xbc\x825\xe4\xbc\x81\xe5\x80\x81\xe4\xbc\x81\xe4\xbc\x82\xec\xa5\xb9\xe7\x9a\x97\xe9\x9e\xb9\xe9\x90\xbe\xeb\xa5\xb6\xe4\xa6\xbd\xe9\x98\xb9\xeb\x9f\x86\xe4\xa7\x9c\xe6\xa4\xbf\xe7\xb1\xab\xeb\xa6\xb9\xe9\x9d\xad\xec\x9a\xb6\xec\x98\xb7\xeb\x8e\xb7\xe6\xad\xa9\xe3\xb0\xb7\xe6\xad\x89\xe4\xb4\x97\xe9\x91\xb9\xe3\x9e\xb3\xe9\x9e\xb7\xe3\xac\xbc\xe7\x8d\xb4\xe9\x8f\x99\xeb\x8f\x97\xe9\x8d\xb4\xe7\xa5\xb3\xe3\xad\xbe\xeb\xa4\xb6\xe6\xae\x9e\xe7\x84\xbb\xef\xbf\xbd\xe4\xb9\xb9\xe1\x8f\x8b\xe9\x9d\x86\xe4\x8d\xbcAs you can see, I did try and constrain the character set a  bit; however, I ran into issues doing this when storing the image color data. Also, this encoding scheme also tends to waste a bunch of bits of data that could be used for additional image information.In terms of run times, for small images the code is extremely fast, about 55ms for the sample images provided, but the time does increase with larger images. For the 512x512 Lena reference image the running time was 1182ms. I should note that the odds are pretty good that the code itself isn\'t very optimized for performance (e.g. everything is worked with as a Bitmap) so the times could go down a bit after some refactoring.Please feel free to offer me any suggestions on what I could have done better or what might be wrong with the code. The full listing of run times and sample output can be found at the following location: http://code-zen.info/twitterimage/Update OneI\'ve updated the the RLE code used when compressing the tweet string to do a basic look back and if so so use that for the output. This only works for the number value pairs, but it does save a couple of characters of data. The running time is more or less the same as well as the image quality, but the tweets tend to be a bit smaller. I will update the chart on the website as I complete the testing. What follows is one of the example tweet strings, again for the small version of Lena:\xe4\xb9\xa4\xe4\xb9\xa4\xe4\xb8\x87\xe4\xb9\x90\xe5\x94\x82\xe4\xbc\x82\xe5\x80\x82\xe5\x80\x81\xe4\xbc\x81\xe5\x84\x822\xe4\xbc\x81\xe5\x80\x813\xe4\xbc\x81\xe5\x80\x81\xe3\x82\xa6\xe4\xbc\x828\xe4\xbc\x81\xe4\xbc\x82\xe3\x82\xa8\xe4\xbc\x825\xe4\xbc\x81\xe5\x80\x82\xe5\x80\x83\xe4\xbc\x82\xe5\x80\x81\xe3\x82\xb0\xe5\x84\x81\xe4\xbc\x812\xe4\xbc\x82\xe5\x80\x83\xe3\x82\xac\xe5\x80\x81\xe3\x82\xb8\xe5\x80\x834\xe4\xbc\x81\xe5\x80\x82\xe4\xbc\x81\xe5\x80\x81\xe4\xbc\x81\xe4\xbc\x82\xe3\x83\x84\xe4\xbc\x82\xe3\x82\xb9\xe5\x80\x81\xe4\xbc\x81\xe4\xbc\x82\xec\xa5\xb9\xe7\x9a\x97\xe9\x9e\xb9\xe9\x90\xbe\xeb\xa5\xb6\xe4\xa6\xbd\xe9\x98\xb9\xeb\x9f\x86\xe4\xa7\x9c\xe6\xa4\xbf\xe7\xb1\xab\xeb\xa6\xb9\xe9\x9d\xad\xec\x9a\xb6\xec\x98\xb7\xeb\x8e\xb7\xe6\xad\xa9\xe3\xb0\xb7\xe6\xad\x89\xe4\xb4\x97\xe9\x91\xb9\xe3\x9e\xb3\xe9\x9e\xb7\xe3\xac\xbc\xe7\x8d\xb4\xe9\x8f\x99\xeb\x8f\x97\xe9\x8d\xb4\xe7\xa5\xb3\xe3\xad\xbe\xeb\xa4\xb6\xe6\xae\x9e\xe7\x84\xbb\xef\xbf\xbd\xe4\xb9\xb9\xe1\x8f\x8b\xe9\x9d\x86\xe4\x8d\xbcUpdate TwoAnother small update, but I modified the code to pack the color shades into groups of three as opposed to four, this uses some more space, but unless I\'m missing something it should mean that "odd" characters no longer appear where the color data is. Also, I updated the compression a bit more so it can now act upon the entire string as opposed to just the color count block. I\'m still testing the run times, but they appear to be nominally improved; however, the image quality is still the same. What follows is the newest version of the Lena tweet:2\xe4\xb9\xa4\xe4\xb8\x87\xe4\xb9\x90\xe5\x94\x82\xe4\xbc\x82\xe5\x80\x82\xe5\x80\x81\xe4\xbc\x81\xe5\x84\x822\xe4\xbc\x81\xe5\x80\x813\xe4\xbc\x81\xe5\x80\x81\xe3\x82\xa6\xe4\xbc\x828\xe4\xbc\x81\xe4\xbc\x82\xe3\x82\xa8\xe4\xbc\x825\xe4\xbc\x81\xe5\x80\x82\xe5\x80\x83\xe4\xbc\x82\xe5\x80\x81\xe3\x82\xb0\xe5\x84\x81\xe4\xbc\x812\xe4\xbc\x82\xe5\x80\x83\xe3\x82\xac\xe5\x80\x81\xe3\x82\xb8\xe5\x80\x834\xe4\xbc\x81\xe5\x80\x82\xe4\xbc\x81\xe5\x80\x81\xe4\xbc\x81\xe4\xbc\x82\xe3\x83\x84\xe4\xbc\x82\xe3\x82\xb9\xe5\x80\x81\xe4\xbc\x81\xe4\xbc\x82\xe5\x9d\xb9\xe5\x9d\xbc\xe5\x9d\xb6\xe5\x9d\xbb\xe5\x88\xbe\xe5\x95\xa9\xe5\xae\xb9\xe5\x8a\x9b\xe5\x90\xb9\xe5\xa9\xa9\xe5\xaa\xb7\xe5\x8a\x9d\xe5\x9c\xbf\xe5\x92\xb6\xe5\x9d\xbc\xe5\xa6\x9b\xe5\x95\xad\xe5\xa5\xa9\xe5\x97\x86\xe5\xa9\xa3\xe5\x86\xb7\xe5\x92\x9b\xe5\x95\xab\xe5\x87\x83\xe5\xa5\x89\xe4\xbd\xb6\xe5\x9d\x8d\xe5\x9d\x87\xe5\x96\xb3\xe5\xa5\xb3\xe5\xaa\x97\xe5\x86\xb3\xe5\x85\xb4\xe5\xae\x97\xe5\x96\x93\xe5\xa4\xbd\xe5\x85\xb4\xe5\x94\xb9\xe5\xb1\xb9\xe5\x86\xb7\xe5\x9c\xb6\xe5\x9f\xab\xe5\xa5\xab\xe5\x94\x93\xe5\x9d\xa4\xe5\x96\x9d\xe5\xa5\x8e\xe4\xbc\xbc\xe5\x95\x86\xe5\x97\x89\xe4\xb9\x83StackOverflow Logo http://code-zen.info/twitterimage/images/stackoverflow-logo.bmp Cornell Box http://code-zen.info/twitterimage/images/cornell-box.bmp Lena http://code-zen.info/twitterimage/images/lena.bmp Mona Lisa http://code-zen.info/twitterimage/images/mona-lisa.bmpThis genetic algorithm that Roger Alsing wrote has a good compression ratio, at the expense of long compression times. The resulting vector of vertices could be further compressed using a lossy or lossless algorithm.http://rogeralsing.com/2008/12/07/genetic-programming-evolution-of-mona-lisa/Would be an interesting program to implement, but I\'ll give it a miss.In the original challenge the size limit is defined as what Twitter still allows you to send if you paste your text in their textbox and press "update". As some people correctly noticed this is different from what you could send as a SMS text message from your mobile.What is not explictily mentioned (but what my personal rule was) is that you should be able to select the tweeted message in your browser, copy it to the clipboard and paste it into a text input field of your decoder so it can display it. Of course you are also free to save the message as a text file and read it back in or write a tool which accesses the Twitter API and filters out any message that looks like an image code (special markers anyone? wink wink). But the rule is that the message has to have gone through Twitter before you are allowed to decode it.Good luck with the 350 bytes - I doubt that you will be able to make use of them.Posting a Monochrome or Greyscale image should improve the size of the image that can be encoded into that space since you don\'t care about colour.Possibly augmenting the challenge to upload three images which when recombined give you a full colour image while still maintaining a monochrome version in each separate image.Add some compression to the above and It could start looking viable...Nice!!! Now you guys have piqued my interest. No work will be done for the rest of the day...Regarding the encoding/decoding part of this challenge.\nbase16b.org is my attempt to specify a standard method for safely and efficiently encoding binary data in the higher Unicode planes.Some features :Sorry, this answer comes way too late for the original competition. I started the project independently of this post, which I discovered half-way into it.The idea of storing a bunch of reference images is interesting. Would it be so wrong to store say 25Mb of sample images, and have the encoder try and compose an image using bits of those? With such a minuscule pipe, the machinery at either end is by necessity going to be much greater than the volume of data passing through, so what\'s the difference between 25Mb of code, and 1Mb of code and 24Mb of image data?(note the original guidelines ruled out restricting the input to images already in the library - I\'m not suggesting that).Stupid idea, but sha1(my_image) would result in a "perfect" representation of any image (ignoring collisions). The obvious problem is the decoding process requires inordinate amounts of brute-forcing..1-bit monochrome would be a bit easier.. Each pixel becomes a 1 or 0, so you would have 1000 bits of data for a 100*100 pixel image. Since the SHA1 hash is 41 characters, we can fit three into one message, only have to brute force 2 sets of 3333 bits and one set of 3334 (although even that is probably still inordinate)It\'s not exactly practical. Even with the fixed-length 1-bit 100*100px image there is.., assuming I\'m not miscalculating, 49995000 combinations, or 16661667 when split into three.Here this compression is good.http://www.intuac.com/userport/john/apt/http://img86.imageshack.us/img86/4169/imagey.jpg http://img86.imageshack.us/img86/4169/imagey.jpgI used the following batch file:The resulting filesize is 559 bytes.Idea: Could you use a font as a palette? Try to break an image in a series of vectors trying to describe them with a combination of vector sets (each character is essentially a set of vectors). This is using the font as a dictionary. I could for instance use a l for a vertical line and a - for a horizontal line? Just an idea.