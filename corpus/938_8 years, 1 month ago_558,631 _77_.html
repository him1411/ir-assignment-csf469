Given two data frames:How can I do database style, i.e., sql style, joins? That is, how do I get:Extra credit:How can I do a SQL style select statement?By using the merge function and its optional parameters:Inner join: merge(df1, df2) will work for these examples because R automatically joins the frames by common variable names, but you would most likely want to specify merge(df1, df2, by = "CustomerId") to make sure that you were matching on only the fields you desired.  You can also use the by.x and by.y parameters if the matching variables have different names in the different data frames.Outer join: merge(x = df1, y = df2, by = "CustomerId", all = TRUE)Left outer: merge(x = df1, y = df2, by = "CustomerId", all.x = TRUE)Right outer: merge(x = df1, y = df2, by = "CustomerId", all.y = TRUE)Cross join: merge(x = df1, y = df2, by = NULL)Just as with the inner join, you would probably want to explicitly pass "CustomerId" to R as the matching variable.  I think it\'s almost always best to explicitly state the identifiers on which you want to merge; it\'s safer if the input data.frames change unexpectedly and easier to read later on.I would recommend checking out Gabor Grothendieck\'s sqldf package, which allows you to express these operations in SQL.I find the SQL syntax to be simpler and more natural than its R equivalent (but this may just reflect my RDBMS bias).See Gabor\'s sqldf GitHub for more information on joins. There is the data.table approach for an inner join, which is very time and memory efficient (and necessary for some larger data.frames):merge also works on data.tables (as it is generic and calls merge.data.table)data.table documented on stackoverflow:\nHow to do a data.table merge operation\nTranslating SQL joins on foreign keys to R data.table syntax\nEfficient alternatives to merge for larger data.frames R\nHow to do a basic left outer join with data.table in R?Yet another option is the join function found in the plyr packageOptions for type: inner, left, right, full.From ?join: Unlike merge, [join] preserves the order of x no matter what join type is used.You can do joins as well using Hadley Wickham\'s awesome dplyr package.  There are some good examples of doing this over at the R Wiki. I\'ll steal a couple here:Merge MethodSince your keys are named the same the short way to do an inner join is merge():a full inner join (all records from both tables) can be created with the "all" keyword:a left outer join of df1 and df2:a right outer join of df1 and df2:you can flip \'em, slap \'em and rub \'em down to get the other two outer joins you asked about :)Subscript MethodA left outer join with df1 on the left using a subscript method would be:The other combination of outer joins can be created by mungling the left outer join subscript example. (yeah, I know that\'s the equivalent of saying "I\'ll leave it as an exercise for the reader...")New in 2014: Especially if you\'re also interested in data manipulation in general (including sorting, filtering, subsetting, summarizing etc.), you should definitely take a look at dplyr, which comes with a variety of functions all designed to facilitate your work specifically with data frames and certain other database types. It even offers quite an elaborate SQL interface, and even a function to convert (most) SQL code directly into R.The four joining-related functions in the dplyr package are (to quote):It\'s all here in great detail.Selecting columns can be done by select(df,"column"). If that\'s not SQL-ish enough for you, then there\'s the sql() function, into which you can enter SQL code as-is, and it will do the operation you specified just like you were writing in R all along (for more information, please refer to the dplyr/databases vignette). For example, if applied correctly, sql("SELECT * FROM hflights") will select all the columns from the "hflights" dplyr table (a "tbl").Update on data.table methods for joining datasets. See below examples for each type of join. There are two methods, one from [.data.table when passing second data.table as the first argument to subset, another way is to use merge function which dispatched to fast data.table method.  Update on 2016-04-01 - and it isn\'t April Fools joke!\nIn 1.9.7 version of data.table joins are now capable to use existing index which tremendously reduce the timing of a join. Below code and benchmark does NOT use data.table indices on join. If you are looking for near real-time join you should use data.table indices.Below benchmark tests base R, sqldf, dplyr and data.table.\nBenchmark tests unkeyed/unindexed datasets. You can get even better performance if you are using keys on your data.tables or indexes with sqldf. Base R and dplyr does not have indexes or keys so I did not include that scenario in benchmark.\nBenchmark is performed on 5M-1 rows datasets, there are 5M-2 common values on join column so each scenario (left, right, full, inner) can be tested and join is still not trivial to perform.  dplyr is very good and performant. In addition to the other answers on it, here was/is its status as of v0.1.3 (4/2014)Per hadley\'s comments in that issue:In joining two data frames with ~1 million rows each, one with 2 columns and the other with ~20, I\'ve surprisingly found merge(..., all.x = TRUE, all.y = TRUE) to be faster then dplyr::full_join(). This is with dplyr v0.4 Merge takes ~17 seconds, full_join takes ~65 seconds.  Some food for though, since I generally default to dplyr for manipulation tasks.For the case of a left join with a 0..*:0..1 cardinality or a right join with a 0..1:0..* cardinality it is possible to assign in-place the unilateral columns from the joiner (the 0..1 table) directly onto the joinee (the 0..* table), and thereby avoid the creation of an entirely new table of data. This requires matching the key columns from the joinee into the joiner and indexing+ordering the joiner\'s rows accordingly for the assignment.If the key is a single column, then we can use a single call to match() to do the matching. This is the case I\'ll cover in this answer.Here\'s an example based on the OP, except I\'ve added an extra row to df2 with an id of 7 to test the case of a non-matching key in the joiner. This is effectively df1 left join df2:In the above I hard-coded an assumption that the key column is the first column of both input tables. I would argue that, in general, this is not an unreasonable assumption, since, if you have a data.frame with a key column, it would be strange if it had not been set up as the first column of the data.frame from the outset. And you can always reorder the columns to make it so. An advantageous consequence of this assumption is that the name of the key column does not have to be hard-coded, although I suppose it\'s just replacing one assumption with another. Concision is another advantage of integer indexing, as well as speed. In the benchmarks below I\'ll change the implementation to use string name indexing to match the competing implementations.I think this is a particularly appropriate solution if you have several tables that you want to left join against a single large table. Repeatedly rebuilding the entire table for each merge would be unnecessary and inefficient.On the other hand, if you need the joinee to remain unaltered through this operation for whatever reason, then this solution cannot be used, since it modifies the joinee directly. Although in that case you could simply make a copy and perform the in-place assignment(s) on the copy.As a side note, I briefly looked into possible matching solutions for multicolumn keys. Unfortunately, the only matching solutions I found were:For example, see Matching multiple columns on different data frames and getting other column as result, match two columns with two other columns, Matching on multiple columns, and the dupe of this question where I originally came up with the in-place solution, Combine two data frames with different number of rows in R.I decided to do my own benchmarking to see how the in-place assignment approach compares to the other solutions that have been offered in this question.Testing code:Here\'s a benchmark of the example based on the OP that I demonstrated earlier:Here I benchmark on random input data, trying different scales and different patterns of key overlap between the two input tables. This benchmark is still restricted to the case of a single-column integer key. As well, to ensure that the in-place solution would work for both left and right joins of the same tables, all random test data uses 0..1:0..1 cardinality. This is implemented by sampling without replacement the key column of the first data.frame when generating the key column of the second data.frame.I wrote some code to create log-log plots of the above results. I generated a separate plot for each overlap percentage. It\'s a little bit cluttered, but I like having all the solution types and join types represented in the same plot.I used spline interpolation to show a smooth curve for each solution/join type combination, drawn with individual pch symbols. The join type is captured by the pch symbol, using a dot for inner, left and right angle brackets for left and right, and a diamond for full. The solution type is captured by the color as shown in the legend.Here\'s a second large-scale benchmark that\'s more heavy-duty, with respect to the number and types of key columns, as well as cardinality. For this benchmark I use three key columns: one character, one integer, and one logical, with no restrictions on cardinality (that is, 0..*:0..*). (In general it\'s not advisable to define key columns with double or complex values due to floating-point comparison complications, and basically no one ever uses the raw type, much less for key columns, so I haven\'t included those types in the key columns. Also, for information\'s sake, I initially tried to use four key columns by including a POSIXct key column, but the POSIXct type didn\'t play well with the sqldf.indexed solution for some reason, possibly due to floating-point comparison anomalies, so I removed it.)The resulting plots, using the same plotting code given above:We have to add extra code which will subset from the newly joined table .SQL :- select a.* from df1 a inner join df2 b on\na.CustomerId=b.CustomerIdR :- merge(df1, df2, by.x = "CustomerId", by.y =\n"CustomerId")[,names(df1)]Same way SQL :- select b.* from df1 a inner join df2 b on\na.CustomerId=b.CustomerIdR :- merge(df1, df2, by.x = "CustomerId", by.y =\n"CustomerId")[,names(df2)]For an inner join on all columns, you could also use fintersect from the data.table-package or intersect from the dplyr-package as an alternative to merge without specifying the by-columns. this will give the rows that are equal between two dataframes:Example data: