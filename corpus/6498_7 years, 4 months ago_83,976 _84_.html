I am looking to get a random record from a huge (100 million record) mongodb.What is the fastest and most efficient way to do so? The data is already there and there are no field in which I can generate a random number and obtain a random row.Any suggestions?Starting with the 3.2 release of MongoDB, you can get N random docs from a collection using the $sample aggregation pipeline operator:Do a count of all records, generate a random number between 0 and the count, and then do:3.2 introduced $sample to the aggregation pipeline.There\'s also a good blog post on putting it into practice.This was actually a feature request:  http://jira.mongodb.org/browse/SERVER-533 but it was filed under "Won\'t fix."The cookbook has a very good recipe to select a random document out of a collection:  http://cookbook.mongodb.org/patterns/random-attribute/To paraphrase the recipe, you assign random numbers to your documents:Then select a random document:Querying with both $gte and $lte is necessary to find the document with a random number nearest rand.And of course you\'ll want to index on the random field:If you\'re already querying against an index, simply drop it, append random: 1 to it, and add it again.You can also use MongoDB\'s geospatial indexing feature to select the documents \'nearest\' to a random number.First, enable geospatial indexing on a collection:To create a bunch of documents with random points on the X-axis:Then you can get a random document from the collection like this:Or you can retrieve several document nearest to a random point:This requires only one query and no null checks, plus the code is clean, simple and flexible. You could even use the Y-axis of the geopoint to add a second randomness dimension to your query.The following recipe is a little slower than the mongo cookbook solution (add a random key on every document), but returns more evenly distributed random documents.  It\'s a little less-evenly distributed than the skip( random ) solution, but much faster and more fail-safe in case documents are removed.It also requires you to add a random "random" field to your documents so don\'t forget to add this when you create them : you may need to initialize your collection as shown by GeoffreyBenchmark resultsThis method is much faster than the skip() method (of ceejayoz) and generates more uniformly random documents than the "cookbook" method reported by Michael:For a collection with 1,000,000 elements:This method takes less than a millisecond on my machine the skip() method takes 180 ms on averageThe cookbook method will cause large numbers of documents to never get picked because their random number does not favor them. This method will pick all elements evenly over time. In my benchmark it was only 30% slower than the cookbook method.the randomness is not 100% perfect but it is very good (and it can be improved if necessary)This recipe is not perfect - the perfect solution would be a built-in feature as others have noted.\nHowever it should be a good compromise for many purposes.Here is a way using the default ObjectId values for _id and a little math and logic.That\'s the general logic in shell representation and easily adaptable.So in points:Find the min and max primary key values in the collectionGenerate a random number that falls between the timestamps of those documents.Add the random number to the minimum value and find the first document that is greater than or equal to that value.This uses "padding" from the timestamp value in "hex" to form a valid ObjectId value since that is what we are looking for. Using integers as the _id value is essentially simplier but the same basic idea in the points.In Python using pymongo:it is tough if there is no data there to key off of.  what are the _id field?  are they mongodb object id\'s?  If so, you could get the highest and lowest values:then if you assume the id\'s are uniformly distributed (but they aren\'t, but at least it\'s a start):You can pick a random timestamp and search for the first object that was created afterwards.\nIt will only scan a single document, though it doesn\'t necessarily give you a uniform distribution.I\'d suggest adding a random int field to each object. Then you can just do a to pick a random document. Just make sure you ensureIndex({random_field:1})I would suggest using map/reduce, where you use the map function to only emit when a random value is above a given probability. The reducef function above works because only one key (\'1\') is emitted from the map function.The value of the "probability" is defined in the "scope", when invoking mapRreduce(...)Using mapReduce like this should also be usable on a sharded db.If you want to select exactly n of m documents from the db, you could do it like this:Where "countTotal" (m) is the number of documents in the db, and "countSubset" (n) is the number of documents to retrieve.This approach might give some problems on sharded databases.My solution on php:You can pick random _id and return corresponding object:Here you dont need to spend space on storing random numbers in collection.Now you can use the aggregate.\nExample:See the doc.When I was faced with a similar solution, I backtracked and found that the business request was actually for creating some form of rotation of the inventory being presented.  In that case, there are much better options, which have answers from search engines like Solr, not data stores like MongoDB.In short, with the requirement to "intelligently rotate" content, what we should do instead of a random number across all of the documents is to include a personal q score modifier.  To implement this yourself, assuming a small population of users, you can store a document per user that has the productId, impression count, click-through count, last seen date, and whatever other factors the business finds as being meaningful to compute a q score modifier.  When retrieving the set to display, typically you request more documents from the data store than requested by the end user, then apply the q score modifier, take the number of records requested by the end user, then randomize the page of results, a tiny set, so simply sort the documents in the application layer (in memory).If the universe of users is too large, you can categorize users into behavior groups and index by behavior group rather than user.If the universe of products is small enough, you can create an index per user.I have found this technique to be much more efficient, but more importantly more effective in creating a relevant, worthwhile experience of using the software solution.In order to get a determinated number of random docs without duplicates:loop geting random index and skip duplicatedIf you have a simple id key, you could store all the id\'s in an array, and then pick a random id. (Ruby answer):non of the solutions worked well for me. especially when there are many gaps and set is small. \nthis worked very well for me(in php):This works nice, it\'s fast, works with multiple documents and doesn\'t require populating rand field, which will eventually populate itself:ps. How to find random records in mongodb question is marked as duplicate of this question. The difference is that this question asks explicitly about single record as the other one explicitly about getting random documents.Using Map/Reduce, you can certainly get a random record, just not necessarily very efficiently depending on the size of the resulting filtered collection you end up working with.I\'ve tested this method with 50,000 documents (the filter reduces it to about 30,000), and it executes in approximately 400ms on an Intel i3 with 16GB ram and a SATA3 HDD...The Map function simply creates an array of the id\'s of all documents that match the query. In my case I tested this with approximately 30,000 out of the 50,000 possible documents.The Reduce function simply picks a random integer between 0 and the number of items (-1) in the array, and then returns that _id from the array.400ms sounds like a long time, and it really is, if you had fifty million records instead of fifty thousand, this may increase the overhead to the point where it becomes unusable in multi-user situations.There is an open issue for MongoDB to include this feature in the core... https://jira.mongodb.org/browse/SERVER-533If this "random" selection was built into an index-lookup instead of collecting ids into an array and then selecting one, this would help incredibly. (go vote it up!)If you\'re using mongoid, the document-to-object wrapper, you can do the following in\nRuby. (Assuming your model is User)In my .irbrc, I haveso in rails console, I can do, for example,to get documents randomly from any collection.If you are using mongoose then you may use mongoose-random\nmongoose-randomWhat works efficiently and reliably is this:Add a field called "random" to each document and assign a random value to it, add an index for the random field and proceed as follows:Let\'s assume we have a collection of web links called "links" and we want a random link from it:To ensure the same link won\'t pop up a second time, update its random field with a new random number: