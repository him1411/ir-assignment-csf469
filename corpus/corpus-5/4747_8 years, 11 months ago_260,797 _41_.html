Am I correct to say the difference between a signed and unsigned integer is:Any other differences?Yes.  There are different ways of representing signed integers.  The easiest to visualise is to use the leftmost bit as a flag (sign and magnitude), but more common is two\'s complement.  Both are in use in most modern microprocessors \xe2\x80\x94 floating point uses sign and magnitude, while integer arithmetic uses two\'s complement.YesI\'ll go into differences at the hardware level, on x86. This is mostly irrelevant unless you\'re writing a compiler or using assembly language. But it\'s nice to know.Firstly, x86 has native support for the two\'s complement representation of signed numbers. You can use other representations but this would require more instructions and generally be a waste of processor time.What do I mean by "native support"? Basically I mean that there are a set of instructions you use for unsigned numbers and another set that you use for signed numbers. Unsigned numbers can sit in the same registers as signed numbers, and indeed you can mix signed and unsigned instructions without worrying the processor. It\'s up to the compiler (or assembly programmer) to keep track of whether a number is signed or not, and use the appropriate instructions.Firstly, two\'s complement numbers have the property that addition and subtraction is just the same as for unsigned numbers. It makes no difference whether the numbers are positive or negative. (So you just go ahead and ADD and SUB your numbers without a worry.)The differences start to show when it comes to comparisons. x86 has a simple way of differentiating them: above/below indicates an unsigned comparison and greater/less than indicates a signed comparison. (E.g. JAE means "Jump if above or equal" and is unsigned.)There are also two sets of multiplication and division instructions to deal with signed and unsigned integers.Lastly: if you want to check for, say, overflow, you would do it differently for signed and for unsigned numbers.Basically he asked only about signed and unsigned. Don\'t know why people are adding extra stuff in this. Let me tell you answer.Unsigned: It consist only positive value i.e 0 to 255.Signed: It consist both negative and positive values but in different formats likeAnd this all explanation is about 8 bit number system.Just a few points for completeness:this answer is discussing only integer representations.  There may be other answers for floating point;the representation of a negative number can vary.  The most common (by far - it\'s nearly universal today) in use today is two\'s complement.  Other representations include one\'s complement (quite rare) and signed magnitude (vanishingly rare - probably only used on museum pieces) which is simply using the high bit as a sign indicator with the remain bits representing the absolute value of the number.When using two\'s complement, the variable can represent a larger range (by one) of negative numbers than positive numbers.  This is because zero is included in the \'positive\' numbers (since the sign bit is not set for zero), but not the negative numbers. This means that the absolute value of the smallest negative number cannot be represented.when using one\'s complement or signed magnitude you can have zero represented as either a positive or negative number (which is one of a couple of reasons these representations aren\'t typically used).Everything except for point 2 is correct. There are many different notations for signed ints, some implementations use the first, others use the last and yet others use something completely different. That all depends on the platform you\'re working with.According to what we learned in class, signed integers can represent both positive and negative numbers, while unsigned integers are only non-negative.For example, looking at an 8-bit number:unsigned values 0 to 255 signed values range from -128 to 127 Another difference is when you are converting between integers of different sizes.For example, if you are extracting an integer from a byte stream (say 16 bits for simplicity), with unsigned values, you could do:(should probably cast the 2nd byte, but I\'m guessing the compiler will do the right thing)With signed values you would have to worry about sign extension and do:Over and above what others have said, in C, you cannot overflow an unsigned integer; the behaviour is defined to be modulus arithmetic.  You can overflow a signed integer and, in theory (though not in practice on current mainstream systems), the overflow could trigger a fault (perhaps similar to a divide by zero fault).(in answer to the second question) By only using a sign bit (and not 2\'s complement), you can end up with -0. Not very pretty.Generally speaking that is correct. Without knowing anything more about why you are looking for the differences I can\'t think of any other differentiators between signed and unsigned. Unsigned integers are far more likely to catch you in a particular trap than are signed integers.  The trap comes from the fact that while 1 & 3 above are correct, both types of integers can be assigned a value outside the bounds of what it can "hold" and it will be silently converted.When you run this, you\'ll get the following output even though both values were assigned to -1 and were declared differently.Signed integers in C represent numbers.  If a and b are variables of signed integer types, the standard will never require that a compiler make the expression a+=b store into a anything other than the arithmetic sum of their respective values.  To be sure, if the arithmetic sum would not fit into a, the processor might not be able to put it there, but the standard would not require the compiler to truncate or wrap the value, or do anything else for that matter if values that exceed the limits for their types.  Note that while the standard does not require it, C implementations are allowed to trap arithmetic overflows with signed values.Unsigned integers in C behave as abstract algebraic rings of integers which are congruent modulo some power of two, except in scenarios involving conversions to, or operations with, larger types.  Converting an integer of any size to a 32-bit unsigned type will yield the member corresponding to things which are congruent to that integer mod 4,294,967,296.  The reason subtracting 3 from 2 yields 4,294,967,295 is that adding something congruent to 3 to something congruent to 4,294,967,295 will yield something congruent to 2.Abstract algebraic rings types are often handy things to have; unfortunately, C uses signedness as the deciding factor for whether a type should behave as a ring.  Worse, unsigned values are treated as numbers rather than ring members when converted to larger types, and unsigned values smaller than int get converted to numbers when any arithmetic is performed upon them.  If v is a uint32_t which equals 4,294,967,294, then v*=v; should make v=4.  Unfortunately, if int is 64 bits, then there\'s no telling what v*=v; could do.Given the standard as it is, I would suggest using unsigned types in situations where one wants the behavior associated with algebraic rings, and signed types when one wants to represent numbers.  It\'s unfortunate that C drew the distinctions the way it did, but they are what they are.The only guaranteed difference between a signed and an unsigned value in C is that the signed value can be negative, 0 or positive, while an unsigned can only be 0 or positive. The problem is that C doesn\'t define the format of types (so you don\'t know that your integers are in two\'s complement). Strictly speaking the first two points you mentioned are incorrect.You must used unsigned Integers when programming on Embedded Systems. In loops, when there is no need for signed integers, using unsigned integers will save safe necessary for designing such systems.