I have a Python script which takes as input a list of integers, which I need to work with four integers at a time.  Unfortunately, I don\'t have control of the input, or I\'d have it passed in as a list of four-element tuples.  Currently, I\'m iterating over it this way:It looks a lot like "C-think", though, which makes me suspect there\'s a more pythonic way of dealing with this situation.  The list is discarded after iterating, so it needn\'t be preserved.  Perhaps something like this would be better?Still doesn\'t quite "feel" right, though.  :-/Related question: How do you split a list into evenly sized chunks in Python?Modified from the recipes section of Python\'s itertools docs:Example\nIn pseudocode to keep the example terse.Note: izip_longest is new to Python 2.6. In Python 3 use zip_longest.Simple. Easy. Fast. Works with any sequence:I\'m a fan of Another way:I needed a solution that would also work with sets and generators. I couldn\'t come up with anything very short and pretty, but it\'s quite readable at least.List:Set:Generator:Posting this as an answer since I cannot comment...Using map() instead of zip() fixes the padding issue in J.F. Sebastian\'s answer:Example:Similar to other proposals, but not exactly identical, I like doing it this way, because it\'s simple and easy to read:This way you won\'t get the last partial chunk. If you want to get (9, None, None, None) as last chunk, just use izip_longest from itertools.Since nobody\'s mentioned it yet here\'s a zip() solution:It works only if your sequence\'s length is always divisible by the chunk size or you don\'t care about a trailing chunk if it isn\'t.Example:Or using itertools.izip to return an iterator instead of a list:Padding can be fixed using @\xce\xa4\xce\x96\xce\xa9\xce\xa4\xce\x96\xce\x99\xce\x9f\xce\xa5\'s answer:Using little functions and things really doesn\'t appeal to me; I prefer to just use slices:If the list is large, the highest-performing way to do this will be to use a generator:With NumPy it\'s simple:output:In your second method, I would advance to the next group of 4 by doing this:However, I haven\'t done any performance measurement so I don\'t know which one might be more efficient.Having said that, I would usually choose the first method. It\'s not pretty, but that\'s often a consequence of interfacing with the outside world.The ideal solution for this problem works with iterators (not just sequences). It should also be fast.This is the solution provided by the documentation for itertools:Using ipython\'s %timeit on my mac book air, I get 47.5 us per loop.However, this really doesn\'t work for me since the results are padded to be even sized groups. A solution without the padding is slightly more complicated. The most naive solution might be:Simple, but pretty slow: 693 us per loopThe best solution I could come up with uses islice for the inner loop:With the same dataset, I get 305 us per loop.Unable to get a pure solution any faster than that, I provide the following solution with an important caveat: If your input data has instances of filldata in it, you could get wrong answer.I really don\'t like this answer, but it is significantly faster. 124 us per loopYet another answer, the advantages of which are:1) Easily understandable\n2) Works on any iterable, not just sequences (some of the above answers will choke on filehandles)\n3) Does not load the chunk into memory all at once\n4) Does not make a chunk-long list of references to the same iterator in memory\n5) No padding of fill values at the end of the listThat being said, I haven\'t timed it so it might be slower than some of the more clever methods, and some of the advantages may be irrelevant given the use case.Update:\nA couple of drawbacks due to the fact the inner and outer loops are pulling values from the same iterator:\n1) continue doesn\'t work as expected in the outer loop - it just continues on to the next item rather than skipping a chunk. However, this doesn\'t seem like a problem as there\'s nothing to test in the outer loop.\n2) break doesn\'t work as expected in the inner loop - control will wind up in the inner loop again with the next item in the iterator. To skip whole chunks, either wrap the inner iterator (ii above) in a tuple, e.g. for c in tuple(ii), or set a flag and exhaust the iterator.Another approach would be to use the two-argument form of iter: This can be adapted easily to use padding (this is similar to Markus Jarderot\xe2\x80\x99s answer):These can even be combined for optional padding:You can use partition or chunks function from funcy library:These functions also has iterator versions ipartition and ichunks, which will be more efficient in this case.You can also peek at their implementation.To avoid all conversions to a list import itertools and:Produces:I checked groupby and it doesn\'t convert to list or use len so I (think) this will delay resolution of each value until it is actually used.  Sadly none of the available answers (at this time) seemed to offer this variation.Obviously if you need to handle each item in turn nest a for loop over g:My specific interest in this was the need to consume a generator to submit changes in batches of up to 1000 to the gmail API:About solution gave by J.F. Sebastian here:It\'s clever, but has one disadvantage - always return tuple. How to get string instead?\nOf course you can write \'\'.join(chunker(...)), but the temporary tuple is constructed anyway.You can get rid of the temporary tuple by writing own zip, like this:ThenExample usage:Here is a chunker without imports that supports generators:Example of use:I like this approach. It feels simple and not magical and supports all iterable types and doesn\'t require imports.There doesn\'t seem to be a pretty way to do this.  Here is a page that has a number of methods, including:If the lists are the same size, you can combine them into lists of 4-tuples with zip(). For example:Here\'s what the zip() function produces:If the lists are large, and you don\'t want to combine them into a bigger list, use itertools.izip(), which produces an iterator, rather than a list.One-liner, adhoc solution to iterate over a list x in chunks of size 4 -At first, I designed it to split strings into substrings to parse string containing hex.\nToday I turned it into complex, but still simple generator.reductor is a callable, which receives generator iterating over content of chunk.\nI\'d expect it to return sequence or string, but I don\'t demand that.You can pass as this argument for example list, tuple, set, frozenset,\nor anything fancier. I\'d pass this function, returning string\n(provided that iterable contains / generates / iterates over strings):Note that reductor can cause closing generator by raising exception.condition is a callable which receives anything what reductor returned.\nIt decides to approve & yield it (by returning anything evaluating to True),\nor to decline it & finish generator\'s work (by returning anything other or raising exception).When number of elements in iterable is not divisible by size, when it gets exhausted, reductor will receive generator generating less elements than size.\nLet\'s call these elements lasts elements.I invited two functions to pass as this argument:  lambda x:x - the lasts elements will be yielded.lambda x: len(x)==<size> - the lasts elements will be rejected.\nreplace <size> using number equal to sizeIt is easy to make itertools.groupby work for you to get an iterable of iterables, without creating any temporary lists:Don\'t get put off by the nested lambdas, outer lambda runs just once to put count() generator and the constant 100 into the scope of the inner lambda.I use this to send chunks of rows to mysql.Quite pythonic here (you may also inline the body of the split_groups function)This answer splits a list of strings, f.ex. to achieve PEP8-line length compliance:Use as