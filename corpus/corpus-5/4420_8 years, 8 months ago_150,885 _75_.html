Is there any way I can separate a List<SomeObject> into several separate lists of SomeObject, using the item index as the delimiter of each split?Let me exemplify:I have a List<SomeObject> and I need a List<List<SomeObject>> or List<SomeObject>[], so that each of these resulting lists will contain a group of 3 items of the original list (sequentially).eg.:Original List: [a, g, e, w, p, s, q, f, x, y, i, m, c]Resulting lists: [a, g, e], [w, p, s], [q, f, x], [y, i, m], [c]I\'d also need the resulting lists size to be a parameter of this function.Try the following code.The idea is to first group the elements by indexes.  Dividing by three has the effect of grouping them into groups of 3.  Then convert each group to a list and the IEnumerable of List to a List of ListsThis question is a bit old, but I just wrote this, and I think it\'s a little more elegant than the other proposed solutions:In general the approach suggested by CaseyB works fine, in fact if you are passing in a List<T> it is hard to fault it, perhaps I would change it to:Which will avoid massive call chains. Nonetheless, this approach has a general flaw. It materializes two enumerations per chunk, to highlight the issue try running: To overcome this we can try Cameron\'s approach, which passes the above test in flying colors as it only walks the enumeration once. Trouble is that it has a different flaw, it materializes every item in each chunk, the trouble with that approach is that you run high on memory. To illustrate that try running:Finally, any implementation should be able to handle out of order iteration of chunks, for example:Many highly optimal solutions like my first revision of this answer failed there. The same issue can be seen in casperOne\'s optimized answer.To address all these issues you can use the following:There is also a round of optimisations you could introduce for out-of-order iteration of chunks, which is out of scope here. As to which method you should choose? It totally depends on the problem you are trying to solve. If you are not concerned with the first flaw the simple answer is incredibly appealing.Note as with most methods, this is not safe for multi threading, stuff can get weird if you wish to make it thread safe you would need to amend EnumeratorWrapper.You could use a number of queries that use Take and Skip, but that would add too many iterations on the original list, I believe.Rather, I think you should create an iterator of your own, like so:You can then call this and it is LINQ enabled so you can perform other operations on the resulting sequences.In light of Sam\'s answer, I felt there was an easier way to do this without:That said, here\'s another pass, which I\'ve codified in an extension method to IEnumerable<T> called Chunk:Nothing surprising up there, just basic error checking.Moving on to ChunkInternal:Basically, it gets the IEnumerator<T> and manually iterates through each item.  It checks to see if there any items currently to be enumerated.  After each chunk is enumerated through, if there aren\'t any items left, it breaks out.Once it detects there are items in the sequence, it delegates the responsibility for the inner IEnumerable<T> implementation to ChunkSequence:Since MoveNext was already called on the IEnumerator<T> passed to ChunkSequence, it yields the item returned by Current and then increments the count, making sure never to return more than chunkSize items and moving to the next item in the sequence after every iteration (but short-circuited if the number of items yielded exceeds the chunk size).If there are no items left, then the InternalChunk method will make another pass in the outer loop, but when MoveNext is called a second time, it will still return false, as per the documentation (emphasis mine):If MoveNext passes the end of the collection, the enumerator is\n  positioned after the last element in the collection and MoveNext\n  returns false. When the enumerator is at this position, subsequent\n  calls to MoveNext also return false until Reset is called.At this point, the loop will break, and the sequence of sequences will terminate.This is a simple test:Output:An important note, this will not work if you don\'t drain the entire child sequence or break at any point in the parent sequence.  This is an important caveat, but if your use case is that you will consume every element of the sequence of sequences, then this will work for you.Additionally, it will do strange things if you play with the order, just as Sam\'s did at one point.Ok, here\'s my take on it:\n\nExample UsageExplanations The code works by nesting two yield based iterators.The outer iterator must keep track of how many elements have been effectively consumed by the inner (chunk) iterator. This is done by closing over remaining with innerMoveNext(). Unconsumed elements of a chunk are discarded before the next chunk is yielded by the outer iterator.\nThis is necessary because otherwise you get inconsistent results, when the inner enumerables are not (completely) consumed (e.g. c3.Count() would return 6).Note: The answer has been updated to address the shortcomings pointed out by @aolszowka.completely lazy, no counting or copying:I think the following suggestion would be the fastest. I am sacrificing the lazyness of the source Enumerable for the ability to use Array.Copy and knowing ahead of the time the length of each of my sublists.We can improve @JaredPar\'s solution to do true lazy evaluation. We use a GroupAdjacentBy method that yields groups of consecutive elements with the same key:Because the groups are yielded one-by-one, this solution works efficiently with long or infinite sequences.System.Interactive provides Buffer() for this purpose. Some quick testing shows performance is similar to Sam\'s solution.Here\'s a list splitting routine I wrote a couple months ago:I wrote a Clump extension method several years ago. Works great, and is the fastest implementation here. :PThis is an old question but this is what I ended up with; it enumerates the enumerable only once, but does create lists for each of the partitions. It doesn\'t suffer from unexpected behavior when ToArray() is called as some of the implementations do:This following solution is the most compact I could come up with that is O(n).Old code, but this is what I\'ve been using:I find this little snippet does the job quite nicely.If the list is of type system.collections.generic you can use the "CopyTo" method available to copy elements of your array to other sub arrays. You specify the start element and number of elements to copy.You could also make 3 clones of your original list and use the "RemoveRange" on each list to shrink the list to the size you want.Or just create a helper method to do it for you.We found David B\'s solution worked the best. But we adapted it to a more general solution:What about this one?As far as I know, GetRange() is linear in terms of number of items taken. So this should perform well.Using modular partitioning:Just putting in my two cents.  If you wanted to "bucket" the list (visualize left to right), you could do the following:It\'s an old solution but I had a different approach. I use Skip to move to desired offset and Take to extract desired number of elements:I took the primary answer and made it to be an IOC container to determine where to split. (For who is really looking to only split on 3 items, in reading this post while searching for an answer?) This method allows one to split on any type of item as needed.So for the OP the code would beTo insert my two cents...By using the list type for the source to be chunked, I found another very compact solution: