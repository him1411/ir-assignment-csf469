I have an application where I am looking for a text file and if there are any changes made to the file I am using the OnChanged eventhandler to handle the event. I am using the NotifyFilters.LastWriteTime but still the event is getting fired twice. Here is the code.In my case the OnChanged is called twice, when I change the text file version.txt and save it.I am afraid that this is a well-known bug/feature of the FileSystemWatcher class. This is from the documentation of the class:You may notice in certain situations that a single creation event generates multiple Created events that are handled by your component. For example, if you use a FileSystemWatcher component to monitor the creation of new files in a directory, and then test it by using Notepad to create a file, you may see two Created events generated even though only a single file was created. This is because Notepad performs multiple file system actions during the writing process. Notepad writes to the disk in batches that create the content of the file and then the file attributes. Other applications may perform in the same manner. Because FileSystemWatcher monitors the operating system activities, all events that these applications fire will be picked up.Now this bit of text is about the Created event, but the same thing applies to other file events as well. In some applications you might be able to get around this by using the NotifyFilter property, but my experience is says that sometimes you have to do some manual duplicate filtering (hacks) as well.A while ago I bookedmarked a page with a few FileSystemWatcher tips. You might want to check it out.I\'ve "fixed" that problem using the following strategy in my delegate:Any duplicated OnChanged events from the FileSystemWatcher can be detected and discarded by checking the File.GetLastWriteTime timestamp on the file in question. Like so: Here is my solution which helped me to stop the event being raised twice:Here I have set the NotifyFilter property with only Filename and size.\nwatcher is my object of FileSystemWatcher. Hope this will help.My scenario is that I have a virtual machine with a Linux server in it. I am developing files on the Windows host. When I change something in a folder on the host I want all the changes to be uploaded, synced onto the virtual server via Ftp. This is how I do eliminate the duplicate change event when I write to a file ( which flags the folder containing the file to be modified as well ) :Mainly I create a hashtable to store file write time information. Then if the hashtable has the filepath that is modified and it\'s time value is the same as the currently notified file\'s change then I know it is the duplicate of the event and ignore it.Try with this code:I know this is an old issue, but had the same problem and none of the above solution really did the trick for the problem I was facing. I have created a dictionary which maps the file name with the LastWriteTime. So if the file is not in the dictionary will go ahead with the process other wise check to see when was the last modified time and if is different from what it is in the dictionary run the code.Here\'s my approach :This is the solution I used to solve this issue on a project where I was sending the file as attachment in a mail.\nIt will easily avoid the twice fired event even with a smaller timer interval but in my case 1000 was alright since I was happier with missing few changes than with flooding the mailbox with > 1 message per second.\nAt least it works just fine in case several files are changed at the exact same time.Another solution I\'ve thought of would be to replace the list with a dictionary mapping files to their respective MD5, so you wouldn\'t have to choose an arbitrary interval since you wouldn\'t have to delete the entry but update its value, and cancel your stuff if it hasn\'t changed.\nIt has the downside of having a Dictionary growing in memory as files are monitored and eating more and more memory, but I\'ve read somewhere that the amount of files monitored depends on the FSW\'s internal buffer, so maybe not that critical.\nDunno how MD5 computing time would affect your code\'s performances either, careful =\\One possible \'hack\' would be to throttle the events using Reactive Extensions for example:In this case I\'m throttling to 50ms, on my system that was enough, but higher values should be safer. (And like I said, it\'s still a \'hack\').The main reason was \nfirst event\'s last access time was current time(file write or changed time).\nthen second event was file\'s original last access time.\nI solve under code.I spent some significant amount of time using the FileSystemWatcher, and some of the approaches here will not work. I really liked the disabling events approach, but unfortunately, it doesn\'t work if there is >1 file being dropped, second file will be missed most if not all times. \nSo I use the following approach:I have a very quick and simple workaround here, it does work for me, and no matter the event would be triggered once or twice or more times occasionally, check it out:This code worked for me.Here is a new solution you can try. Works well for me. In the event handler for the changed event programmatically remove the handler from the designer output a message if desired then programmatically add the handler back. example: I have changed the way I monitor files in directories.  Instead of using the FileSystemWatcher I poll locations on another thread and then look at the LastWriteTime of the file.Using this information and keeping an index of a file path and it\'s latest write time I can determine files that have changed or that have been created in a particular location.  This removes me from the oddities of the FileSystemWatcher.  The main downside is that you need a data structure to store the LastWriteTime and the reference to the file, but it is reliable and easy to implement.You could try to open it for write, and if successful then you could assume the other application is done with the file.Just opening it for write appears not to raise the changed event. So it should be safe.Sorry for the grave dig, but I\'ve been battling this issue for a while now and finally came up with a way to handle these multiple fired events. I would like to thank everyone in this thread as I have used it in many references when battling this issue.Here is my complete code. It uses a dictionary to track the date and time of the last write of the file. It compares that value, and if it is the same, it suppresses the events. It then sets the value after starting the new thread.I have created a Git repo with a class that extends FileSystemWatcher to trigger the events only when copy is done. It discards all the changed events exept the last and it raise it only when the file become available for read.Download FileSystemSafeWatcher and add it to your project.Then use it as a normal FileSystemWatcher and monitor when the events are triggered.I was able to do this by added a function that checks for duplicates in an buffer array. Then perform the action after the array has not been modified for X time using a timer:\n - Reset timer every time something is written to the buffer\n - Perform action on tickThis also catches another duplication type.  If you modify a file inside a folder, the folder also throws a Change event.This solution worked for me on production application:Environment:VB.Net Framework 4.5.2Set manually object properties: NotifyFilter = SizeThen use this code:Try this!mostly for future me :)I wrote a wrapper using Rx:Usage:if you register to the OnChanged event, then by deleting the monitored file before changing it might work, as long as you only need to monitor the OnChange event..Make it simple define one global variable var1 = true.Well, here is my solution how to raise an event only once:here is implementation of FileChanged