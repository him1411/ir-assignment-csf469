I have always wondered if, in general, declaring a throw-away variable before a loop, as opposed to repeatedly inside the loop, makes any (performance) difference? \nA (quite pointless) example in Java:a) declaration before loop:b) declaration (repeatedly) inside loop:Which one is better, a or b? I suspect that repeated variable declaration (example b) creates more overhead in theory, but that compilers are smart enough so that it doesn\'t matter. Example b has the advantage of being more compact and limiting the scope of the variable to where it is used. Still, I tend to code according example a.Edit: I am especially interested in the Java case.Which is better, a or b?From a performance perspective, you\'d have to measure it. (And in my opinion, if you can measure a difference, the compiler isn\'t very good).From a maintenance perspective, b is better. Declare and initialize variables in the same place, in the narrowest scope possible. Don\'t leave a gaping hole between the declaration and the initialization, and don\'t pollute namespaces you don\'t need to.Well I ran your A and B examples 20 times each, looping 100 million times.(JVM - 1.5.0)A: average execution time: .074 secB: average execution time : .067 secTo my surprise B was slightly faster.\nAs fast as computers are now its hard to say if you could accurately measure this.\nI would code it the A way as well but I would say it doesn\'t really matter.It depends on the language and the exact use. For instance, in C# 1 it made no difference. In C# 2, if the local variable is captured by an anonymous method (or lambda expression in C# 3) it can make a very signficant difference.Example:Output:The difference is that all of the actions capture the same outer variable, but each has its own separate inner variable.The following is what I wrote and compiled in .NET.This is what I get from .NET Reflector when CIL is rendered back into code.So both look exactly same after compilation. In managed languages code is converted into CL/byte code and at time of execution it\'s converted into machine language. So in machine language a double may not even be created on the stack. It may just be a register as code reflect that it is a temporary variable for WriteLine function. There are a whole set optimization rules just for loops. So the average guy shouldn\'t be worried about it, especially in managed languages. There are cases when you can optimize manage code, for example, if you have to concatenate a large number of strings using just string a; a+=anotherstring[i] vs using StringBuilder. There is very big difference in performance between both. There are a lot of such cases where the compiler cannot optimize your code, because it cannot figure out what is intended in a bigger scope. But it can pretty much optimize basic things for you.This is a gotcha in VB.NET. The Visual Basic result won\'t reinitialize the variable in this example:This will print 0 the first time (Visual Basic variables have default values when declared!) but i each time after that.If you add a = 0, though, you get what you might expect:It is language dependent - IIRC C# optimises this, so there isn\'t any difference, but JavaScript (for example) will do the whole memory allocation shebang each time.I would always use A (rather than relying on the compiler) and might also rewrite to:This still restricts intermediateResult to the loop\'s scope, but doesn\'t redeclare during each iteration.I made a simple test:vs I compiled these codes with gcc - 5.2.0. And then I disassembled the main ()\nof these two codes and that\'s the result:1\xc2\xba:vs2\xc2\xbaWhich are exaclty the same asm result. isn\'t a proof that the two codes produce the same thing?In my opinion, b is the better structure.  In a, the last value of intermediateResult sticks around after your loop is finished.Edit:\nThis doesn\'t make a lot of difference with value types, but reference types can be somewhat weighty.  Personally, I like variables to be dereferenced as soon as possible for cleanup, and b does that for you,I suspect a few compilers could optimize both to be the same code, but certainly not all.  So I\'d say you\'re better off with the former.  The only reason for the latter is if you want to ensure that the declared variable is used only within your loop.As a general rule, I declare my variables in the inner-most possible scope. So, if you\'re not using intermediateResult outside of the loop, then I\'d go with B.A co-worker prefers the first form, telling it is an optimization, preferring to re-use a declaration.I prefer the second one (and try to persuade my co-worker! ;-)), having read that:Anyway, it falls in the category of premature optimization that rely in quality of compiler and/or JVM.There is a difference in C# if you are using the variable in a lambda, etc.  But in general the compiler will basically do the same thing, assuming the variable is only used within the loop.  Given that they are basically the same: Note that version b makes it much more obvious to readers that the variable isn\'t, and can\'t, be used after the loop.  Additionally, version b is much more easily refactored.  It is more difficult to extract the loop body into its own method in version a. Moreover, version b assures you that there is no side effect to such a refactoring.Hence, version a annoys me to no end, because there\'s no benefit to it and it makes it much more difficult to reason about the code...Well, you could always make a scope for that:This way you only declare the variable once, and it\'ll die when you leave the loop.I\'ve always thought that if you declare your variables inside of your loop then you\'re wasting memory.  If you have something like this:Then not only does the object need to be created for each iteration, but there needs to be a new reference allocated for each object.  It seems that if the garbage collector is slow then you\'ll have a bunch of dangling references that need to be cleaned up.However, if you have this:Then you\'re only creating a single reference and assigning a new object to it each time.  Sure, it might take a bit longer for it to go out of scope, but then there\'s only one dangling reference to deal with.I think it depends on the compiler and is hard to give a general answer.My practice is following:  if type of variable is simple (int, double, ...) I prefer variant b (inside).\nReason: reducing scope of variable.  if type of variable is not simple (some kind of class or struct) I prefer variant a (outside).\nReason: reducing number of ctor-dtor calls.From a performance perspective, outside is (much) better.I executed both functions 1 billion times each. \noutside() took 65 milliseconds. inside() took 1.5 seconds.this is the better form1) in this way declared once time both variable, and not each for cycle.\n2) the assignment it\'s fatser thean all other option.\n3) So the bestpractice rule is any declaration outside the iteration for.A) is a safe bet than B).........Imagine if you are initializing structure in loop rather than \'int\' or \'float\' then what?like You are certainly bound to face problems with memory leaks!. Hence I believe \'A\' is safer bet while \'B\' is vulnerable to memory accumulation esp working close source libraries.You can check usinng \'Valgrind\' Tool on Linux specifically sub tool \'Helgrind\'. It\'s an interesting question. From my experience there is an ultimate question to consider when you debate this matter for a code:Is there any reason why the variable would need to be global?It makes sense to only declare the variable once, globally, as opposed to many times locally, because it is better for organizing the code and requires less lines of code. However, if it only needs to be declared locally within one method, I would initialize it in that method so it is clear that the variable is exclusively relevant to that method. Be careful not to call this variable outside the method in which it is initialized if you choose the latter option--your code won\'t know what you\'re talking about and will report an error.Also, as a side note, don\'t duplicate local variable names between different methods even if their purposes are near-identical; it just gets confusing. I tested for JS with Node 4.0.0 if anyone is interested. Declaring outside the loop resulted in a ~.5 ms performance improvement on average over 1000 trials with 100 million loop iterations per trial. So I\'m gonna say go ahead and write it in the most readable / maintainable way which is B, imo. I would put my code in a fiddle, but I used the performance-now Node module. Here\'s the code:Even if I know my compiler is smart enough, I won\'t like to rely on it, and will use the a) variant.The b) variant makes sense to me only if you desperately need to make the intermediateResult unavailable after the loop body. But I can\'t imagine such desperate situation, anyway....EDIT: Jon Skeet made a very good point, showing that variable declaration inside a loop can make an actual semantic difference.