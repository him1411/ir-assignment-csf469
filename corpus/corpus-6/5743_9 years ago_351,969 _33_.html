I\'m trying to ftp a folder using the command line ftp client, but so far I\'ve only been able to use \'get\' to get individual files. You could rely on wget which usually handles ftp get properly (at least in my own experience). For example:You can also use -m which is suitable for mirroring. It is currently equivalent to -r -N -l inf.If you\'ve some special characters in the credential details, you can specify the --user and --password arguments to get it to work. Example with custom login with specific characters:EDIT\nAs pointed out by @asmaier, watch out that even if -r is for recursion, it has a default max level of 5:If you don\'t want to miss out subdirs, better use the mirroring option, -m:Just to complement the answer given by Thibaut Barr\xc3\xa8re.I usedNote the double slash after the server name. If I don\'t put an extra slash the path is relative to the home directory of user.If you can use scp instead of ftp, the -r option will do this for you. I would check to see whether you can use a more modern file transfer mechanism than FTP.If lftp is installed on your machine, use mirror dir. And you are done. See the comment by Ciro below if you want to recursively download a directory. There is \'ncftp\' which is available for installation in linux. This works on the FTP protocol and can be used to download files and folders recursively. works on linux. Has been used and is working fine for recursive folder/file transfer.Check this link... http://www.ncftp.com/Use WGet instead.  It supports HTTP and FTP protocols.Good Luck!reference: http://linux.about.com/od/commands/l/blcmdl1_wget.htmIf you want to stick to command line FTP, you should try NcFTP. Then you can use get -R to recursively get a folder. You will also get completion.If you can, I strongly suggest you tar and bzip (or gzip, whatever floats your boat) the directory on the remote machine\xe2\x80\x94for a directory of any significant size, the bandwidth savings will probably be worth the time to zip/unzip.wget -r ftp://urlWork perfectly for Redhat and UbuntuYou should not use ftp. Like telnet it is not using secure protocols, and passwords are transmitted in clear text. This makes it very easy for third parties to capture your username and password.To copy remote directories remotely, these options are better:rsync is the best-suited tool if you can login via ssh, because it copies only the differences, and can easily restart in the middle in case the connection breaks.ssh -r is the second-best option to recursively copy directory structures.See:rsync man pagessh man pageTry mget:You might also need to switch off the prompt so it does not ask for every file (see the propmt command)But using scp or rsync over ssh is probably better than ftp if you can.To recap:toggle the prompt by PROMPT command.Usage: