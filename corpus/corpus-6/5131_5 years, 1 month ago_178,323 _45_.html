I have come across many NoSQL databases and SQL databases. There are varying parameters to measure the strength and weaknesses of these databases and scalability is one of them. What is the difference between horizontally and vertically scaling these databases?Horizontal scaling means that you scale by adding more machines into your pool of resources whereas Vertical scaling means that you scale by adding more power (CPU, RAM) to an existing machine.An easy way to remember this is to think of a machine on a server rack, we add more machines across the horizontal direction and add more resources to a machine in the vertical direction.                  In a database world horizontal-scaling is often based on partitioning of the data i.e. each node contains only part of the data , in vertical-scaling the data resides on a single node and scaling is done through multi-core i.e. spreading the load between the CPU and RAM resources of that machine.With horizontal-scaling it is often easier to scale dynamically by adding more machines into the existing pool - Vertical-scaling is often limited to the capacity of a single machine, scaling beyond that capacity often involves downtime and comes with an upper limit.A good example for horizontal scaling is Cassandra , MongoDB .. and a good example for vertical scaling is MySQL - Amazon RDS (The cloud version of MySQL). It provides an easy way to scale vertically by switching from small to bigger machines. This process often involves downtime.In-Memory Data Grids such as GigaSpaces XAP, Coherence etc.. are often optimized for both horizontal and vertical scaling simply because they\'re not bound to disk. Horizontal-scaling through partitioning and vertical-scaling through multi-core support.  You can read more on this subject on my earlier posts:\nScale-out vs Scale-up and The Common Principles Behind the NOSQL Alternatives Horizontal scalability is the ability to increase capacity by connecting multiple hardware or software entities so that they work as a single logical unit. When servers are clustered, the original server is being scaled out horizontally. If a cluster requires more resources to improve performance and provide high availability (HA), an administrator can scale out by adding more servers to the cluster.An important advantage of horizontal scalability is that it can provide administrators with the ability to increase capacity on the fly. Another advantage is that in theory, horizontal scalability is only limited by how many entities can be connected successfully. The distributed storage system Cassandra, for example, runs on top of hundreds of commodity nodes spread across different data centers. Because the commodity hardware is scaled out horizontally, Cassandra is fault tolerant and does not have a single point of failure (SPoF). Vertical scalability, on the other hand, increases capacity by adding more resources, such as more memory or an additional CPU, to a machine. Scaling vertically, which is also called scaling up, usually requires downtime while new resources are being added and has limits that are defined by hardware. When Amazon RDS customers need to scale vertically, for example, they can switch from a smaller to a bigger machine, but Amazon\'s largest RDS instance has only 68 GB of memory.Scaling horizontally has both advantages and disadvantages.  For example, adding inexpensive commodity computers to a cluster might seem to be a cost-effective solution at first glance, but it\'s important for the administrator to know whether the licensing costs for those additional servers, the additional operations cost of  powering and cooling and the large footprint they will occupy in the data center truly makes scaling horizontally a better choice than scaling vertically. Horizontal Scaling - also referred to as "scale-out" is basically the addition of more machines or setting up a cluster or a distributed environment for your software system. This usually requires a load-balancer program which is a middle-ware component in the standard 3 tier client-server architectural model. Load-Balancer is responsible to distribute user requests (load) among the various back-end systems/machines/nodes in the cluster. Each of these back-end machines run a copy of your software and hence capable of servicing requests. This is just one of the various functions that load balancer may be performing. Another very common responsibility is "health-check" where the load balancer uses the "ping-echo" protocol or exchanges heartbeat messages with all the servers to ensure they are up and running fine.Load-Balancer distributes load by maintaining state of each machine -- how many requests are being served by each machine, which machine is idle, which machine is over-loaded with queued requests etc. So the load balancing algorithm considers such things before redirecting the request to an appropriate server machine. It also takes into account the network overhead and might choose the server in the nearest data-center provided it is available to service the requests. The request-response can also be done in 2 different ways:Load Balancer always acts as an intermediary program for every response - In this case, once the request has been handed over to the server by the load balancer, any response from the server to the user will go through the load balancer. So the server machines that are actually servicing the request will never directly interface with the user machine running the client application. The machine hosting the load balancer program will be handling all the requests/responses to and from the user.Load Balancer does not act as an intermediary for the responses coming from the server machine - In this case, once the server has received the request from load-balancer, it bypasses the load balancer and communicates it responses directly to the client. Setting up a cluster and load-balancer as a front-end interface to the client application does not really complete our scale-out architecture and design. There are still lots of critical questions to be answered and a number of key design decisions to be made which will affect the overall properties of our system.We first need to identify our business goals and areas where we would like to add value. These goals will give rise to various requirements. We should then ask ourselves various questions with respect to different systemic properties.Will such a design address our performance requirements ? What performance characteristics do we care about ? \nIs it the overall system throughput where we are interested in serving    maximum number of requests in any given time ?\nOr is it the system\'s response time where we design for sending back      the response to client in as less time as possible ?\nBoth these and many other types of performance characteristics are related to each other.Will such a design address our availability requirements ? Is the system fault-tolerant ? If so, what is the degree of it ?Is such a design reliable ? Does it impact the correctness ? We should not forget that 100% correctness is an implicit goal of any system.Are we really meeting our scalability goals ? Might be achieving the short-term or immediate ones, but what is going to happen in the long run ?All these kinds of requirements should have quantifiable measures associated with them. We should then make important design decisions by questioning ourselves, developing prototypes, and refining the design.Firstly, is using load-balancer the only approach to distribute load and horizontally scale the system ?Do the various back-end servers or nodes communicate with each other ?\nIf yes, then how does the system address the situation where one or          more nodes go down -- permanently or temporarily ?\nIf yes, then how does the system address the situation where the       network connecting the nodes is down, but all the nodes are up and running ? Most importantly, do we have to differentiate between these two situations ? How ?All this is what makes a distributed system so interesting and challenging to design and implement. Vertical Scaling -  also referred to as "scale-up" approach is an attempt to increase the capacity of a single machine :\nBy adding more processing power\nBy adding more storage\nMore memory etc\nSummary:What is important here is to understand the differences between these 2 scaling approaches, identify what suits our requirements, and see if the application really fits the model we choose.As you would have understood by now, horizontal scaling comes with overhead in the form of cluster setup, management, and maintenance costs and complexities. The design gets increasingly complex and programming model changes. So simply throwing in new hardware and adding more nodes or machines is not the way to start. First, see if the requirements can be met by increasing the capacity or tuning characteristics of a single machine. If not, then go with the scale-out approach or a combination of both.There is an additional architecture that wasn\'t mentioned - SQL-based database services that enable horizontal scaling without the complexity of manual sharding. These services do the sharding in the background, so they enable you to run a traditional SQL database and scale out like you would with NoSQL engines like MongoDB or CouchDB. Two services I am familiar with are EnterpriseDB for PostgreSQL and Xeround for MySQL. I saw an in-depth post by Xeround which explains why scale-out on SQL databases is difficult and how they do it differently - treat this with a grain of salt as it is a vendor post. Also check out Wikipedia\'s Cloud Database entry, there is a nice explanation of SQL vs. NoSQL and service vs. self-hosted, a list of vendors and scaling options for each combination. ;)Yes scaling horizontally means adding more machines, but it also implies that the machines are equal in the cluster. MySQL can scale horizontally in terms of Reading data, through the use of replicas, but once it reaches capacity of the server mem/disk, you have to begin sharding data across servers. This becomes increasingly more complex. Often keeping data consistent across replicas is a problem as replication rates are often too slow to keep up with data change rates. Couchbase is also a fantastic NoSQL Horizontal Scaling database, used in many commercial high availability applications and games and arguably the highest performer in the category. It partitions data automatically across cluster, adding nodes is simple, and you can use commodity hardware, cheaper vm instances (using Large instead of High Mem, High Disk machines at AWS for instance). It is built off the Membase (Memcached) but adds persistence. Also, in the case of Couchbase, every node can do reads and writes, and are equals in the cluster, with only failover replication (not full dataset replication across all servers like in mySQL).Performance-wise, you can see an excellent Cisco benchmark: http://blog.couchbase.com/understanding-performance-benchmark-published-cisco-and-solarflare-using-couchbase-serverHere is a great blog post about Couchbase Architecture: http://horicky.blogspot.com/2012/07/couchbase-architecture.htmlTraditional relational databases where designed as client/server database systems. They can be scaled horizontally but the process to do so tends to be complex and error prone. NewSQL databases likeNuoDB are memory-centric distributed database systems designed to scale out horizontally while maintaining the SQL/ACID properties of traditional RDBMS.For more information on NuoDB, read their technical whitepaper at http://goo.gl/uzLIWB. SQL databases like Oracle, db2 also support Horizontal scaling through Shared disk cluster. For example Oracle RAC,  IBM DB2 purescale or Sybase ASE Cluster edition. New node can be added to Oracle RAC system or DB2 purescale system to achieve horizontal scaling.But the approach is different from noSQL databases (like mongodb, CouchDB or IBM Cloudant) is that the data sharding is not part of Horizontal scaling.  In noSQL databases data is shraded during horizontal scaling.