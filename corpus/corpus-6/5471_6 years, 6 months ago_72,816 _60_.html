Are there any Ruby / Python features that are blocking implementation of optimizations (e.g. inline caching) V8 engine has?Python is co-developed by Google guys so it shouldn\'t be blocked by software patents. Or this is rather matter of resources put into the V8 project by Google. What blocks Ruby, Python to get Javascript V8 speed?Nothing.Well, okay: money. (And time, people, resources, but if you have money, you can buy those.)V8 has a team of brilliant, highly-specialized, highly-experienced (and thus highly-paid) engineers working on it, that have decades of experience (I\'m talking individually – collectively it\'s more like centuries) in creating high-performance execution engines for dynamic OO languages. They are basically the same people who also created the Sun HotSpot JVM (among many others).Lars Bak, the lead developer, has been literally working on VMs for 25 years (and all of those VMs have lead up to V8), which is basically his entire (professional) life. Some of the people writing Ruby VMs aren\'t even 25 years old.Are there any Ruby / Python features that are blocking implementation of optimizations (e.g. inline caching) V8 engine has?Given that at least IronRuby, JRuby, MagLev, MacRuby and Rubinius have either monomorphic (IronRuby) or polymorphic inline caching, the answer is obviously no.Modern Ruby implementations already do a great deal of optimizations. For example, for certain operations, Rubinius\'s Hash class is faster than YARV\'s. Now, this doesn\'t sound terribly exciting until you realize that Rubinius\'s Hash class is implemented in 100% pure Ruby, while YARV\'s is implemented in 100% hand-optimized C.So, at least in some cases, Rubinius can generate better code than GCC!Or this is rather matter of resources put into the V8 project by Google.Yes. Not just Google. The lineage of V8\'s source code is 25 years old now. The people who are working on V8 also created the Self VM (to this day one of the fastest dynamic OO language execution engines ever created), the Animorphic Smalltalk VM (to this day one of the fastest Smalltalk execution engines ever created), the HotSpot JVM (the fastest JVM ever created, probably the fastest VM period) and OOVM (one of the most efficient Smalltalk VMs ever created).In fact, Lars Bak, the lead developer of V8, worked on every single one of those, plus a few others.There\'s a lot more impetus to highly optimize JavaScript interpretors which is why we see so many resources being put into them between Mozilla, Google, and Microsoft. JavaScript has to be downloaded, parsed, compiled, and run in real time while a (usually impatient) human being is waiting for it, it has to run WHILE a person is interacting with it, and it\'s doing this in an uncontrolled client-end environment that could be a computer, a phone, or a toaster. It HAS to be efficient in order to run under these conditions effectively.Python and Ruby are run in an environment controlled by the developer/deployer. A beefy server or desktop system generally where the limiting factor will be things like memory or disk I/O and not execution time. Or where non-engine optimizations like caching can be utilized. For these languages it probably does make more sense to focus on language and library feature set over speed optimization.The side benefit of this is that we have two great high performance open source JavaScript engines that can and are being re-purposed for all manner of applications such as Node.js.A good part of it has to do with community. Python and Ruby for the most part have no corporate backing. No one gets paid to work on Python and Ruby full-time (and they especially don\'t get paid to work on CPython or MRI the whole time). V8, on the other hand, is backed by the most powerful IT company in the world.Furthermore, V8 can be faster because the only thing that matters to the V8 people is the interpreter -- they have no standard library to work on, no concerns about language design. They just write the interpreter. That\'s it.It has nothing to do with intellectual property law. Nor is Python co-developed by Google guys (its creator works there along with a few other committers, but they don\'t get paid to work on Python).Another obstacle to Python speed is Python 3. Its adoption seems to be the main concern of the language developers -- to the point that they have frozen development of new language features until other implementations catch up.On to the technical details, I don\'t know much about Ruby, but Python has a number of places where optimizations could be used (and Unladen Swallow, a Google project, started to implement these before biting the dust). Here are some of the optimizations that they planned. I could see Python gaining V8 speed in the future if a JIT a la PyPy gets implemented for CPython, but that does not seem likely for the coming years (the focus right now is Python 3 adoption, not a JIT).Many also feel that Ruby and Python could benefit immensely from removing their respective global interpreter locks.You also have to understand that Python and Ruby are both much heavier languages than JS -- they provide far more in the way of standard library, language features, and structure. The class system of object-orientation alone adds a great deal of weight (in a good way, I think). I almost think of Javascript as a language designed to be embedded, like Lua (and in many ways, they are similar). Ruby and Python have a much richer set of features, and that expressiveness is usually going to come at the cost of speed.Performance doesn\'t seem to be a major focus of the core Python developers, who seem to feel that "fast enough" is good enough, and that features that help programmers be more productive are more important than features that help computers run code faster. Indeed, however, there was a (now abandoned) Google project, unladen-swallow, to produce a faster Python interpreter compatible with the standard interpreter. PyPy is another project that intends to produce a faster Python. There is also Psyco, the forerunner of PyPy, which can provide performance boosts to many Python scripts without changing out the whole interpreter, and Cython, which lets you write high-performance C libraries for Python using something very much like Python syntax.Misleading question. V8 is a JIT (a just in time compiler) implementation of JavaScript and in its most popular non-browser implementation Node.js it is constructed around an event loop. CPython is not a JIT & not evented. But these exist in Python most commonly in the PyPy project - a CPython 2.7 (and soon to be 3.0+) compatible JIT. And there are loads of evented server libraries like Tornado for example. Real world tests exist between PyPy running Tornado vs Node.js and the performance differences are slight.I just ran across this question and there is also a big technical reason for the performance difference that wasn\'t mentioned.  Python has a very large ecosystem of powerful software extensions, but most of these extensions are written in C or other low-level languages for performance and are heavily tied to the CPython API. There are lots of well-known techniques (JIT, modern garbage collector, etc) that could be used to speed up the CPython implementation but all would require substantial changes to the API, breaking most of the extensions in the process.  CPython would be faster, but a lot of what makes Python so attractive (the extensive software stack) would be lost.  Case in point, there are several faster Python implementations out there but they have little traction compared to CPython.Because of different design priorities and use case goals I believe.In general main purpose of scripting (a.k.a. dynamic) languages is to be a "glue" between calls of native functions. And these native functions shall a) cover most critical/frequently used areas and b) be as effective as possible.Here is an example: \njQuery sort causing iOS Safari to freeze \nThe freeze there is caused by excessive use of get-by-selector calls. If get-by-selector would  be implemented in native code and effectively it will be no such problem at all.Consider ray-tracer demo that is frequently used demo for V8 demonstration. In Python world it can be implemented in native code as Python provides all facilities for native extensions. But in V8 realm (client side sandbox) you have no other options rather than making VM to be [sub]effective as possible. And so the only option see ray-tracer implementation there is by using script code. So different priorities and motivations.In Sciter I\'ve made a test by implementing pretty much full jQurey core natively. On practical tasks like ScIDE (IDE made of HTML/CSS/Script) I believe such solution works significantly better then any VM optimizations.As other people have mentioned, Python has a performant JIT compiler in the form of PyPy.Making meaningful benchmarks is always subtle, but I happen to have a simple benchmark of K-means written in different languages - you can find it here. One of the constraints was that the various languages should all implement the same algorithm and should strive to be simple and idiomatic (as opposed to optimized for speed). I have written all the implementations, so I know I have not cheated, although I cannot claim for all languages that what I have written is idiomatic (I only have a passing knowledge of some of those).I do not claim any definitive conclusion, but PyPy was among the fastest implementations I got, far better than Node. CPython, instead, was at the slowest end of the ranking.Just like V8 is just an implementation for JS, CPython is just one implementation for Python. Pypy has performances matching V8\'s.Also, there the problem of perceived performance : since V8 is natively non blocking, Web dev leads to more performant projects because you save the IO wait. And V8 is mainly used for dev Web where IO is key, so they compare it to similar projects. But you can use Python in many, many other areas than web dev. And you can even use C extensions for a lot of tasks, such as scientific computations or encryption, and crunch data with blazing perfs.But on the web, most popular Python and Ruby projects are blocking. Python, especially, has the legacy of the synchronous WSGI standard, and frameworks like the famous Django are based on it.You can write asynchronous Python (like with Twisted, Tornado, gevent or asyncio) or Ruby. But it\'s not done often. The best tools are still blocking.However, they are some reasons for why the default implementations in Ruby and Python are not as speedy as V8.Like J\xc3\xb6rg W Mittag pointed out, the guys working on V8 are VM geniuses. Python is dev by a bunch a passionate people, very good in a lot of domains, but are not as specialized in VM tuning.The Python Software foundation has very little money : less than 40k in a year to invest in Python. This is kinda crazy when you think big players such as Google, Facebook or Apple are all using Python, but it\'s the ugly truth : most work is done for free. The language that powers Youtube and existed before Java has been handcrafted by volunteers. They are smart and dedicated volunteers, but when they identify they need more juice in a field, they can\'t ask for 300k to hire a top notch specialist for this area of expertise. They have to look around for somebody who would do it for free.While this works, it means you have to be very a careful about your priorities. Hence, now we need to look at :Even with the latest modern features, writing Javascript is terrible. You have scoping issues, very few collections, terrible string and array manipulation, almost no stdlist apart from date, maths and regexes, and no syntactic sugar even for very common operations.But in V8, you\'ve got speed.This is because, speed was the main objective for Google, since it\'s a bottleneck for page rendering in Chrome.In Python, usability is the main objective. Because it\'s almost never the bottleneck on the project. The scarce resource here is developer time. It\'s optimized for the developer.Because JavaScript implementations need not care about backwards compatibility of their bindings.Until recently the only users of the JavaScript implementations have been web browsers.  Due to security requirements, only the web browser vendors had the privilege to extend the functionality by writing bindings to the runtimes.  Thus there was no need keep the C API of the bindings backwards compatible, it was permissible to request the web browser developers update their source code as the JavaScript runtimes evolved; they were working together anyways.  Even V8, which was a latecomer to the game, and also lead by a very very experienced developer, have changed the API as it became better.OTOH Ruby is used (mainly) on the server-side.  Many popular ruby extensions are written as C bindings (consider an RDBMS driver).  In other words, Ruby would have never succeeded without maintaining the compatibility.Today, the difference still exist to some extent.  Developers using node.js are complaining that it is hard to keep their native extensions backwards compatible, as V8 changes the API over time (and that is one of the reasons node.js has been forked).  IIRC ruby is still taking a much more conservative approach in this respect.V8 is fast due to the JIT, Crankshaft, the type inferencer and data-optimized code. Tagged pointers, NaN-tagging of doubles.\nAnd of course it does normal compiler optimizations in the middle. The plain ruby, python and perl engines don\'t do neither of the those, just minor basic optimizations.The only major vm which comes close is luajit, which doesn\'t even do type inference, constant folding, NaN-tagging nor integers, but uses similar small code and data structures, not as fat as the bad languages.\nAnd my prototype dynamic languages, potion and p2 have similar features as luajit, and outperform v8. With an optional type system, "gradual typing", you could easily outperform v8, as you can bypass crankshaft. See dart.The known optimized backends, like pypy or jruby still suffer from various over-engineering techniques.