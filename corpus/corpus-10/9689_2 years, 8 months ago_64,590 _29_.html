What are the differences between Apache Spark and Apache Flink?Will Apache Flink replace Hadoop?At first what do they have in common? Flink and Spark are both general-purpose data processing platforms and top level projects of the Apache Software Foundation (ASF). They have a wide field of application and are usable for dozens of big data scenarios. Thanks to expansions like SQL queries (Spark: Spark SQL, Flink: MRQL), Graph processing (Spark: GraphX, Flink: Spargel (base) and Gelly(library)), machine learning (Spark: MLlib, Flink: Flink ML) and stream processing (Spark Streaming, Flink Streaming). Both are capable of running in standalone mode, yet many are using them on top of Hadoop (YARN, HDFS). They share a strong performance due to their in memory nature.However, the way they achieve this variety and the cases they are specialized on differ.Differences:\nAt first I\'d like to provide two links which go in some detail on differences between Flink and Spark before summing it up. If you have the time have a look at Apache Flink is the 4G of BigData Analytics Framework and Flink and Spark Similarities and DifferencesIn contrast to Flink, Spark is not capable of handling data sets larger than the RAM before version 1.5.xFlink is optimized for cyclic or iterative processes by using iterative transformations on collections. This is achieved by an optimization of join algorithms, operator chaining and reusing of partitioning and sorting. However, Flink is also a strong tool for batch processing. Flink streaming processes data streams as true streams, i.e., data elements are immediately "pipelined" though a streaming program as soon as they arrive. This allows to perform flexible window operations on streams. It is even capable of handling late data in streams by the use of watermarks. Furthermore Flink provides a very strong compatibility mode which makes it possible to use your existing storm, map reduce, ... code on the flink execution engineSpark on the other hand is based on resilient distributed datasets (RDDs). This (mostly) in-memory datastructure gives the power to sparks functional programming paradigm. It is capable of big batch calculations by pinning memory. Spark streaming wraps data streams into mini-batches, i.e., it collects all data that arrives within a certain period of time and runs a regular batch program on the collected data. While the batch program is running, the data for the next mini-batch is collected.Will Flink replace Hadoop? No, it will not. Hadoop consists of different parts:HDFS and YARN are still necessary as integral part of BigData clusters. Those two are building the base for other distributed technologies like distributed query engines or distributed databases. The main use-case for MapReduce is batch processing for data sets larger than the RAM of the cluster while Flink is designed for stream and iterative processing. So in general those two can co-exist even though I would strongly recommend to go with flinks stronger and more easy to use batch-capabilities.As per Apache Flink & Spark documentation pages:Apache Flink is an open source platform for distributed stream and batch data processingApache Spark\xe2\x84\xa2 is a fast and general engine for large-scale data processing.Real time stream processing is USP of Apache Flink.Flink provides expressive APIs that enable programmers to quickly develop streaming data applications.Flink is built to be a good YARN citizen (which Spark has not quite achieved yet), and it can run existing MapReduce jobs directly on its execution engine.Have a look at this article form infoworld bog posted by  Ian Pointer for more details.Key differences from blog posted by VON HANS-PETER ZORN UND JASIR EL-SOBHYRegarding your second question, neither Flink nor Spark can replace Hadoop.Flink is a replacement for Hadoop MapReduce; which works in both batch and streaming modes, eliminating the map and reduce jobs in favour of a directed graph approach that leverages in-memory storage for massive performance gains. HDFS (Hadoop Distributed File System) and YARN ( Yet Another Resource Negotiator), which are part of big Hadoop eco system can\'t be replaced by FlinkHave a look at this flink-vs-spark presentation by Slim Baltagi, Director of Big data engineering, Capital One.Flink\xe2\x80\x99s programs are optimized by cost-based optimizer (e.g: SQL engines). So Flink applications will be required re-configuration and maintenance whenever the cluster characteristics change and the data evolves over time.From the point of view of a developer:At the moment: If you want to get a Job as fast as possible in the big data environment, learn Spark, because it\'s mostly used on the market.But in my opinion Flink is the better choice, because I don\'t have to face so much "out-of-memory" problems during the development. Flink has it\'s own Memory Manager, so in general you don\'t need to care about it.Flink\'s one of the unique feature is, processing out-of-order data Streams using WatermarksSpark provides near real-time streaming due to micro-batching architecture whereas Apache Flink provides true real realtime streamig due pure streamig architecture based on Kappa Architecture. This is proven by Yahoo streaming Benchmark Application and then again by extended yahoo streaming application.. Go through the video which explains this detail and helped me understand it. https://www.youtube.com/watch?v=WTBsMTpR-mE