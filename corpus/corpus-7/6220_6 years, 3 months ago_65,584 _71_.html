Multiplication and division can be achieved using bit operators, for exampleand so on.Is it actually faster to use say (i<<3)+(i<<1) to multiply with 10 than using i*10 directly? Is there any sort of input that can\'t be multiplied or divided in this way?Short answer:  Not likely.Long answer:\nYour compiler has an optimizer in it that knows how to multiply as quickly as your target processor architecture is capable.  Your best bet is to tell the compiler your intent clearly (i.e. i*2 rather than i << 1) and let it decide what the fastest assembly/machine code sequence is.  It\'s even possible that the processor itself has implemented the multiply instruction as a sequence of shifts & adds in microcode.Bottom line--don\'t spend a lot of time worrying about this.  If you mean to shift, shift.  If you mean to multiply, multiply.  Do what is semantically clearest--your coworkers will thank you later.  Or, more likely, curse you later if you do otherwise.Just a concrete point of measure: many years back, I benchmarked two\nversions of my hashing algorithm:andOn every machine I benchmarked it on, the first was at least as fast as\nthe second.  Somewhat surprisingly, it was sometimes faster (e.g. on a\nSun Sparc).  When the hardware didn\'t support fast multiplication (and\nmost didn\'t back then), the compiler would convert the multiplication\ninto the appropriate combinations of shifts and add/sub.  And because it\nknew the final goal, it could sometimes do so in less instructions than\nwhen you explicitly wrote the shifts and the add/subs.Note that this was something like 15 years ago.  Hopefully, compilers\nhave only gotten better since then, so you can pretty much count on the\ncompiler doing the right thing, probably better than you could.  (Also,\nthe reason the code looks so C\'ish is because it was over 15 years ago.\nI\'d obviously use std::string and iterators today.)In addition to all the other good answers here, let me point out another reason to not use shift when you mean divide or multiply. I have never once seen someone introduce a bug by forgetting the relative precedence of multiplication and addition. I have seen bugs introduced when maintenance programmers forgot that "multiplying" via a shift is logically a multiplication but not syntactically of the same precedence as multiplication. x * 2 + z and x << 1 + z are very different!If you\'re working on numbers then use arithmetic operators like + - * / %. If you\'re working on arrays of bits, use bit twiddling operators like & ^ | >> . Don\'t mix them; an expression that has both bit twiddling and arithmetic is a bug waiting to happen.This depends on the processor and the compiler. Some compilers already optimize code this way, others don\'t.\nSo you need to check each time your code needs to be optimized this way.Unless you desperately need to optimize, I would not scramble my source code just to save an assembly instruction or processor cycle.Is it actually faster to use say (i<<3)+(i<<1) to multiply with 10 than using i*10 directly?It might or might not be on your machine - if you care, measure in your real-world usage.Benchmarking is very difficult to do meaningfully, but we can look at a few facts.  From http://www.penguin.cz/~literakl/intel/s.html#SAL and    http://www.penguin.cz/~literakl/intel/i.html#IMUL we get an idea of x86 clock cycles needed for arithmetic shift and multiplication.  Say we stick to "486" (the newest one listed), 32 bit registers and immediates, IMUL takes 13-42 cycles and IDIV 44.  Each SAL takes 2, and adding 1, so even with a few of those together shifting superficially looks like a winner.These days, with the core i7:(from http://software.intel.com/en-us/forums/showthread.php?t=61481)The latency is 1 cycle for an integer addition and 3 cycles for an integer multiplication. You can find the latencies and thoughput in Appendix C of the "Intel\xc2\xae 64 and IA-32 Architectures Optimization Reference Manual", which is located on http://www.intel.com/products/processor/manuals/.(from some Intel blurb)Using SSE, the Core i7 can issue simultaneous add and multiply instructions, resulting in a peak rate of 8 floating-point operations (FLOP) per clock cycleThat gives you an idea of how far things have come.  The optimisation trivia - like bit shifting versus * - that was been taken seriously even into the 90s is just obsolete now.  Bit-shifting is still faster, but for non-power-of-two mul/div by the time you do all your shifts and add the results it\'s slower again.  Then, more instructions means more cache faults, more potential issues in pipelining, more use of temporary registers may mean more saving and restoring of register content from the stack... it quickly gets too complicated to quantify all the impacts definitively but they\'re predominantly negative.More generally, your question is tagged C and C++.  As 3rd generation languages, they\'re specifically designed to hide the details of the underlying CPU instruction set.  To satisfy their language Standards, they must support multiplication and shifting operations (and many others) even if the underlying hardware doesn\'t.  In such cases, they must synthesize the required result using many other instructions.  Similarly, they must provide software support for floating point operations if the CPU lacks it and there\'s no FPU.  Modern CPUs all support * and <<, so this might seem absurdly theoretical and historical, but the significance thing is that the freedom to choose implementation goes both ways: even if the CPU has an instruction that implements the operation requested in the source code in the general case, the compiler\'s free to choose something else that it prefers because it\'s better for the specific case the compiler\'s faced with.Examples (with a hypothetical assembly language)Instructions like exclusive or (xor) have no relationship to the source code, but xor-ing anything with itself clears all the bits, so it can be used to set something to 0.  Source code that implies memory addresses may not entail any being used.These kind of hacks have been used for as long as computers have been around.  In the early days of 3GLs, to secure developer uptake the compiler output had to satisfy the existing hardcore hand-optimising assembly-language dev. community that the produced code wasn\'t slower, more verbose or otherwise worse.  Compilers quickly adopted lots of great optimisations - they became a better centralised store of it than any individual assembly language programmer could possibly be, though there\'s always the chance that they miss a specific optimisation that happens to be crucial in a specific case - humans can sometimes nut it out and grope for something better while compilers just do as they\'ve been told until someone feeds that experience back into them.So, even if shifting and adding is still faster on some particular hardware, then the compiler writer\'s likely to have worked out exactly when it\'s both safe and beneficial.If your hardware changes you can recompile and it\'ll look at the target CPU and make another best choice, whereas you\'re unlikely to ever want to revisit your "optimisations" or list which compilation environments should use multiplication and which should shift.  Think of all the non-power-of-two bit-shifted "optimisations" written 10+ years ago that are now slowing down the code they\'re in as it runs on modern processors...!Thankfully, good compilers like GCC can typically replace a series of bitshifts and arithmetic with a direct multiplication when any optimisation is enabled (i.e. ...main(...) { return (argc << 4) + (argc << 2) + argc; } -> imull   $21, 8(%ebp), %eax) so a recompilation may help even without fixing the code, but that\'s not guaranteed.Strange bitshifting code implementing multiplication or division is far less expressive of what you were conceptually trying to achieve, so other developers will be confused by that, and a confused programmer\'s more likely to introduce bugs or remove something essential in an effort to restore seeming sanity.  If you only do non-obvious things when they\'re really tangibly beneficial, and then document them well (but don\'t document other stuff that\'s intuitive anyway), everyone will be happier.If you have some extra knowledge, such as that your int will really only be storing values x, y and z, then you may be able to work out some instructions that work for those values and get you your result more quickly than when the compiler\'s doesn\'t have that insight and needs an implementation that works for all int values.  For example, consider your question:Multiplication and division can be achieved using bit operators...You illustrate multiplication, but how about division?According to the C++ Standard 5.8:-3- The value of E1 >> E2 is E1 right-shifted E2 bit positions. If E1 has an unsigned type or if E1 has a signed type and a nonnegative value, the value of the result is the integral part of the quotient of E1 divided by the quantity 2 raised to the power E2. If E1 has a signed type and a negative value, the resulting value is implementation-defined. So, your bit shift has an implementation defined result when x is negative: it may not work the same way on different machines.  But, / works far more predictably.  (It may  not be perfectly consistent either, as different machines may have different representations of negative numbers, and hence different ranges even when there are the same number of bits making up the representation.)You may say "I don\'t care... that int is storing the age of the employee, it can never be negative".  If you have that kind of special insight, then yes - your >> safe optimisation might be passed over by the compiler unless you explicitly do it in your code.  But, it\'s risky and rarely useful as much of the time you won\'t have this kind of insight, and other programmers working on the same code won\'t know that you\'ve bet the house on some unusual expectations of the data you\'ll be handling... what seems a totally safe change to them might backfire because of your "optimisation".Is there any sort of input that can\'t be multiplied or divided in this way?Yes... as mentioned above, negative numbers have implementation defined behaviour when "divided" by bit-shifting.Just tried on my machine compiling this :When disassembling it produces output :This version is faster than your hand-optimized code with pure shifting and addition.You really never know what the compiler is going to come up with, so it\'s better to simply write a normal multiplication and let him optimize the way he wants to, except in very precise cases where you know the compiler cannot optimize.Shifting is generally a lot faster than multiplying at an instruction level but you may well be wasting your time doing premature optimisations. The compiler may well perform these optimisations at compiletime. Doing it yourself will affect readability and possibly have no effect on performance. It\'s probably only worth it to do things like this if you have profiled and found this to be a bottleneck.Actually the division trick, known as \'magic division\' can actually yield huge payoffs. Again you should profile first to see if it\'s needed. But if you do use it there are useful programs around to help you figure out what instructions are needed for the same division semantics. Here is an example : http://www.masm32.com/board/index.php?topic=12421.0An example which I have lifted from the OP\'s thread on MASM32:Would generate:Shift and integer multiply instructions have similar performance on most modern CPUs - integer multiply instructions were relatively slow back in the 1980s but in general this is no longer true. Integer multiply instructions may have higher latency, so there may still be cases where a shift is preferable. Ditto for cases where you can keep more execution units busy (although this can cut both ways).Integer division is still relatively slow though, so using a shift instead of division by a power of 2 is still a win, and most compilers will implement this as an optimisation. Note however that for this optimisation to be valid the dividend needs to be either unsigned or must be known to be positive. For a negative dividend the shift and divide are not equivalent!Output:So if you want to help the compiler then make sure the variable or expression in the dividend is explicitly unsigned.It completely depends on target device, language, purpose, etc. Pixel crunching in a video card driver? Very likely, yes!.NET business application for your department? Absolutely no reason to even look into it. For a high performance game for a mobile device it might be worth looking into, but only after easier optimizations have been performed. Don\'t do unless you absolutely need to and your code intent requires shifting rather than multiplication/division.In typical day - you could potentialy save few machine cycles (or loose, since compiler knows better what to optimize), but the cost doesn\'t worth it - you spend time on minor details rather than actual job, maintaining the code becomes harder and your co-workers will curse you. You might need to do it for high-load computations, where each saved cycle means minutes of runtime. But, you should optimize one place at a time and do performance tests each time to see if you really made it faster or broke compilers logic.As far as I know in some machines multiplication can need upto 16 to 32 machine cycle. So Yes, depending on the machine type, bitshift operators are faster than multiplication / division. However certain machine do have their math processor, which contains special instructions for multiplication/division.I agree with the marked answer by Drew Hall.  The answer could use some additional notes though.For the vast majority of software developers the processor and compiler are no longer relevant to the question.  Most of us are far beyond the 8088 and MS-DOS. It is perhaps only relevant for those who are still developing for embedded processors...At my software company Math (add/sub/mul/div) should be used for all mathematics.\nWhile Shift should be used when converting between data types eg. ushort to byte as n>>8 and not n/256.In the case of signed integers and right shift vs division, it can make a difference. For negative numbers, the shift rounds rounds towards negative infinity whereas division rounds towards zero. Of course the compiler will change the division to something cheaper, but it will usually change it to something that has the same rounding behavior as division, because it is either unable to prove that the variable won\'t be negative or it simply doesn\'t care.\nSo if you can prove that a number won\'t be negative or if you don\'t care which way it will round, you can do that optimization in a way that is more likely to make a difference.Python test performing same multiplication 100 million times against the same random numbers.So in doing a shift rather than multiplication/division by a power of two in python, there\'s a slight improvement (~10% for division; ~1% for multiplication).  If its a non-power of two, there\'s likely a considerable slowdown.Again these #s will change depending on your processor, your compiler (or interpreter -- did in python for simplicity).As with everyone else, don\'t prematurely optimize.  Write very readable code, profile if its not fast enough, and then try to optimize the slow parts.  Remember, your compiler is much better at optimization than you are.There are optimizations the compiler can\'t do because they only work for a reduced set of inputs.  Below there is c++ sample code that can do a faster division doing a 64bits "Multiplication by the reciprocal". Both numerator and denominator must be below certain threshold. Note that it must be compiled to use 64 bits instructions to be actually faster than normal division.