How to fix it?In some other python-based static blog apps, Chinese post can be published successfully.\nSuch as this app: http://github.com/vrypan/bucket3. In my site http://bc3.brite.biz/, Chinese post can be published successfully.Finally I got it:Let me check:The above shows the default encoding of python is utf8. Then the error is no more.Without seeing the source it\'s difficult to know the root cause, so I\'ll have to speak generally.UnicodeDecodeError: \'ascii\' codec can\'t decode byte generally happens when you try to convert a Python 2.x str that contains non-ASCII to a Unicode string without specifying the encoding of the original string.In brief, Unicode strings are an entirely separate type of Python string that does not contain any encoding. They only hold Unicode point codes and therefore can hold any Unicode point from across the entire spectrum. Strings contain encoded text, beit UTF-8, UTF-16, ISO-8895-1, GBK, Big5 etc. Strings are decoded to Unicode and Unicodes are encoded to strings. Files and text data are always transferred in encoded strings.The Markdown module authors probably use unicode() (where the exception is thrown) as a quality gate to the rest of the code - it will convert ASCII or re-wrap existing Unicodes strings to a new Unicode string. The Markdown authors can\'t know the encoding of the incoming string so will rely on you to decode strings to Unicode strings before passing to Markdown.Unicode strings can be declared in your code using the u prefix to strings. E.g.Unicode strings may also come from file, databases and network modules. When this happens, you don\'t need to worry about the encoding.Conversion from str to Unicode can happen even when you don\'t explicitly call unicode().The following scenarios cause UnicodeDecodeError exceptions:In the following diagram, you can see how the word caf\xc3\xa9 has been encoded in either "UTF-8" or "Cp1252" encoding depending on the terminal type. In both examples, caf is just regular ascii. In UTF-8, \xc3\xa9 is encoded using two bytes. In "Cp1252", \xc3\xa9 is 0xE9 (which is also happens to be the Unicode point value (it\'s no coincidence)). The correct decode() is invoked and conversion to a Python Unicode is successfull:\nIn this diagram, decode() is called with ascii (which is the same as calling unicode() without an encoding given). As ASCII can\'t contain bytes greater than 0x7F, this will throw a UnicodeDecodeError exception:It\'s good practice to form a Unicode sandwich in your code, where you decode all incoming data to Unicode strings, work with Unicodes, then encode to strs on the way out. This saves you from worrying about the encoding of strings in the middle of your code.If you need to bake non-ASCII into your source code, just create Unicode strings by prefixing the string with a u. E.g.To allow Python to decode your source code, you will need to add an encoding header to match the actual encoding of your file. For example, if your file was encoded as \'UTF-8\', you would use:This is only necessary when you have non-ASCII in your source code.Usually non-ASCII data is received from a file. The io module provides a TextWrapper that decodes your file on the fly, using a given encoding. You must use the correct encoding for the file - it can\'t be easily guessed. For example, for a UTF-8 file:my_unicode_string would then be suitable for passing to Markdown. If a UnicodeDecodeError from the read() line, then you\'ve probably used the wrong encoding value.The Python 2.7 CSV module does not support non-ASCII characters \xf0\x9f\x98\xa9. Help is at hand, however, with https://pypi.python.org/pypi/backports.csv.Use it like above but pass the opened file to it:Most Python database drivers can return data in Unicode, but usually require a little configuration. Always use Unicode strings for SQL queries.In the connection string add:Add:Web pages can be encoded in just about any encoding. The Content-type header should contain a charset field to hint at the encoding. The content can then be decoded manually against this value. Alternatively, Python-Requests returns Unicodes in response.text.If you must decode strings manually, you can simply do my_string.decode(encoding), where encoding is the appropriate encoding. Python 2.x supported codecs are given here: Standard Encodings. Again, if you get UnicodeDecodeError then you\'ve probably got the wrong encoding.Work with Unicodes as you would normal strs.print writes through the stdout stream. Python tries to configure an encoder on stdout so that Unicodes are encoded to the console\'s encoding. For example, if a Linux shell\'s locale is en_GB.UTF-8, the output will be encoded to UTF-8. On Windows, you will be limited to an 8bit code page.An incorrectly configured console, such as corrupt locale, can lead to unexpected print errors. PYTHONIOENCODING environment variable can force the encoding for stdout. Just like input, io.open can be used to transparently convert Unicodes to encoded byte strings.The same configuration for reading will allow Unicodes to be written directly.Python 3 in no more Unicode capable as Python 2.x is, but the regular str is now a Unicode string and the old str is now bytes. The default encoding is now UTF-8, so if you .decode() a byte string without giving an encoding, Python 3 uses UTF-8 encoding. This probably fixes 50% of people\'s Unicode problems.Further, open() operates in text mode by default, so returns decoded str (Unicode ones). The encoding is derived from your locale, which tends to be UTF-8 on Un*x systems or an 8-bit code page, such as windows-1251, on Windows boxes.This is the classic "unicode issue".   I believe that explaining this is beyond the scope of a StackOverflow answer to completely explain what is happening.  It is well explained here.In very brief summary, you have passed something that is being interpreted as a string of bytes to something that needs to decode it into Unicode characters, but the default codec (ascii) is failing.The presentation I pointed you to provides advice for avoiding this.   Make your code a "unicode sandwich".   In Python 2, the use of "from __future__ import unicode_literals" helps.Update: how can the code be fixed:OK - in your variable "source" you have some bytes.  It is not clear from your question how they got in there - maybe you read them from a web form?   In any case, they are not encoded with ascii, but python is trying to convert them to unicode assuming that they are.  You need to explicitly tell it what the encoding is.   This means that you need to know what the encoding is!   That is not always easy, and it depends entirely on where this string came from.   You could experiment with some common encodings - for example UTF-8.   You tell unicode() the encoding as a second parameter:In some cases, when you check your default encoding (print sys.getdefaultencoding()), it returns that you are using ASCII. If you change to UTF-8, it doesn\'t work, depending on the content of your variable.\nI found another way:    I find the best is to always convert to unicode - but this is difficult to achieve because in practice you\'d have to check and convert every argument to every function and method you ever write that includes some form of string processing.So I came up with the following approach to either guarantee unicodes or byte strings, from either input. In short, include and use the following lambdas:Examples:Here\'s some more reasoning about this.This error happens mainly because your context requires a unicode string but what is passed is just a string.\nbefore you convert into code check if the string is already in unicode in which case you will get a TypeError: decoding Unicode is not supported as you are trying to convert into unicode a string that is already in unicode .Ideally check it before you convert as below:Adding on the above, the above does not remove the unsupported characters. It just changes the type but the non ascii still remains. In order to remove the characters use the below,I got the same problem with the string "Pasteler\xc3\x83\xc2\xada Mallorca" and I solved with:In a Django (1.9.10)/Python 2.7.5 project I have frequent UnicodeDecodeError exceptions; mainly when I try to feed unicode strings to logging. I made a helper function for arbitrary objects to basically format to 8-bit ascii strings and replacing any characters not in the table to \'?\'. I think it\'s not the best solution but since the default encoding is ascii (and i don\'t want to change it) it will do:add top of the python file. this will convert your code file as Unicode\nthis will not fixed all case. but this code same  me many times I had the same problem but it didn\'t work for Python 3. I followed this and it solved my problem:You have to set the encoding when you are reading/writing the file.Encode converts a unicode object in to a string object. I think you are trying to encode a string object. first convert your result into unicode object and then encode that unicode object into \'utf-8\'.\nfor example