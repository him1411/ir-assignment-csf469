sample code:The problem: it\'s not human readable. My (smart) users want to verify or even edit text files with JSON dumps. (and i\'d rather not use XML)Is there a way to serialize objects into utf-8 json string (instead of  \\uXXXX ) ?this doesn\'t help:this works, but if any sub-objects is a python-unicode and not utf-8, it\'ll dump garbage:i searched the json.dumps documentation but couldn\'t find something useful.i\'ll try to sum up the comments and answers by Martijn Pieters:(edit: 2nd thought after @Sebastian\'s comment and about a year later)there might be no is a built-in solution in json.dumps.i\'ll have to convert all strings to UTF8 Unicode the object before it\'s being JSON-ed.\ni\'ll use Mark\'s function that converts strings recuresively in a nested objectthe example I gave depends too much on my computer & IDE environment, and doesn\'t run the same on all computers.Thank you everybody :) Use the ensure_ascii=False switch to json.dumps(), then encode the value to UTF-8 manually:If you are writing this to a file, you can use io.open() instead of open() to produce a file object that encodes Unicode values for you as you write, then use json.dump() instead to write to that file:In Python 3, the built-in open() is an alias for io.open(). Do note that there is a bug in the json module where the ensure_ascii=False flag can produce a mix of unicode and str objects. The workaround for Python 2 then is:If you are passing in byte strings (type str in Python 2, bytes in Python 3) encoded to UTF-8, make sure to also set the encoding keyword:Note that your second sample is not valid Unicode; you gave it UTF-8 bytes as a unicode literal, that would never work:Only when I encoded that string to Latin 1 (whose unicode codepoints map one-to-one to bytes) then decode as UTF-8 do you see the expected output. That has nothing to do with JSON and everything to do with that you use the wrong input. The result is called a Mojibake.If you got that Unicode value from a string literal, it was decoded using the wrong codec. It could be your terminal is mis-configured, or that your text editor saved your source code using a different codec than what you told Python to read the file with. Or you sourced it from a library that applied the wrong codec. This all has nothing to do with the JSON library.UPDATE: This is wrong answer, but it\'s still useful to understand why it\'s wrong. See comments. How about unicode-escape?Peters\' python 2 workaround fails on an edge case:It was crashing on the .decode(\'utf8\') part of line 3.   I fixed the problem by making the program much simpler by avoiding that step as well as the special casing of ascii:easy like a cakeTo write to a fileTo print to stdinHere\'s my solution using json.dump():where SYSTEM_ENCODING is set to:The following is my understanding var reading answer above and google.  Using ensure_ascii=False in json.dumps is the right direction to solve this problem, as pointed out by Martijn. However, this may raise an exception:You need extra settings in either site.py or sitecustomize.py to set your sys.getdefaultencoding() correct. site.py is under lib/python2.7/ and sitecustomize.py is under lib/python2.7/site-packages.If you want to use site.py, under def setencoding(): change the first if 0: to if 1: so that python will use your operation system\'s locale.If you prefer to use sitecustomize.py, which may not exist if you haven\'t created it. simply put these lines:Then you can do some Chinese json output in utf-8 format, such as:You will get an utf-8 encoded string, rather than \\u escaped json string.To verify your default encoding:You should get "utf-8" or "UTF-8" to verify your site.py or sitecustomize.py settings.Please note that you could not do sys.setdefaultencoding("utf-8") at interactive python console.