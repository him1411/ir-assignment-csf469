I want to convert a table, represented as a list of lists, into a Pandas DataFrame. As an extremely simplified example:What is the best way to convert the columns to the appropriate types, in this case columns 2 and 3 into floats? Is there a way to specify the types while converting to DataFrame? Or is it better to create the DataFrame first and then loop through the columns to change the type for each column? Ideally I would like to do this in a dynamic way because there can be hundreds of columns and I don\'t want to specify exactly which columns are of which type. All I can guarantee is that each columns contains values of the same type.You can use pd.to_numeric (introduced in version 0.17) to convert a column or a Series to a numeric type. The function can also be applied over multiple columns of a DataFrame using apply.Importantly, the function also takes an errors key word argument that lets you force not-numeric values to be NaN, or simply ignore columns containing these values.Example uses are shown below.Here\'s an example using a Series of strings s which has the object dtype:The function\'s default behaviour is to raise if it can\'t convert a value. In this case, it can\'t cope with the string \'pandas\':Rather than fail, we might want \'pandas\' to be considered a missing/bad value. We can coerce invalid values to NaN as follows:The third option is just to ignore the operation if an invalid value is encountered:We might want to apply this operation to multiple columns. Processing each column in turn is tedious, so we can use DataFrame.apply to have the function act on each column.Borrowing the DataFrame from the question:Then we can write:and now \'col2\' and \'col3\' have dtype float64 as desired.However, we might not know which of our columns can be converted reliably to a numeric type. In that case we can just write:Then the function will be applied to the whole DataFrame. Columns that can be converted to a numeric type will be converted, while columns that cannot (e.g. they contain non-digit strings or dates) will be left alone.There is also pd.to_datetime and pd.to_timedelta for conversion to dates and timestamps.Version 0.21.0 introduces the method infer_objects() for converting columns of a DataFrame that have an object datatype to a more specific type.For example, let\'s create a DataFrame with two columns of object type, with one holding integers and the other holding strings of integers:Then using infer_objects(), we can change the type of column \'a\' to int64:Column \'b\' has been left alone since its values were strings, not integers. If we wanted to try and force the conversion of both columns to an integer type, we could use df.astype(int) instead.How about this? Here is a function that takes as its arguments a DataFrame and a list of columns and coerces all data in the columns to numbers.So, for your example:How about creating two dataframes, each with different data types for their columns, and then appending them together?ResultsAfter the dataframe is created, you can populate it with floating point variables in the 1st column, and strings (or any data type you desire) in the 2nd column. 