I am trying to write a bash script for testing that takes a parameter and sends it through curl to web site.  I need to url encode the value to make sure that special characters are processed properly.  What is the best way to do this?  Here is my basic script so far:Use curl --data-urlencode; from man curl:This posts data, similar to the other --data options with the exception that this performs URL-encoding. To be CGI-compliant, the <data> part should begin with a name followed by a separator and a content specification.Example usage:See the man page for more info.This requires curl 7.18.0 or newer (released January 2008). Use  curl -V to check which version you have.Here is the pure BASH answer.You can use it in two ways:[edited]Here\'s the matching rawurldecode() function, which - with all modesty - is awesome.With the matching set, we can now perform some simple tests:And if you really really feel that you need an external tool (well, it will go a lot faster, and might do binary files and such...)  I found this on my OpenWRT router...Where url_escape.sed was a file that contained these rules:Use Perl\'s URI::Escape module and uri_escape function in the second line of your bash script:Edit: Fix quoting problems, as suggested by Chris Johnsen in the comments. Thanks!for the sake of completeness, many solutions using sed or awk only translate a special set of characters and are hence quite large by code size and also dont translate other special characters that should be encoded.a safe way to urlencode would be to just encode every single byte - even those that would\'ve been allowed.xxd is taking care here that the input is handled as bytes and not characters.edit:xxd comes with the vim-common package in Debian and I was just on a system where it was not installed and I didnt want to install it. The altornative is to use hexdump from the bsdmainutils package in Debian. According to the following graph, bsdmainutils and vim-common should have an about equal likelihood to be installed:http://qa.debian.org/popcon-png.php?packages=vim-common%2Cbsdmainutils&show_installed=1&want_legend=1&want_ticks=1but nevertheless here a version which uses hexdump instead of xxd and allows to avoid the tr call:I find it more readable in python:the triple \' ensures that single quotes in value won\'t hurt. urllib is in the standard library. It work for exampple for this crazy (real world) url:I\'ve found the following snippet useful to stick it into a chain of program calls, where URI::Escape might not be installed:(source)one of variants, may be ugly, but simple:If you wish to run GET request and use pure curl just add --get to  @Jacob\'s solution.Here is an example:Direct link to awk version : http://www.shelldorado.com/scripts/cmds/urlencode\nI used it for years and it works like a charmthis will encode the string inside of $1 and output it in $url. although you don\'t have to put it in a var if you want. BTW didn\'t include the sed for tab thought it would turn it into spaces\nAnother option is to use jq:-s (--slurp) reads input lines into an array and -s -R (--slurp --raw-input) reads the input into a single string. -r (--raw-output) outputs the contents of strings instead of JSON string literals.Or this percent-encodes all bytes:For those of you looking for a solution that doesn\'t need perl, here is one that only needs hexdump and awk:Stitched together from a couple of places across the net and some local trial and error. It works great!This may be the best one:uni2ascii is very handy:Using php from a shell script:If you don\'t want to depend on Perl you can also use sed. It\'s a bit messy, as each character has to be escaped individually. Make a file with the following contents and call it urlencode.sedTo use it do the following.This will split the string into a part that needs encoding, and the part that is fine, encode the part that needs it, then stitches back together.You can put that into a sh script for convenience, maybe have it take a parameter to encode, put it on your path and then you can just call:sourceYou can emulate javascript\'s encodeURIComponent in perl.  Here\'s the command:You could set this as a bash alias in .bash_profile:Now you can pipe into encodeURIComponent:Here\'s the node version:Simple PHP option:Ruby, for completenessAnother php approach:The question is about doing this in bash and there\'s no need for python or perl as there is in fact a single command that does exactly what you want - "urlencode".This is also much better, as the above perl answer, for example, doesn\'t encode all characters correctly. Try it with the long dash you get from Word and you get the wrong encoding.Note, you need "gridsite-clients" installed to provide this command.Here is a POSIX function to do that:Example:SourceHere\'s a one-line conversion using Lua, similar to blueyed\'s answer except with all the RFC 3986 Unreserved Characters left unencoded (like this answer):Additionally, you may need to ensure that newlines in your string are converted from LF to CRLF, in which case you can insert a gsub("\\r?\\n", "\\r\\n") in the chain before the percent-encoding.Here\'s a variant that, in the non-standard style of application/x-www-form-urlencoded, does that newline normalization, as well as encoding spaces as \'+\' instead of \'%20\' (which could probably be added to the Perl snippet using a similar technique).Having php installed I use this way:This is the ksh version of orwellophile\'s answer containing the rawurlencode and rawurldecode functions (link: How to urlencode data for curl command?). I don\'t have enough rep to post a comment, hence the new post..Here\'s a Bash solution which doesn\'t invoke any external programs:Here is my version for busybox ash shell for an embedded system, I originally adopted Orwellophile\'s variant:What would parse URLs better than javascript?