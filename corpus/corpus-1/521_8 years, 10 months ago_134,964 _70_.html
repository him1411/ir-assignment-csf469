In .NET System.Object.GetHashCode method is used in a lot of places,  throughout the .NET base class libraries. Especially when finding items in a collection fast or to determine equality. Is there a standard algorithm/ best practice on how to implement the GetHashCode override for my custom classes so I don\'t degrade performance?I usually go with something like the implementation given in Josh Bloch\'s fabulous Effective Java. It\'s fast and creates a pretty good hash which is unlikely to cause collisions. Pick two different prime numbers, e.g. 17 and 23, and do:EDIT: As noted in comments, you may find it\'s better to pick a large prime to multiply by instead. Apparently 486187739 is good... and although most examples I\'ve seen with small numbers tend to use primes, there are at least similar algorithms where non-prime numbers are often used. In the not-quite-FNV example later, for example, I\'ve used numbers which apparently work well - but the initial value isn\'t a prime. (The multiplication constant is prime though. I don\'t know quite how important that is.)This is better than the common practice of XORing hashcodes for two main reasons. Suppose we have a type with two int fields:By the way, the earlier algorithm is the one currently used by the C# compiler for anonymous types.EDIT: This page gives quite a few options. I think for most cases the above is "good enough" and it\'s incredibly easy to remember and get right. The FNV alternative is similarly simple, but uses different constants and XOR instead of ADD as a combining operation. It looks something like the code below, but the normal FNV algorithm operates on individual bytes, so this would require modifying to perform one iteration per byte, instead of per 32-bit hash value. FNV is also designed for variable lengths of data, whereas the way we\'re using it here is always for the same number of field values. Comments on this answer suggest that the code here doesn\'t actually work as well (in the sample case tested) as the addition approach above.EDIT: Note that one thing to be aware of is that ideally you should prevent your equality-sensitive (and thus hashcode-sensitive) state from changing after adding it to a collection that depends on the hash code.As per the documentation:You can override GetHashCode for immutable reference types. In general, for mutable reference types, you should override GetHashCode only if:Microsoft already provides a good generic HashCode generator: Just copy your property/field values to an anonymous type and hash it:This will work for any number of properties. It does not use boxing or extra resources. It just uses the algorithm already implemented in the framework for anonymous types.Here is my hashcode helper.\nIt\'s advantage is that it uses generic type arguments and therefore will not cause boxing:Also it has extension method to provide a fluent interface, so you can use it like this:or like this:  I have a Hashing class in Helper library that I use it for this purpose.Then, simply you can use it as:I didn\'t assess its performance, so any feedback is welcomed.Here\'s my helper class that uses the Jon Skeet\'s implementation.Usage:If you want to avoid writing an extension method for System.Int32:It\'s still generic, it still avoids any heap allocation and it\'s used exactly the same way:Update after Martin\'s comment:obj != null caused boxing so I switched to the default comparer.In most cases where Equals() compares multiple fields it doesn\'t really matter if your GetHash() hashes on one field or on many. You just have to make sure that calculating the hash is really cheap (No allocations, please) and fast (No heavy computations and certainly no database connections) and provides a good distribution.The heavy lifting should be part of the Equals() method; the hash should be a very cheap operation to enable calling Equals() on as few items as possible.And one final tip: Don\'t rely on GetHashCode() being stable over multiple aplication runs. Many .Net types don\'t guarantee their hash codes to stay the same after a restart, so you should only use the value of GetHashCode() for in memory data structures.Up until recently my answer would have been very close to Jon Skeet\'s here. However, I recently started a project which used power-of-two hash tables, that is hash tables where the size of the internal table is 8, 16, 32, etc. There\'s a good reason for favouring prime-number sizes, but there are some advantages to power-of-two sizes too.And it pretty much sucked. So after a bit of experimentation and research I started re-hashing my hashes with the following:And then my power-of-two hash table didn\'t suck any more.This disturbed me though, because the above shouldn\'t work. Or more precisely, it shouldn\'t work unless the original GetHashCode() was poor in a very particular way.Re-mixing a hashcode can\'t improve a great hashcode, because the only possible effect is that we introduce a few more collisions.Re-mixing a hash code can\'t improve a terrible hash code, because the only possible effect is we change e.g. a large number of collisions on value 53 to a large number of value 183487291.Re-mixing a hash code can only improve a hash code that did at least fairly well in avoiding absolute collisions throughout its range (232 possible values) but badly at avoiding collisions when modulo\'d down for actual use in a hash table. While the simpler modulo of a power-of-two table made this more apparent, it was also having a negative effect with the more common prime-number tables, that just wasn\'t as obvious (the extra work in rehashing would outweigh the benefit, but the benefit would still be there).Edit: I was also using open-addressing, which would also have increased the sensitivity to collision, perhaps more so than the fact it was power-of-two.And well, it was disturbing how much string.GetHashCode() could be improved this way (on the order of tests running about 20-30times faster due to fewer collisions) and more disturbing how much my own hash codes could be improved (much more than that).All the GetHashCode() implementations I\'d coded in the past, and indeed used as the basis of answers on this site, were much worse than I\'d throught. Much of the time it was "good enough" for much of the uses, but I wanted something better.So I put that project to one side (it was a pet project anyway) and started looking at how to produce a good, well-distributed hash code in .NET quickly.In the end I settled on porting SpookyHash to .NET. Indeed the code above is a fast-path version of using SpookyHash to produce a 32-bit output from a 32-bit input.Now, SpookyHash is not a nice quick to remember piece of code. My port of it is even less so because I hand-inlined a lot of it for better speed*. But that\'s what code reuse is for.Then I put that project to one side, because just as the original project had produced the question of how to produce a better hash code, so that project produced the question of how to produce a better .NET memcpy.Then I came back, and produced a lot of overloads to easily feed just about all of the native types (except decimal\xe2\x80\xa0) into a hash code.It\'s fast, for which Bob Jenkins deserves most of the credit because his original code I ported from is faster still, especially on 64-bit machines which the algorithm is optimised for\xe2\x80\xa1.The full code can be seen at https://bitbucket.org/JonHanna/spookilysharp/src but consider that the code above is a simplified version of it.However, since it\'s now already written, one can make use of it more easily:It also takes seed values, so if you need to deal with untrusted input and want to protect against Hash DoS attacks you can set a seed based on uptime or similar, and make the results unpredictable by attackers:*A big surprise in this is that hand-inlining a rotation method that returned (x << n) | (x >> -n) improved things. I would have been sure that the jitter would have inlined that for me, but profiling showed otherwise.\xe2\x80\xa0decimal isn\'t native from the .NET perspective though it is from the C#. The problem with it is that its own GetHashCode() treats precision as significant while its own Equals() does not. Both are valid choices, but not mixed like that. In implementing your own version, you need to choose to do one, or the other, but I can\'t know which you\'d want.\xe2\x80\xa1By way of comparison. If used on a string, the SpookyHash on 64 bits is considerably faster than string.GetHashCode() on 32 bits which is slightly faster than string.GetHashCode() on 64 bits, which is considerably faster than SpookyHash on 32 bits, though still fast enough to be a reasonable choice.This is a good one:And here is how to use it:Here is my simplistic approach. I am using the classic builder pattern for this. It is typesafe (no boxing/unboxing) and also compatbile with .NET 2.0 (no extension methods etc.).It is used like this:And here is the acutal builder class:Here is another fluent implementation of the algorithm posted above by Jon Skeet, but which includes no allocations or boxing operations:Usage:The compiler will ensure HashValue is not called with a class due to the generic type constraint. But there is no compiler support for HashObject since adding a generic argument also adds a boxing operation.Most of my work is done with database connectivity which means that my classes all have a unique identifier from the database.  I always use the ID from the database to generate the hashcode.Pretty much similar to nightcoder\'s solution except it\'s easier to raise primes if you want to. PS: This is one of those times where you puke a little in your mouth, knowing that this could be refactored into one method with 9 default\'s but it would be slower, so you just close your eyes and try to forget about it.ReSharper users can generate GetHashCode, Equals, and others with ReSharper -> Edit -> Generate Code -> Equality Members.397 seems to be an ersatz ReSharper "signature", as all methods as of version 2016.2 use it.Microsoft lead for several way of hashing....i can guess that for multiple big int u can use this:and same for multi-type... all converted first to int using GetHashCode()\nthen the int values will be xor\'ed and the result is ur hash...for those who use hash as ID (i mean a unique value), hash is naturally limit number of digits, i think it was 5 bytes for hashing algorithm, at last MD5...you may turn multiple value to a hashed value and some of them be same, so don\'t use it as an identifier... (maybe some day i gonna use your component)I ran into an issue with floats and decimals using the implementation selected as the answer above.  This test fails (floats; hash is the same even though I switched 2 values to be negative):But this test passes (with ints):I changed my implementation to not use GetHashCode for the primitive types and it seems to work better