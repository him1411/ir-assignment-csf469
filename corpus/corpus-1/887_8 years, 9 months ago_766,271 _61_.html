Is there an easy way to run a MySQL query from the Linux command line and output the results in CSV  format?Here\'s what I\'m doing now:It gets messy when there are a lot of columns that need to be surrounded by quotes, or if there are quotes in the results that need to be escaped.From http://www.tech-recipes.com/rx/1475/save-mysql-query-results-into-a-text-or-csv-file/Using this command columns names will not be exported.Which is tab separated. Pipe it like that to get a true CSV (thanks @therefromhere): mysql --batch, -BPrint results using tab as the column separator, with each row on a\n  new line. With this option, mysql does not use the history file.\n  Batch mode results in non-tabular output format and escaping of\n  special characters. Escaping may be disabled by using raw mode; see\n  the description for the --raw option.This will give you a tab separated file. Since commas (or strings containing comma) are not escaped it is not straightforward to change the delimiter to comma.Here\'s a fairly gnarly way of doing it. Found it somewhere, can\'t take any creditmysql --user=wibble --password wobble -B -e "select * from vehicle_categories;" | sed "s/\'/\\\'/;s/\\t/\\",\\"/g;s/^/\\"/;s/$/\\"/;s/\\n//g" > vehicle_categories.csvWorks pretty well. Once again though a regex proves write only.Regex Explanation:So, putting it all together:Unix/Cygwin only, pipe it through \'tr\':N.B.: This handles neither embedded commas, nor embedded tabs.The OUTFILE solution given by Paul Tomblin causes a file to be written on the MySQL server itself, so this will work only if you have FILE access, as well as login access or other means for retrieving the file from that box.If you don\'t have such access, and tab-delimited output is a reasonable substitute for CSV (e.g., if your end goal is to import to Excel), then Serbaut\'s solution (using mysql --batch and optionally --raw) is the way to go.How about:  MySQL Workbench can export recordsets to CSV, and it seems to handle commas in fields very well. The CSV opens up in OpenOffice fine.All of the solutions here to date, except the Mysql workbench one, are incorrect and quite possibly unsafe (ie security issues) for at least some possible content in the mysql db.Mysql Workbench (and similarly PHPMyAdmin) provide a formally correct solution, but are designed for downloading the output to a user\'s location.  They\'re not so useful for things like automating data export.It is not possible to generate reliably correct csv from the output of mysql -B -e \'SELECT ...\' because that cannot encode carriage returns and white space in fields.  The \'-s\' flag to mysql does do backslash escaping, and might lead to a correct solution.  However, using a scripting language (one with decent internal data structures that is, not bash), and libraries where the encoding issues have already been carefully worked out is far safer.I thought about writing a script for this, but as soon as I thought about what I\'d call it, it occurred to me to search for pre-existing work by the same name.  While I haven\'t gone over it thoroughly, the solution at https://github.com/robmiller/mysql2csv looks promising.  Depending on your application, the yaml approach to specifying the SQL commands might or might not appeal though.  I\'m also not thrilled with the requirement for a more recent version of ruby than comes as standard with my Ubuntu 12.04 laptop or Debian Squeeze servers.  Yes I know I could use RVM, but I\'d rather not maintain that for such a simple purpose.Hopefully someone will point out a suitable tool, that\'s had a bit of testing.  Otherwise I\'ll probably update this when I find or write one.This saved me a couple of times. Fast and it works!--batch--rawExample:From your command line,\nyou can do this:Credits: Exporting table from Amazon RDS into a csv fileThis is simple, and it works on anything without needing batch mode or output files:Explanation:That\'s it!Many of the answers on this page are weak because they don\'t handle the general case of what can occur in CSV format. e.g. commas and quotes embedded in fields and other conditions that always come up eventually.  We need a general solution that works for all valid CSV input data.Here\'s a simple and strong solution in Python:Name that file tab2csv, put it on your path, give it execute permissions, then use it list this:The Python CSV-handling functions cover corner cases for CSV input format(s).This could be improved to handle very large files via a streaming approach.CREATE TABLE () (SELECT data FROM other_table ) ENGINE=CSV  ; When you create a CSV table, the server creates a table format file in\n  the database directory. The file begins with the table name and has an\n  .frm extension. The storage engine also creates a data file. Its name\n  begins with the table name and has a .CSV extension. The data file is\n  a plain text file. When you store data into the table, the storage\n  engine saves it into the data file in comma-separated values format.To expand on previous answers, the following one-liner exports a single table as a tab-separated file. It\'s suitable for automation, exporting the database every day or so.Conveniently, we can use the same technique to list out MySQL\'s tables, and to describe the fields on a single table:Alternatively to the answer above, you can have a MySQL table that uses the CSV engine.Then you will have a file on your hard disk that will always be in a CSV format which you could just copy without processing it.Here\'s what I do:The perl script (sniped from elsewhere) does a nice job of converting the tab spaced fields to CSV.Using the solution posted by Tim, I created this bash script to facilitate the process (root password is requested, but you can modify the script easily to ask for any other user):It will create a file named: database.table.csvNot exactly as a CSV format, but tee command from MySQL client can be used to save the output into a local file:You can disable it using notee.The problem with SELECT \xe2\x80\xa6 INTO OUTFILE \xe2\x80\xa6; is that it requires permission to write files at the server.Building on user7610, here is the best way to do it.  With mysql outfile there were 60 mins of file ownership and overwriting problems.  It\'s not cool, but it worked in 5 mins.php csvdump.php localhost root password database tablename > whatever-you-like.csvIf there is PHP installed on the machine you are using, you can write a PHP script to do that. It requires the PHP installation has the MySQL extension installed.You can call the PHP interpreter from the command line like so:I am including the --php-ini switch, because you may need to use your own PHP configuration that enables the MySQL extension. On PHP 5.3.0+ that extension is enabled by default, so that is no longer necessary to use the configuration to enable it.Then you can write your export script like any normal PHP script:The advantage of this method is, that it has no problems with varchar and text fields, that have text containing newlines. Those fields are correctly quoted and those newlines in them will be interpreted by the CSV reader as a part of the text, not record separators. That is something that is hard to correct afterwards with sed or so.This answer uses Python and a popular third party library, PyMySQL. I\'m adding it because Python\'s csv library is powerful enough to correctly handle many different flavors of .csv and no other answers are using Python code to interact with the database.