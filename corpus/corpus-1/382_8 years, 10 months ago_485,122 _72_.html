I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.I was looking for something useful in itertools but I couldn\'t find anything obviously useful. Might\'ve missed it, though.Related question: What is the most \xe2\x80\x9cpythonic\xe2\x80\x9d way to iterate over a list in chunks?Here\'s a generator that yields the chunks you want:If you\'re using Python 2, you should use xrange() instead of range():Also you can simply use list comprehension instead of writing a function. Python 3:Python 2 version:If you want something super simple:Directly from the (old) Python documentation (recipes for itertools):The current version, as suggested by J.F.Sebastian:I guess Guido\'s time machine works\xe2\x80\x94worked\xe2\x80\x94will work\xe2\x80\x94will have worked\xe2\x80\x94was working again.These solutions work because [iter(iterable)]*n (or the equivalent in the earlier version) creates one iterator, repeated n times in the list. izip_longest then effectively performs a round-robin of "each" iterator; because this is the same iterator, it is advanced by each such call, resulting in each such zip-roundrobin generating one tuple of n items.Here is a generator that work on arbitrary iterables:Example:I know this is kind of old but I don\'t why nobody mentioned numpy.array_split:I\'m surprised nobody has thought of using iter\'s two-argument form:Demo:This works with any iterable and produces output lazily. It returns tuples rather than iterators, but I think it has a certain elegance nonetheless. It also doesn\'t pad; if you want padding, a simple variation on the above will suffice:Demo:Like the izip_longest-based solutions, the above always pads. As far as I know, there\'s no one- or two-line itertools recipe for a function that optionally pads. By combining the above two approaches, this one comes pretty close:Demo:I believe this is the shortest chunker proposed that offers optional padding. Simple yet elegantor if you prefer:I saw the most awesome Python-ish answer in a duplicate of this question:You can create n-tuple for any n. If a = range(1, 15), then the result will be:If the list is divided evenly, then you can replace zip_longest with zip, otherwise the triplet (13, 14, None) would be lost. Python 3 is used above. For Python 2, use izip_longest.None of these answers are evenly sized chunks, they all leave a runt chunk at the end, so they\'re not completely balanced. If you were using these functions to distribute work, you\'ve built-in the prospect of one likely finishing well before the others, so it would sit around doing nothing while the others continued working hard.For example, the current top answer ends with:I just hate that runt at the end!Others, like list(grouper(3, xrange(7))), and chunk(xrange(7), 3) both return: [(0, 1, 2), (3, 4, 5), (6, None, None)]. The None\'s are just padding, and rather inelegant in my opinion. They are NOT evenly chunking the iterables.Why can\'t we divide these better?Here\'s a balanced solution, adapted from a function I\'ve used in production (Note in Python 3 to replace xrange with range):And I created a generator that does the same if you put it into a list:And finally, since I see that all of the above functions return elements in a contiguous order (as they were given):To test them out:Which prints out:Notice that the contiguous generator provide chunks in the same length patterns as the other two, but the items are all in order, and they are as evenly divided as one may divide a list of discrete elements.more-itertools has a chunks iterator.It also has a lot more things, including all the recipes in the itertools documentation.If you had a chunk size of 3 for example, you could do:source:\nhttp://code.activestate.com/recipes/303060-group-a-list-into-sequential-n-tuples/I would use this when my chunk size is fixed number I can type, e.g. \'3\', and would never change.A generator expression:eg.If you know list size:If you don\'t (an iterator):In the latter case, it can be rephrased in a more beautiful way if you can be sure that the sequence always contains a whole number of chunks of given size (i.e. there is no incomplete last chunk).I like the Python doc\'s version proposed by tzot and J.F.Sebastian a lot,\n but it has two shortcomings:I\'m using this one a lot in my code:UPDATE: A lazy chunks version:The toolz library has the partition function for this:At this point, I think we need a recursive generator, just in case...In python 2:In python 3:Also, in case of massive Alien invasion, a decorated recursive generator might become handy:usage:Where AA is array, SS is chunk size. For example:You may also use get_chunks function of utilspie library as:You can install utilspie via pip:Disclaimer: I am the creator of utilspie library.heh, one line versionConsider using matplotlib.cbook piecesfor example:Another more explicit version.code:result:I realise this question is old (stumbled over it on Google), but surely something like the following is far simpler and clearer than any of the huge complex suggestions and only uses slicing:See this referencePython3If you are into brackets - I picked up a book on Erlang :)