I wonder whether there is a shortcut to make a simple list out of list of lists in Python.I can do that in a for loop, but maybe there is some cool "one-liner"? I tried it with reduce, but I get an error.CodeError messagewhich means:is faster than the shortcuts posted so far. (l is the list to flatten.)Here is a the corresponding function:For evidence, as always, you can use the timeit module in the standard library:Explanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(L**2) when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So (for simplicity and without actual loss of generality) say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., I * (L**2)/2.The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.You can use itertools.chain():or, on Python >=2.6, use itertools.chain.from_iterable() which doesn\'t require unpacking the list:This approach is arguably more readable than [item for sublist in l for item in sublist] and appears to be faster too:Note that only works on lists of lists. For lists of lists of lists, you\'ll need another solution.@Nadia: You have to use much longer lists. Then you see the difference quite strikingly!\nMy results for len(l) = 1600where:The extend() method in your example modifies x instead of returning a useful value (which reduce() expects).A faster way to do the reduce version would beI take my statement back. sum is not the winner. Although it is faster when the list is small. But the performance degrades significantly with larger lists. The sum version is still running for more than a minute and it hasn\'t done processing yet!For medium lists:Using small lists and timeit: number=1000000Why do you use extend?This should work fine.Here is a general approach that applies to nested lists of lists, numbers, strings, and other mixed containers types.This solution employs Python 3\'s powerful yield from keyword, which extracts items from sub-generators.  Note, this solution does not apply to strings.  UPDATE: Now supports strings.  REF: solution modified from Beazley, D. and B. Jones.  Recipe 4.14, Python Cookbook 3rd Ed., O\'Reilly Media Inc. Sebastopol, CA: 2013.I tested most suggested solutions with perfplot (a pet project of mine, essentially a wrapper around timeit), and foundlist(itertools.chain.from_iterable(a))to be the fastest solution.Code to reproduce the plot:There seems to be a confusion with operator.add! When you add two lists together, the correct term for that is concat, not add. operator.concat is what you need to use.If you\'re thinking functional, it is as easy as this::You see reduce respects the sequence type, so when you supply a tuple, you get back a tuple. let\'s try with a list::Aha, you get back a list.How about performance::from_iterable is pretty fast! But it\'s no comparison to reduce with concat.The reason your function didn\'t work: the extend extends array in-place and doesn\'t return it. You can still return x from lambda, using some trick:Note: extend is more efficient than + on lists.If you want to flatten a data-structure where you don\'t know how deep it\'s nested you could use iteration_utilities.deepflatten1It\'s a generator so you need to cast the result to a list or explicitly iterate over it.To flatten only one level and if each of the items is itself iterable you can also use iteration_utilities.flatten which itself is just a thin wrapper around itertools.chain.from_iterable:1 Disclaimer: I\'m the author of that libraryAn bad feature of Anil\'s function above is that it requires the user to always manually specify the second argument to be an empty list []. This should instead be a default. Due to the way Python objects work, these should be set inside the function, not in the arguments.Here\'s a working function:Testing:Following seem simplest to me:Consider installing the more_itertools package.It ships with an implementation for flatten (source, from the itertools recipes):As of version 2.4, you can flatten more complicated, nested iterables with more_itertools.collapse (source, contributed by  abarnet).One can also use NumPy\'s flat:Edit 11/02/2016: Only works when sublists have identical dimensions.Simple code for underscore.py package fanIt solves all flatten problems (none list item or complex nesting)You can install underscore.py with pipIf you are willing to give up a tiny amount of speed for a cleaner look, then you could use numpy.concatenate().tolist() or numpy.concatenate().ravel().tolist():You can find out more here in the docs numpy.concatenate and numpy.ravelFastest solution I have found (for large list anyway):Done! You can of course turn it back into a list by executing list(l)Cleaned up @Deleet exampleExample: https://repl.it/G8mb/0I recently came across a situation where I had a mix of strings and numeric data in sublists such aswhere methods like flat_list = [item for sublist in test for item in sublist] have not worked. So, I came up with the following solution for 1+ level of sublistsAnd the resultYou could convert it to a string first (the other answer are probably better though)