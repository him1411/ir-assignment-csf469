In the same vein as \nQuickly create a large file on a Linux system? \nI\'d like to quickly create a large file on a windows system.  By large I\'m thinking 5GB.  The content doesn\'t matter.  A built in command or short batch file would be preferable, but I\'ll accept an application if there are no other easy ways.where <length> is in bytes.You can use the Sysinternals Contig tool. It has a -n switch which creates a new file of a given size. It will create a file almost instantaneous.I was searching for a way to generate large files with data..not just sparse file..came across the below technique.http://www.windows-commandline.com/how-to-create-large-dummy-file/Check out RDFC http://www.bertel.de/software/rdfc/index-en.html RDFC is probably not the fastest but it does allocate data blocks. The absolutely fastest would have to use lower level API to just obtain cluster chains and put them into MFT without writing data.Beware that there\'s no silver bullet here - if "creation" returns instnatly that means you got a sparse file which just fakes a large file but you won\'t get data blocks/chains till you write into it. If you just read is you\'d get very fast zeros whihc could make you believe that your drive all of the sudden got blazingly fast :-)Check the Windows Server 2003 Resource Kit Tools. There is a utility called Creatfil.It is the similar to mkfile on Solaris.I needed a regular 10 GB file for testing, so I couldn\'t use fsutil because it creates sparse files (thanks @ZXX).I wanted to create a 10 GB file, but for some reason it only showed up as 4 GB, so I wanted to be safe and stopped at 4 GB. If you really want to be sure your file will be handled properly by the operating system and other applications, stop expanding it at 1 GB.Found an excellent utility that is configurable at https://github.com/SL5R0/GenFile.It fills the target file with random data, so there are no problems with sparse files, and for my purposes (testing compression algorithms) it gives a nice level of white noise.Open up windows task manager, find the biggest process you have running right click, and click on Create dump file.This will create a file relative to the size of the process in memory in your temp folder.You can easily create a file sized in gigs.PowerShell one-liner to create a file in C:\\Temp to fill disk C: leaving only 10MB:Short of writing a full application, us Python guys can achieve files of any size with 4 lines, same snippet on Windows and Linux (os.stat() line is just a check).Plain ol\' C...  this builds under Mingw GCC on WinXX and should work\non any \'generic\' C platform.Generates null file of specified size.  Resultant file is NOT just a directory\nspace-occupier entry, and in fact occupies the specified number of bytes. This\nis fast because no actual writes occur except for the byte written before close. \nMy instance produces a file full of zeros - this could vary by platform; this\nprgm essentially sets up the directory structure for whatever data is hanging\naround.I found a solution using DEBUG at http://www.scribd.com/doc/445750/Create-a-Huge-File, but I don\'t know an easy way to script it and it doesn\'t seem to be able to create files larger than 1 GB.You can try this C++ code:maybe it will take some time to generate depending on your CPU speed...... 1 MB file dummy.txt within few seconds. See here : http://www.windows-commandline.com/how-to-create-large-dummy-file/Temp files should be stored in the Windows Temp Folder. Based on the answer from Rod you can use the following one liner to create a 5 GB temp file which returns the filenameExplanation:Simple Answer in python, If you need to create a large real text file I just used a simple while loop and was able to create a 5GB file in about 20 seconds. I know its crude but it is fast enough.I was looking for a way to create large dummy file with space allocation recently. All of the solutions look awkward. Finally I just started DISKPART utility in Windows (embedded since Windows Vista):Where MAXIMUM is the resulting file size, 20GB here.