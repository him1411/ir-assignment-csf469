Well, this one seems quite simple, and it is. All you have to do to download a file to your server is:Only there is one problem. What if you have a large file, like 100mb. Then, you will run out of memory, and not be able to download the file.What I want is a way to write the file to the disk as I am downloading it. That way, I can download bigger files, without running into memory problems.Since PHP 5.1.0, file_put_contents() supports writing piece-by-piece by passing a stream-handle as the $data parameter:From the manual:If data [that is the second argument] is a stream resource, the remaining buffer of that stream will be copied to the specified file. This is similar with using\n  stream_copy_to_stream().(Thanks Hakre.)Try using cURLI\'m not sure but I believe with the CURLOPT_FILE option it writes as it pulls the data, ie. not buffered.Above there is examle (cited by prodigitalson) of code wchih not work (reason: missing fopen in CURLOPT_FILE - http://www.webdeveloper.com/forum/showthread.php?268299-RESOLVED-PHP-script-for-a-cronjob-download-file-unpzck-run-another-php-script ). I cant add comment there becose I have too low number of points so Below I give working example (it also work for "local url"):I use this to download fileThere are 3 ways:You can find examples from here.A PHP 4 & 5 Solution:readfile() will not present any memory issues, even when sending large files, on its own.\nA URL can be used as a filename with this function if the fopen wrappers have been enabled.http://php.net/manual/en/function.readfile.phpUse a simple method in php copy() Note: if the destination file already exists, it will be overwrittenPHP copy() FunctionSpecial Note: Don\'t forget to set permission 777 for the destination folder