I have a small utility that I use to download a MP3 from a website on a schedule and then builds/updates a podcast XML file which I\'ve obviously added to iTunes.The text processing that creates/updates the XML file is written in Python. I use wget inside a Windows .bat file to download the actual MP3 however. I would prefer to have the entire utility written in Python though.I struggled though to find a way to actually down load the file in Python, thus why I resorted to wget.So, how do I download the file using Python?In Python 2, use urllib2 which comes with the standard library.This is the most basic way to use the library, minus any error handling.  You can also do more complex stuff such as changing headers.  The documentation can be found here.One more, using urlretrieve:(for Python 3+ use \'import urllib.request\' and urllib.request.urlretrieve)Yet another one, with a "progressbar"In 2012, use the python requests libraryYou can run pip install requests to get it.Requests has many advantages over the alternatives because the API is much simpler. This is especially true if you have to do authentication. urllib and urllib2 are pretty unintuitive and painful in this case.2015-12-30People have expressed admiration for the progress bar. It\'s cool, sure. There are several off-the-shelf solutions now, including tqdm:This is essentially the implementation @kvance described 30 months ago.The wb in open(\'test.mp3\',\'wb\') opens a file (and erases any existing file) in binary mode so you can save data with it instead of just text.Here\'s how to do it in Python 3 using the standard library:urllib.request.urlopenurllib.request.urlretrieveAn improved version of the PabloG code for Python 2/3:Wrote wget library in pure Python just for this purpose. It is pumped up urlretrieve with these features as of version 2.0.I agree with Corey, urllib2 is more complete than urllib and should likely be the module used if you want to do more complex things, but to make the answers more complete, urllib is a simpler module if you want just the basics:Will work fine. Or, if you don\'t want to deal with the "response" object you can call read() directly:use wget module:Following are the most commonly used calls for downloading files in python:urllib.urlretrieve (\'url_to_file\', file_name)urllib2.urlopen(\'url_to_file\')requests.get(url)wget.download(\'url\', file_name)Note: urlopen and urlretrieve are found to perform relatively bad with downloading large files (size > 500 MB). requests.get stores the file in-memory until download is complete.  You can get the progress feedback with urlretrieve as well:If you have wget installed, you can use parallel_sync.pip install parallel_syncDoc:\nhttps://pythonhosted.org/parallel_sync/pages/examples.htmlThis is pretty powerful. It can download files in parallel, retry upon failure , and it can even download files on a remote machine.This may be a little late, But I saw pabloG\'s code and couldn\'t help adding a os.system(\'cls\') to make it look AWESOME! Check it out : If running in an environment other than Windows, you will have to use something other then \'cls\'. In MAC OS X and Linux it should be \'clear\'.Simple yet Python 2 & Python 3 compatible way:Source code can be:urlretrieve and requests.get is simple, however the reality not.\nI have fetched data for couple sites, including text and images, the above two probably solve most of the tasks. but for a more universal solution I suggest the use of urlopen. As it is included in Python 3 standard library, your code could run on any machine that run Python 3 without pre-installing site-parThis answer provides a solution to HTTP 403 Forbidden when downloading file over http using Python. I have tried only requests and urllib modules, the other module may provide something better, but this is the one I used to solve most of the problems.I wrote the following, which works in vanilla Python 2 or Python 3.Notes: