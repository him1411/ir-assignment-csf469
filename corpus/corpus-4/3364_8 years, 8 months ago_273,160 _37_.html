In C, we can find the size of an int, char, etc. I want to know how to get size of objects like a string, integer, etc. in Python.Related question: How many bytes per element are there in a Python list (tuple)?I am using an XML file which contains size fields that specify the size of value. I must parse this XML and do my coding. When I want to change the value of a particular field, I will check the size field of that value. Here I want to compare whether the new value that I\'m gong to enter is of the same size as in XML. I need to check the size of new value. In case of a string I can say its the length. But in case of int, float, etc. I am confused.Just use the sys.getsizeof function defined in the sys module.sys.getsizeof(object[, default]):Return the size of an object in bytes.\n  The object can be any type of object.\n  All built-in objects will return\n  correct results, but this does not\n  have to hold true for third-party\n  extensions as it is implementation\n  specific.The default argument allows to define\n  a value which will be returned if the\n  object type does not provide means to\n  retrieve the size and would cause a\n  TypeError.getsizeof calls the object\xe2\x80\x99s\n  __sizeof__ method and adds an additional garbage collector overhead\n  if the object is managed by the\n  garbage collector.Usage example, in python 3.0:If you are in python < 2.6 and don\'t have sys.getsizeof you can use this extensive module instead. Never used it though.The answer, "Just use sys.getsizeof" is not a complete answer. That answer does work for builtin objects directly, but it does not account for what those objects may contain, specifically, what types, such as tuples, lists, dicts, and sets contain. They can contain instances each other, as well as numbers, strings and other objects.Using 64 bit Python 2.7 from the Anaconda distribution and guppy.hpy along with sys.getsizeof, I have determined the minimum size of the following objects, and note that sets and dicts preallocate space so empty ones don\'t grow again until after a set amount (which may vary by implementation of the language):*Note that dictionaries (but not sets) are getting a more\ncompact representation in Python 3.6I think 8 bytes per additional item to reference makes a lot of sense on a 64 bit machine. Those 8 bytes point to the place in memory the contained item is at. The 4 bytes are fixed width for unicode in Python 2, if I recall correctly, but in Python 3, str becomes a unicode of width equal to the max width of the characters.(And for more on slots, see this answer )To cover most of these types, I wrote this recursive function to try to estimate the size of most Python objects, including most builtins, types in the collections module, and custom types (slotted and otherwise):And I tested it rather casually (I should unittest it):It kind of breaks down on class definitions and function definitions because I don\'t go after all of their attributes, but since they should only exist once in memory for the process, their size really doesn\'t matter too much.For numpy arrays, getsizeof doesn\'t work - for me it always returns 40 for some reason:Then (in ipython):Happily, though:The Pympler package\'s asizeof module can do this.Use as follows:Unlike sys.getsizeof, it works for your self-created objects. It even works with numpy.This can be more complicated than it looks depending on how you want to count things.  For instance, if you have a list of ints, do you want the size of the list containing the references to the ints? (ie. list only, not what is contained in it), or do you want to include the actual data pointed to, in which case you need to deal with duplicate references, and how to prevent double-counting when two objects contain references to the same object. You may want to take a look at one of the python memory profilers, such as pysizer to see if they meet your needs.Here is a quick script I  wrote based on the previous answers to list sizes of all variablesIn case anyone comes across this question and needs a more "bulletproof" solution than sys.getsizeof or the procedure provided by Aaron Hall, there is a recipe here that attempts to deal with issues such as classes and bytecode objects in a principled and flexible way (it is far too long to replicate or meaningfully summarize here unfortunately).  Having run into this problem many times myself, I wrote up a small function (inspired by @aaron-hall\'s answer) & tests that does what I would have expected sys.getsizeof to do:https://github.com/bosswissam/pysizeIf you\'re interested in the backstory, here it isEDIT: Attaching the code below for easy reference. To see the most up-to-date code, please check the github link.You can measure the change in maximum resident set size of current process using resource module, like this:First: an answer.Discussion:\nIn Python, you cannot ever access "direct" memory addresses.  Why, then, would you need or want to know how many such addresses are occupied by a given object??  It\'s a question that\'s entirely inappropriate at that level of abstraction.  When you\'re painting your house, you don\'t ask what frequencies of light are absorbed or reflected by each of the constituent atoms within the paint, you just ask what color it is -- the details of the physical characteristics that create that color are beside the point.  Similarly, the number of bytes of memory that a given Python object occupies is beside the point.So, why are you trying to use Python to write C code? :)