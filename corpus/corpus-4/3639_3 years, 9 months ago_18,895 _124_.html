Which image processing techniques could be used to implement an application that detects the christmas trees displayed in the following images? \n \n\n\nI\'m searching for solutions that are going to work on all these images. Therefore, approaches that require training haar cascade classifiers or template matching are not very interesting.I\'m looking for something that can be written in any programming language, as long as it uses only Open Source technologies. The solution must be tested with the images that are shared on this question. There are 6 input images and the answer should display the results of processing each of them. Finally, for each output image there must be red lines draw to surround the detected tree.How would you go about programmatically detecting the trees in these images?I have an approach which I think is interesting and a bit different from the rest.  The main difference in my approach, compared to some of the others, is in how the image segmentation step is performed--I used the DBSCAN clustering algorithm from Python\'s scikit-learn; it\'s optimized for finding somewhat amorphous shapes that may not necessarily have a single clear centroid.At the top level, my approach is fairly simple and can be broken down into about 3 steps.  First I apply a threshold (or actually, the logical "or" of two separate and distinct thresholds).  As with many of the other answers, I assumed that the Christmas tree would be one of the brighter objects in the scene, so the first threshold is just a simple monochrome brightness test; any pixels with values above 220 on a 0-255 scale (where black is 0 and white is 255) are saved to a binary black-and-white image.  The second threshold tries to look for red and yellow lights, which are particularly prominent in the trees in the upper left and lower right of the six images, and stand out well against the blue-green background which is prevalent in most of the photos.  I convert the rgb image to hsv space, and require that the hue is either less than 0.2 on a 0.0-1.0 scale (corresponding roughly to the border between yellow and green) or greater than 0.95 (corresponding to the border between purple and red) and additionally I require bright, saturated colors: saturation and value must both be above 0.7.  The results of the two threshold procedures are logically "or"-ed together, and the resulting matrix of black-and-white binary images is shown below:You can clearly see that each image has one large cluster of pixels roughly corresponding to the location of each tree, plus a few of the images also have some other small clusters corresponding either to lights in the windows of some of the buildings, or to a background scene on the horizon.  The next step is to get the computer to recognize that these are separate clusters, and label each pixel correctly with a cluster membership ID number.For this task I chose DBSCAN.  There is a pretty good visual comparison of how DBSCAN typically behaves, relative to other clustering algorithms, available here.  As I said earlier, it does well with amorphous shapes.  The output of DBSCAN, with each cluster plotted in a different color, is shown here:There are a few things to be aware of when looking at this result.  First is that DBSCAN requires the user to set a "proximity" parameter in order to regulate its behavior, which effectively controls how separated a pair of points must be in order for the algorithm to declare a new separate cluster rather than agglomerating a test point onto an already pre-existing cluster.  I set this value to be 0.04 times the size along the diagonal of each image.  Since the images vary in size from roughly VGA up to about HD 1080, this type of scale-relative definition is critical.Another point worth noting is that the DBSCAN algorithm as it is implemented in scikit-learn has memory limits which are fairly challenging for some of the larger images in this sample.  Therefore, for a few of the larger images, I actually had to "decimate" (i.e., retain only every 3rd or 4th pixel and drop the others) each cluster in order to stay within this limit.  As a result of this culling process, the remaining individual sparse pixels are difficult to see on some of the larger images.  Therefore, for display purposes only, the color-coded pixels in the above images have been effectively "dilated" just slightly so that they stand out better.  It\'s purely a cosmetic operation for the sake of the narrative; although there are comments mentioning this dilation in my code, rest assured that it has nothing to do with any calculations that actually matter.Once the clusters are identified and labeled, the third and final step is easy: I simply take the largest cluster in each image (in this case, I chose to measure "size" in terms of the total number of member pixels, although one could have just as easily instead used some type of metric that gauges physical extent) and compute the convex hull for that cluster.  The convex hull then becomes the tree border.  The six convex hulls computed via this method are shown below in red:The source code is written for Python 2.7.6 and it depends on numpy, scipy, matplotlib and scikit-learn.  I\'ve divided it into two parts.  The first part is responsible for the actual image processing:and the second part is a user-level script which calls the first file and generates all of the plots above:EDIT NOTE: I edited this post to (i) process each tree image individually, as requested in the requirements, (ii) to consider both object brightness and shape in order to improve the quality of the result. Below is presented an approach that takes in consideration the object brightness and shape. In other words, it seeks for objects with triangle-like shape and with significant brightness. It was implemented in Java, using Marvin image processing framework.The first step is the color thresholding. The objective here is to focus the analysis on objects with significant brightness. output images:http://marvinproject.sourceforge.net/other/trees/tree_1threshold.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_2threshold.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_3threshold.pnghttp://marvinproject.sourceforge.net/other/trees/tree_4threshold.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_5threshold.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_6threshold.pngsource code:In the second step, the brightest points in the image are dilated in order to form shapes. The result of this process is the probable shape of the objects with significant brightness. Applying flood fill segmentation, disconnected shapes are detected.output images:http://marvinproject.sourceforge.net/other/trees/tree_1_fill.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_2_fill.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_3_fill.pnghttp://marvinproject.sourceforge.net/other/trees/tree_4_fill.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_5_fill.png\nhttp://marvinproject.sourceforge.net/other/trees/tree_6_fill.pngsource code:As shown in the output image, multiple shapes was detected. In this problem, there a just a few bright points in the images. However, this approach was implemented to deal with more complex scenarios. In the next step each shape is analyzed. A simple algorithm detects shapes with a pattern similar to a triangle. The algorithm analyze the object shape line by line. If the center of the mass of each shape line is almost the same (given a threshold) and mass increase as y increase, the object has a triangle-like shape. The mass of the shape line is the number of pixels in that line that belongs to the shape. Imagine you slice the object horizontally and analyze each horizontal segment. If they are centralized to each other and the length increase from the first segment to last one in a linear pattern, you probably has an object that resembles a triangle.source code:Finally, the position of each shape similar to a triangle and with significant brightness, in this case a Christmas tree, is highlighted in the original image, as shown below.final output images:http://marvinproject.sourceforge.net/other/trees/tree_1_out_2.jpg\nhttp://marvinproject.sourceforge.net/other/trees/tree_2_out_2.jpg\nhttp://marvinproject.sourceforge.net/other/trees/tree_3_out_2.jpghttp://marvinproject.sourceforge.net/other/trees/tree_4_out_2.jpg\nhttp://marvinproject.sourceforge.net/other/trees/tree_5_out_2.jpg\nhttp://marvinproject.sourceforge.net/other/trees/tree_6_out_2.jpgfinal source code:The advantage of this approach is the fact it will probably work with images containing other luminous objects since it analyzes the object shape.Merry Christmas!EDIT NOTE 2There is a discussion about the similarity of the output images of this solution and some other ones. In fact, they are very similar. But this approach does not just segment objects. It also analyzes the object shapes in some sense. It can handle multiple luminous objects in the same scene. In fact, the Christmas tree does not need to be the brightest one. I\'m just abording it to enrich the discussion. There is a bias in the samples that just looking for the brightest object, you will find the trees. But, does we really want to stop the discussion at this point? At this point, how far the computer is really recognizing an object that resembles a Christmas tree? Let\'s try to close this gap. Below is presented a result just to elucidate this point:input imageoutputHere is my simple and dumb solution.\nIt is based upon the assumption that the tree will be the most bright and big thing in the picture.The first step is to detect the most bright pixels in the picture, but we have to do a distinction between the tree itself and the snow which reflect its light. Here we try to exclude the snow appling a really simple filter on the color codes:Then we find every "bright" pixel:Finally we join the two results:Now we look for the biggest bright object:Now we have almost done, but there are still some imperfection due to the snow.\nTo cut them off we\'ll build a mask using a circle and a rectangle to approximate the shape of a tree to delete unwanted pieces:The last step is to find the contour of our tree and draw it on the original picture.I\'m sorry but at the moment I have a bad connection so it is not possible for me to upload pictures. I\'ll try to do it later.Merry Christmas.EDIT:Here some pictures of the final output:\n\n\n\n\nI wrote the code in Matlab R2007a. I used k-means to roughly extract the christmas tree. I \nwill show my intermediate result only with one image, and final results with all the six.First, I mapped the RGB space onto Lab space, which could enhance the contrast of red in its b channel:Besides the feature in color space, I also used texture feature that is relevant with the \nneighborhood rather than each pixel itself. Here I linearly combined the intensity from the \n3 original channels (R,G,B). The reason why I formatted this way is because the christmas \ntrees in the picture all have red lights on them, and sometimes green/sometimes blue \nillumination as well. I applied a 3X3 local binary pattern on I0, used the center pixel as the threshold, and \nobtained the contrast by calculating the difference between the mean pixel intensity value \nabove the threshold and the mean value below it.Since I have 4 features in total, I would choose K=5 in my clustering method. The code for \nk-means are shown below (it is from Dr. Andrew Ng\'s machine learning course. I took the \ncourse before, and I wrote the code myself in his programming assignment). \n  \n   \n   \n    Since the program runs very slow in my computer, I just ran 3 iterations. Normally the stop \ncriteria is (i) iteration time at least 10, or (ii) no change on the centroids any more. To \nmy test, increasing the iteration may differentiate the background (sky and tree, sky and \nbuilding,...) more accurately, but did not show a drastic changes in christmas tree \nextraction. Also note k-means is not immune to the random centroid initialization, so running the program several times to make a comparison is recommended. After the k-means, the labelled region with the maximum intensity of I0 was chosen. And \nboundary tracing was used to extracted the boundaries. To me, the last christmas tree is the most difficult one to extract since the contrast in  that picture is not high enough as they are in the first five. Another issue in my method  is that I used bwboundaries function in Matlab to trace the boundary, but sometimes the  inner boundaries are also included as you can observe in 3rd, 5th, 6th results. The dark  side within the christmas trees are not only failed to be clustered with the illuminated side, but they also lead to so many tiny inner boundaries tracing (imfill doesn\'t improve very much). In all my algorithm still has a lot improvement space.  \n  \n  \n  Some publications indicates that mean-shift may be more robust than k-means, and many \ngraph-cut based algorithms are also very competitive on complicated boundaries \nsegmentation. I wrote a mean-shift algorithm myself, it seems to better extract the regions \nwithout enough light. But mean-shift is a little bit over-segmented, and some strategy of \nmerging is needed. It ran even much slower than k-means in my computer, I am afraid I have \nto give it up. I eagerly look forward to see others would submit excellent results here \nwith those modern algorithms mentioned above. Yet I always believe the feature selection is the key component in image segmentation. With \na proper feature selection that can maximize the margin between object and background, many \nsegmentation algorithms will definitely work. Different algorithms may improve the result \nfrom 1 to 10, but the feature selection may improve it from 0 to 1.Merry Christmas !This is my final post using the traditional image processing approaches...Here I somehow combine my two other proposals, achieving even better results. As a matter of fact I cannot see how these results could be better (especially when you look at the masked images that the method produces).At the heart of the approach is the combination of three key assumptions:With these assumptions in mind the method works as follows:Here is the code in MATLAB (again, the script loads all jpg images in the current folder and, again, this is far from being an optimized piece of code):High resolution results still available here!\nEven more experiments with additional images can be found here....another old fashioned solution - purely based on HSV processing:A word on the heuristics in the HSV processing:Of course one may experiment with numerous other possibilities to fine-tune this approach...Here is the MATLAB code to do the trick (warning: the code is far from being optimized!!! I used techniques not recommended for MATLAB programming just to be able to track anything in the process-this can be greatly optimized):In the results I show the masked image and the bounding box.\nMy solution steps:Get R channel (from RGB) - all operations we make on this channel:Create Region of Interest (ROI)Threshold R channel with min value 149 (top right image)Dilate result region  (middle left image)Detect eges in computed roi. Tree has a lot of edges (middle right image) Dilate resultErode with bigger radius  ( bottom left image)Select the biggest (by area) object - it\'s the result regionConvexHull ( tree is convex polygon ) ( bottom right image )Bounding box  (bottom right image - grren box )Step by step:\nThe first result - most simple but not in open source software - "Adaptive Vision Studio + Adaptive Vision Library":\nThis is not open source but really fast to prototype:Whole algorithm to detect christmas tree (11 blocks):\nNext step. We want open source solution. Change AVL filters to OpenCV filters:\nHere I did little changes e.g. Edge Detection use cvCanny filter, to respect roi i did multiply region image with edges image, to select the biggest element i used findContours + contourArea but idea is the same.https://www.youtube.com/watch?v=sfjB3MigLH0&index=1&list=UUpSRrkMHNHiLDXgylwhWNQQI can\'t show images with intermediate steps now because I can put only 2 links.Ok now we use openSource filters but it\'s not still whole open source. \nLast step - port to c++ code. I used OpenCV in version 2.4.4The result of final c++ code is:\nc++ code is also quite short:Some old-fashioned image processing approach...\nThe idea is based on the assumption that images depict lighted trees on typically darker and smoother backgrounds (or foregrounds in some cases). The lighted tree area is more "energetic" and has higher intensity. \nThe process is as follows:What you get is a binary mask and a bounding box for each image.Here are the results using this naive technique:\nCode on MATLAB follows:\nThe code runs on a folder with JPG images. Loads all images and returns detected results.Using a quite different approach from what I\'ve seen, I created a php script that detects christmas trees by their lights. The result ist always a symmetrical triangle, and if necessary numeric values like the angle ("fatness") of the tree.The biggest threat to this algorithm obviously are lights next to (in great numbers) or in front of the tree (the greater problem until further optimization).\nEdit (added): What it can\'t do: Find out if there\'s a christmas tree or not, find multiple christmas trees in one image, correctly detect a cristmas tree in the middle of Las Vegas, detect christmas trees that are heavily bent, upside-down or chopped down... ;)The different stages are:Explanation of the markings:Source code:Images:\n\n\n\n\n\nBonus: A german Weihnachtsbaum, from Wikipedia\n\nhttp://commons.wikimedia.org/wiki/File:Weihnachtsbaum_R%C3%B6merberg.jpgI used python with opencv.My algorithm goes like this:The code:If I change the kernel from (25,5) to (10,5)\nI get nicer results on all trees but the bottom left,\nmy algorithm assumes that the tree has lights on it, and\nin the bottom left tree, the top has less light then the others.