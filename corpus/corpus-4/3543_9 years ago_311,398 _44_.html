I have a ~23000 line SQL dump containing several databases worth of data. I need to extract a certain section of this file (i.e. the data for a single database) and place it in a new file. I know both the start and end line numbers of the data that I want.Does anyone know a Unix command (or series of commands) to extract all lines from a file between say line 16224 and 16482 and then redirect them into a new file?From the sed manual:p - \n      Print out the pattern space (to the standard output). This command is usually only used in conjunction with the -n command-line option.n -\n      If auto-print is not disabled, print the pattern space, then, regardless, replace the pattern space with the next line of input. If\n  there is no more input then sed exits without processing any more\n  commands.andAddresses in a sed script can be in any of the following forms:number\n      Specifying a line number will match only that line in the input.An address range can be specified by specifying two addresses\n  separated by a comma (,). An address range matches lines starting from\n  where the first address matches, and continues until the second\n  address matches (inclusively).Where 16224,16482 are the start line number and end line number, inclusive.  This is 1-indexed.  -n suppresses echoing the input as output, which you clearly don\'t want; the numbers indicate the range of lines to make the following command operate on; the command p prints out the relevant lines.Quite simple using head/tail:using sed:using awk:There is another approach with awk:If the file is huge, it can be good to exit after reading the last desired line. This way it won\'t unnecessarily read the file until to the end:You could use \'vi\' and then the following command:Alternatively: EDIT:- Just to add explanation, you use head -n 16482 to display first 16482 lines then use tail -n 258 to get last 258 lines out of the first output. sed -n \'16224,16482p\' < dump.sqlshould do the trick. The downside of this approach is that you need to do the arithmetic to determine the argument for tail and to account for whether you want the \'between\' to include the ending line or not.I was about to post the head/tail trick, but actually I\'d probably just fire up emacs. ;-)open the new output file, ctl-y\nsaveLet\'s me see what\'s happening. I would use:FNR contains the record (line) number of the line being read from the file.I wrote a Haskell program called splitter that does exactly this: have a read through my release blog post.You can use the program as follows:And that is all that there is to it. You will need Haskell to install it. Just:And you are done. I hope that you find this program useful.Even we can do this to check at command line:For Example:Using ruby:Quick and dirty:Probably not the best way to do it but it should work.BTW: 259 = 16482-16224+1.I wrote a small bash script that you can run from your command line, so long as you update your PATH to include its directory (or you can place it in a directory that is already contained in the PATH).Usage: $ pinch filename start-line end-lineThis might work for you (GNU sed):or taking advantage of bash:The -n in the accept answers work. Here\'s another way in case you\'re inclined.This does the following:I think this might be useful solution. If the table name is "person" you can use sed to get all the lines you need to restore your table.Based on this answer, where it is missing the "DROP TABLE IF EXIST" for the table you are restoring and you need to delete few lines from the bottom of the new file before using it to prevent deleting the next table.Detailed information can also be found here