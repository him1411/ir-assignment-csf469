A self-type for a trait A:says that "A cannot be mixed into a concrete class that does not also extend B".On the other hand, the following:says that "any (concrete or abstract) class mixing in A will also be mixing in B".Don\'t these two statements mean the same thing? The self-type seems to serve only to create the possibility of a simple compile-time error.What am I missing?It is used for Dependency Injection, such as in the Cake Pattern. There exists a great article covering many different forms of dependency injection in Scala, including the Cake Pattern. If you Google "Cake Pattern and Scala", you\'ll get many links, including presentations and videos. For now, here is a link to another question.Now, as to what is the difference between a self type and extending a trait, that is simple. If you say B extends A, then B is an A. When you do dependency injection, you want B to require A, not to be an A. For example:Which would cause no error if subclassing were used.Self types allow you to define cyclical dependencies. For example, you can achieve this:Inheritance using extends does not allow that. Try:In the Odersky book, look at section 33.5 (Creating spreadsheet UI chapter) where it mentions:In the spreadsheet example, class Model inherits from Evaluator and\n  thus gains access to its evaluation method. To go the other way, class\n  Evaluator defines its self type to be Model, like this:Hope this helps.One additional difference is that self-types can specify non-class types.  For instanceThe self type here is a structural type.   The effect is to say that anything that mixes in Foo must implement a no-arg "close" method returning unit.  This allows for safe mixins for duck-typing.Section 2.3 "Selftype Annotations" of Martin Odersky\'s original Scala paper Scalable Component Abstractions actually explains the purpose of selftype beyond mixin composition very well: provide an alternative way of associating a class with an abstract type.The example given in the paper was like the following, and it doesn\'t seem to have an elegant subclass correspondent:Let\'s start with the cyclical dependency.However, the modularity of this solution is not as great as it might first appear, because you can override self types as so:Although, if you override a member of a self type, you lose access to the original member, which can still be accessed through super using inheritance. So what is really gained over using inheritance is: Now I can\'t claim to understand all the subtleties of the cake pattern, but it strikes me that the main method of enforcing modularity is through composition rather than inheritance or self types. The inheritance version is shorter, but the main reason I prefer inheritance over self types is that I find it much more tricky to get the initialisation order correct with self types. However, there are some things you can do with self types that you can\'t do with inheritance. Self types can use a type while inheritance requires a trait or a class as in:You can even do:Although you\'ll never be able to instantiate it. I don\'t see any absolute reason for not being be able to inherit from a type, but I certainly feel it would be useful to have path constructor classes and traits as we have type constructor traits / classes. As unfortunatelyWe have this:Or this:One point that should be empathised more is that traits can extends classes. Thanks to David Maclver for pointing this out. Here\'s an example from my own code:ScnBase inherits from the Swing Frame class, so it could be used as a self type and then mixed in at the end (at instantiation). However, val geomR needs to be initialised before it\'s used by inheriting traits. So we need a class to enforce prior initialisation of geomR. The class ScnVista can then be inherited from by multiple orthogonal traits which can themselves be inherited from. Using multiple type parameters (generics) offers an alternative form of modularity.Another thing that has not been mentioned: because self-types aren\'t part of the hierarchy of the required class they can be excluded from pattern matching, especially when you are exhaustively matching against a sealed hierarchy. This is convenient when you want to model orthogonal behaviors such as:TL;DR summary of the other answers:Types you extend are exposed to inherited types, but self-types are noteg: class Cow { this: FourStomachs } allows you to use methods only available to ruminants, such as digestGrass.  Traits that extend Cow however will have no such privileges.  On the other hand, class Cow extends FourStomachs will expose digestGrass to anyone who extends Cow  .self-types allow cyclical dependencies, extending other types does notA self type lets you specify what types are allowed to mixin a trait.  For example, if you have a trait with a self type Closeable, then that trait knows that the only things that are allowed to mix it in, must implement the Closeable interface.Update: A principal difference is that self-types can depend on multiple classes (I admit that\'s a bit corner case). For example, you can haveThis allows to add the Employee mixin just to anything that is a subclass of Person and Expense. Of course, this is only meaningful if Expense extends Person or vice versa. The point is that using self-types Employee can be independent of the hierarchy of the classes it depends on. It doesn\'t care of what extends what - If you switch the hierarchy of Expense vs Person, you don\'t have to modify Employee.in the first case, a sub-trait or sub-class of B can be mixed in to whatever uses A. So B can be an abstract trait.