How can I best write a query that selects 10 rows randomly from a total of 600k?A great post handling several cases, from simple, to gaps, to non-uniform with gaps.http://jan.kneschke.de/projects/mysql/order-by-rand/For most general case, here is how you do it:This supposes that the distribution of ids is equal, and that there can be gaps in the id list. See the article for more advanced examplesIts very simple and single line query.I am getting fast queries (around 0.5 seconds) with a slow cpu, selecting 10 random rows in a 400K registers MySQL database non-cached 2Gb size. See here my code: Fast selection of random rows in MySQLFrom book :Choose a Random Row Using an OffsetStill another technique that avoids problems found in the preceding\nalternatives is to count the rows in the data set and return a random\nnumber between 0 and the count. Then use this number as an offset\nwhen querying the data setUse this solution when you can\xe2\x80\x99t assume contiguous key values and\nyou need to make sure each row has an even chance of being selected.How to select random rows from a table:From here:\nSelect random rows in MySQLA quick improvement over "table scan" is to use the index to pick up random ids.Well if you have no gaps in your keys and they are all numeric you can calculate random numbers and select those lines. but this will probably not be the case.So one solution would be the following:which will basically ensure that you get a random number in the range of your keys and then you select the next best which is greater.\nyou have to do this 10 times.however this is NOT really random because your keys will most likely not be distributed evenly.It\'s really a big problem and not easy to solve fulfilling all the requirements, MySQL\'s rand() is the best you can get if you really want 10 random rows.There is however another solution which is fast but also has a trade off when it comes to randomness, but may suit you better. Read about it here: How can i optimize MySQL's ORDER BY RAND() function?Question is how random do you need it to be. Can you explain a bit more so I can give you a good solution.For example a company I worked with had a solution where they needed absolute randomness extremely fast. They ended up with pre-populating the database with random values that were selected descending and set to different random values afterwards again.If you hardly ever update you could also fill an incrementing id so you have no gaps and just can calculate random keys before selecting... It depends on the use case!I used this http://jan.kneschke.de/projects/mysql/order-by-rand/ posted by Riedsio (i used the case of a stored procedure that returns one or more random values):In the article he solves the problem of gaps in ids causing not so random results by maintaining a table (using triggers, etc...see the article);\nI\'m solving the problem by adding another column to the table, populated with contiguous numbers, starting from 1 (edit: this  column is added to the temporary table created by the subquery at runtime, doesn\'t affect your permanent table):In the article i can see he went to great lengths to optimize the code; i have no ideea if/how much my changes impact the performance but works very well for me.Simple query that has excellent performance (works with gaps):Two nested subqueries are used because MySQL doesn\'t support LIMIT in the first one yet.This is fast because the sort phase only uses the indexed ID column.For weighted version: https://stackoverflow.com/a/41577458/893432I needed a query to return a large number of random rows from a rather large table. This is what I came up with. First get the maximum record id:Then substitute that value into:Where max is the maximum record id in the table and n is the number of rows you want in your result set. The assumption is that there are no gaps in the record id\'s although I doubt it would affect the result if there were (haven\'t tried it though). I also created this stored procedure to be more generic; pass in the table name and number of rows to be returned. I\'m running MySQL 5.5.38 on Windows 2008, 32GB, dual 3GHz E5450, and on a table with 17,361,264 rows it\'s fairly consistent at ~.03 sec / ~11 sec to return 1,000,000 rows. (times are from MySQL Workbench 6.1; you could also use CEIL instead of FLOOR in the 2nd select statement depending on your preference)thenHere is a game changer that may be helpfully for many;I have a table with 200k rows, with sequential id\'s, I needed to pick N random rows, so I opt to generate random values based in the biggest ID in the table, I created this script to find out which is the fastest operation:The results are:Based in this results, order desc is the fastest operation to get the max id,\nHere is my answer to the question:FYI: To get 10 random rows from a 200k table, it took me 1.78 ms (including all the operations in the php side)All the best answers have been already posted (mainly those referencing the link http://jan.kneschke.de/projects/mysql/order-by-rand/).I want to pinpoint another speed-up possibility - caching. Think of why you need to get random rows. Probably you want display some random post or random ad on a website. If you are getting 100 req/s, is it really needed that each visitor gets random rows? Usually it is completely fine to cache these X random rows for 1 second (or even 10 seconds). It doesn\'t matter if 100 unique visitors in the same 1 second get the same random posts, because the next second another 100 visitors will get different set of posts.When using this caching you can use also some of the slower solution for getting the random data as it will be fetched from MySQL only once per second regardless of your req/s.Combine the answer of @redsio with a temp-table (600K is not that much):And then take a version of @redsios Answer:If the table is big, you can sieve on the first part:Version: You could keep the table tmp_randorder persistent, call it datatable_idlist. Recreate that table in certain intervals (day, hour), since it also will get holes. If your table gets really big, you could also refill holes select l.data_id as whole \nfrom datatable_idlist l\nleft join datatable dt on dt.id = l.data_id\nwhere dt.id is null;Version: Give your Dataset a random_sortorder column either directly in datatable or in a persistent extra table datatable_sortorder. Index that column. Generate a Random-Value in your Application (I\'ll call it $rand).This solution discriminates the \'edge rows\' with the highest and the lowest random_sortorder, so rearrange them in intervals (once a day).Another simple solution would be ranking the rows and fetch one of them randomly and with this solution you won\'t need to have any \'Id\' based column in the table.You can change the limit value as per your need to access as many rows as you want but that would mostly be consecutive values.However, if you don\'t want consecutive random values then you can fetch a bigger sample and select randomly from it. something like ...One way that i find pretty good if there\'s an autogenerated id is to use the modulo operator \'%\'. For Example, if you need 10,000 random records out 70,000, you could simplify this by saying you need 1 out of every 7 rows. This can be simplified in this query:If the result of dividing target rows by total available is not an integer, you will have some extra rows than what you asked for, so you should add a LIMIT clause to help you trim the result set like this:This does require a full scan, but it is faster than ORDER BY RAND, and in my opinion simpler to understand than other options mentioned in this thread. Also if the system that writes to the DB creates sets of rows in batches you might not get such a random result as you where expecting.I improved the answer @Riedsio had. This is the most efficient query I can find on a large, uniformly distributed table with gaps (tested on getting 1000 random rows from a table that has > 2.6B rows). Let me unpack what\'s going on.Doing the union helps you fit everything into 1 query so you can avoid doing multiple queries. It also lets you save the overhead of calculating MAX(id). Depending on your application, this might matter a lot or very little.Note that this gets only the ids and gets them in random order. If you want to do anything more advanced I recommend you do this:If you want one random record (no matter if there are gapes between ids):Source: https://www.warpconduit.net/2011/03/23/selecting-a-random-record-using-mysql-benchmark-results/#comment-1266Old question, but this is something I ran into today, wanting to select a random page. I opted not to use any of the answers here because of concerns with performance and the fact that many of them have strong biases in the "random". Here was my solution (using PHP):Pages model:Pages controller:Basically, all it\'s doing is getting an array of page slugs from the DB, and using PHP to pick a random one from the returned array.If you want 10 records, just iterate through the array and remove chosen ones to avoid duplicates, and then add them to a separate array of results. Something like this:I Use this query:query time:0.016sUse the below simple query to get random data from a table.This is how I do it:I like it because does not require other tables, it is simple to write, and it is very fast to execute.I guess this is the best possible way..