What is the difference between decimal, float and double in .NET?When would someone use one of these?float and double are floating binary point types. In other words, they represent a number like this:The binary number and the location of the binary point are both encoded within the value.decimal is a floating decimal point type. In other words, they represent a number like this:Again, the number and the location of the decimal point are both encoded within the value \xe2\x80\x93 that\'s what makes decimal still a floating point type instead of a fixed point type.The important thing to note is that humans are used to representing non-integers in a decimal form, and expect exact results in decimal representations; not all decimal numbers are exactly representable in binary floating point \xe2\x80\x93 0.1, for example \xe2\x80\x93 so if you use a binary floating point value you\'ll actually get an approximation to 0.1. You\'ll still get approximations when using a floating decimal point as well \xe2\x80\x93 the result of dividing 1 by 3 can\'t be exactly represented, for example.As for what to use when:For values which are "naturally exact decimals" it\'s good to use decimal. This is usually suitable for any concepts invented by humans: financial values are the most obvious example, but there are others too. Consider the score given to divers or ice skaters, for example.For values which are more artefacts of nature which can\'t really be measured exactly anyway, float/double are more appropriate. For example, scientific data would usually be represented in this form. Here, the original values won\'t be "decimally accurate" to start with, so it\'s not important for the expected results to maintain the "decimal accuracy". Floating binary point types are much faster to work with than decimals.Precision is the main difference. Float - 7 digits (32 bit)Double-15-16 digits (64 bit)Decimal -28-29 significant digits (128 bit)Decimals have much higher precision and are usually used within financial applications that require a high degree of accuracy. Decimals are much slower (up to 20X times in some tests) than a double/float. Decimals and Floats/Doubles cannot be compared without a cast whereas Floats and Doubles can. Decimals also allow the encoding or trailing zeros.Result : The Decimal structure is strictly geared to financial calculations requiring accuracy, which are relatively intolerant of rounding.  Decimals are not adequate for scientific applications, however, for several reasons:for more information you can go to source of this picture:http://social.msdn.microsoft.com/Forums/en-US/csharpgeneral/thread/921a8ffc-9829-4145-bdc9-a96c1ec174a5float 7 digits of precision double has about 15 digits of precisiondecimal has about 28 digits of precisionIf you need better accuracy, use double instead of float.\nIn modern CPUs both data types have almost the same performance. The only benifit of using float is they take up less space. Practically matters only if you have got many of them.I found this is interesting. What Every Computer Scientist Should Know About Floating-Point ArithmeticNo one has mentioned thatIn default settings, Floats (System.Single) and doubles (System.Double) will never use\n  overflow checking while Decimal (System.Decimal) will always use\n  overflow checking.I mean throws OverflowException.But these do not:&I won\'t reiterate tons of good (and some bad) information already answered in other answers and comments, but I will answer your followup question with a tip:When would someone use one of these?Use decimal for counted valuesUse float/double for measured valuesSome examples:money (do we count money or measure money?)distance (do we count distance or measure distance? *)scores (do we count scores or measure scores?)We always count money and should never measure it. We usually measure distance. We often count scores.* In some cases, what I would call nominal distance, we may indeed want to \'count\' distance. For example, maybe we are dealing with country signs that show distances to cities, and we know that those distances never have more than one decimal digit (xxx.x km).The Decimal, Double, and Float variable types are different in the way that they store the values. Precision is the main difference where float is a single precision (32 bit) floating point data type, double is a double precision (64 bit) floating point data type and decimal is a 128-bit floating point data type.Float - 32 bit (7 digits)Double - 64 bit (15-16 digits)Decimal - 128 bit (28-29 significant digits)The main difference is Floats and Doubles are binary floating point types and a Decimal will store the value as a floating decimal point type. So Decimals have much higher precision and are usually used within monetary (financial) or scientific calculation applications that require a high degree of accuracy. But in performance wise Decimals are slower than double and float types.Decimal can 100% accurately represent any number within the precision of the decimal format, whereas Float and Double, cannot accurately represent all numbers, even numbers that are within their respective formats precision.DecimalIn case of financial applications, or scientific calculations, it is better to use Decimal types because it gives you a high level of accuracy and easy to avoid rounding errorsDoubleDouble Types are probably the most normally used data type for real values, except handling money.FloatIt is used mostly in graphic libraries because very high demands for processing powers, also used situations that can endure rounding errors.Integers, as was mentioned, are whole numbers. They can\'t store the point something, like .7, .42, and .007. If you need to store numbers that are not whole numbers, you need a different type of variable. You can use the double type, or the float type. You set these types of variables up in exactly the same way: instead of using the word int, you type double, or float. Like this:(Float is short for "floating point", and just means a number with a point something on the end.)The difference between the two is in the size of the numbers that they can hold. For float, you can have up to 7 digits in your number. For doubles, you can have up to 16 digits. To be more precise, here\'s the official size:Float is a 32-bit number and double is a 64-bit number.Double click your new button to get at the code. Add the following three lines to your button code:Halt your program and return to the coding window. Change this line:Run your programme and click your double button. The message box correctly displays the number. Add another number on the end, though, and C# will again round up or down. The moral is, if you want accuracy, careful of rounding!This has been an interesting thread of me, as today, we\'ve just had a nasty little bug, concerning "decimal" having less precision than a "float".In our C# code, we are reading numeric values from an Excel spreadsheet, converting them into a decimal, then sending this decimal back to a Service, to save into a SQL Server database.Now, for almost all of our Excel values, this worked beautifully.  But for some, very small Excel values, using "decimal.TryParse" lost the value completely.  One such example:cellValue = 0.00006317592Decimal.TryParse(cellValue.ToString(), out value); would return 0The solution, bizarrely, was to convert the Excel values into a double first, and then into a decimal.Even though double has less precision than a decimal, this actually ensured small numbers would still be recognised.  For some reason, "double.TryParse" was actually able to retrieve such small numbers, whereas "decimal.TryParse" would set them to zero.Odd.  Very odd.  float   ~ \xc2\xb11.5 x 10-45 to \xc2\xb13.4 x 1038 --------7 figures\ndouble  ~ \xc2\xb15.0 x 10-324 to \xc2\xb11.7 x 10308 ------15 or 16 figures\ndecimal ~ \xc2\xb11.0 x 10-28 to \xc2\xb17.9 x 1028 --------28 or 29 figuresFor applications such as games and embedded systems where memory and performance are both critical, float is usually the numeric type of choice as it is faster and half the size of a double. Integers used to be the weapon of choice, but floating point performance has overtaken integer in modern processors. Decimal is right out!The Decimal, Double, and Float variable types are different in the way that they store the values. Precision is the main difference where float is a single precision (32 bit) floating point data type, double is a double precision (64 bit) floating point data type and decimal is a 128-bit floating point data type.Float - 32 bit (7 digits)Double - 64 bit (15-16 digits)Decimal - 128 bit (28-29 significant digits)More about...the difference between Decimal, Float and DoubleThe problem with all these types is that a certain imprecision subsists \nAND that this problem can occur with small decimal numbers like in the following exampleQuestion: Which value does bLower variable contain ?Answer: On a 32 bit machine bLower contains TRUE !!!If I replace Double by Decimal, bLower contains FALSE which is the good answer.In double, the problem is that fMean-fDelta = 1.09999999999 that is lower that 1.1.Caution: I think that same problem can certainly exists for other number because Decimal is only a double with higher precision and the precision has always a limit.In fact, Double, Float and Decimal correspond to BINARY decimal in COBOL !It is regrettable that other numeric types implemented in COBOL don\'t exist in .Net. For those that don\'t know COBOL, there exist in COBOL following numeric typeThe main difference between each of these is the precision.float is a 32-bit number, double is a 64-bit number and decimal is a 128-bit number.